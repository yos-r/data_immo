{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des biblioth√®ques n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import missingno as msno\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, calinski_harabasz_score\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import missingno as msno\n",
    "import warnings\n",
    "import importlib; importlib.reload(model_functions)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "df=model_functions.read_data('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nStatistiques descriptives:\")\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse des donn√©es manquantes: \n",
    "model_functions.analyze_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b449ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des Prix\n",
    "# 1er niveau d'imputation\n",
    "df['price'] = df.groupby(['neighborhood', 'property_type','transaction'])['price'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "df['price_ttc'] = df.groupby(['neighborhood', 'property_type','transaction'])['price_ttc'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "# 2√®me niveau d'imputation\n",
    "df['price'] = df.groupby(['city','transaction'])['price'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['price_ttc'] = df.groupby(['city','transaction'])['price_ttc'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['listing_price'] = df['listing_price'].fillna(df['price']) # Remplir les valeurs manquantes de 'listing_price' avec la valeur de 'price' si disponible\n",
    "df['suffix'] = df['suffix'].fillna('TTC') # remplacer suffixe par ttc par defaut\n",
    "# 3√®me niveau d'imputation\n",
    "df = df[df['price'].notnull()] #√©liminer les lignes o√π 'price' est toujours manquant\n",
    "\n",
    "\n",
    "null_price_rows = df[df['price'].isna()]\n",
    "display(null_price_rows)\n",
    "print(f\"Nombre de lignes avec 'price' manquant apr√®s imputation : {null_price_rows.shape[0]}\") # de 244 prix manquants on passe √† 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea00c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des variables cat√©gorielles: standing et condition\n",
    "df=model_functions.impute_condition_simple(df)\n",
    "df=model_functions.impute_finishing_simple(df)\n",
    "# Imputation de la variable 'age' et 'construction_year'\n",
    "df=model_functions.impute_property_year_age(df)\n",
    "df['construction_year']=2025-df['age']\n",
    "# Imputation des variables binaires des commodit√©s\n",
    "df=model_functions.impute_binary_amenities(df,['central_heating','air_conditioning','elevator','swimming_pool','equipped_kitchen','garden'])\n",
    "# Imputation des variables num√©riques des pieces, chambres, salles de bain et parkings\n",
    "df=model_functions.simple_impute_rooms(df)\n",
    "df=model_functions.simple_impute_rooms(df,'bedrooms')\n",
    "df=model_functions.simple_impute_rooms(df,'parkings')\n",
    "df=model_functions.simple_impute_rooms(df,'bathrooms')\n",
    "df.drop(columns=['amenities'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification de l'imputation\n",
    "model_functions.analyze_missing_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b98be0",
   "metadata": {},
   "source": [
    "# Apprentissage supervis√© "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611920f",
   "metadata": {},
   "source": [
    "## R√©gression lin√©aire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Pr√©paration les donn√©es pour la r√©gression - encode uniquement condition, finishing et variables binaires\n",
    "df_regression= model_functions.prepare_data_for_regression(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f292a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©gression lin√©aire du prix du bien immobilier / segementation par prix/ type de propriete et quartier/ville\n",
    "model, importance, metrics = model_functions.regression_par_segment(\n",
    "    df,\n",
    "    city='Cite El Khadra', \n",
    "    property_type='bureau',\n",
    "    transaction='rent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model, rf_importance, rf_metrics = model_functions.random_forest_par_segment(\n",
    "    df,\n",
    "    city='La Soukra', \n",
    "    property_type='villa',\n",
    "    transaction='sale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9255411",
   "metadata": {},
   "source": [
    "## Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea80e2",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fbf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, importance, r2 = model_functions.xgboost_simple(\n",
    "    df,\n",
    "    city='Cite El Khadra', \n",
    "    property_type='appartement',\n",
    "    transaction='rent'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5dc40",
   "metadata": {},
   "source": [
    "## Comparaison des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = model_functions.comparer_modeles(\n",
    "     df,\n",
    "    city='La Soukra', \n",
    "    property_type='appartement',\n",
    "    transaction='sale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26da3d",
   "metadata": {},
   "source": [
    "# Apprentissage non supervis√© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c72db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df[(df['city'] == 'La Soukra') & (df['property_type'] == 'appartement') & (df['transaction'] == 'sale')]\n",
    "df_scaled, scaler, feature_names = model_functions.prepare_data_for_clustering(filtered)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec4f4b",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681395fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPRENDRE LE LIEN ENTRE PCA ET VOS VARIABLES ORIGINALES\n",
    "pca_model, df_pca, explained_variance = model_functions.apply_pca_analysis(df_scaled, 2)\n",
    "# Analyse des liens\n",
    "loadings_df, fig_contrib = model_functions.analyse_complete_pca_variables(pca_model, df_pca, explained_variance, feature_names, df ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e931d",
   "metadata": {},
   "source": [
    "## Kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model, kmeans_n_clusters, kmeans_labels, kmeans_metrics, scores, n_clusters_list = model_functions.apply_kmeans_clustering(\n",
    "    df_scaled, \n",
    "    n_clusters_range=(2, 8),  # Tester de 2 √† 8 clusters\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. VISUALISATION K-MEANS AVEC MATPLOTLIB\n",
    "# ===================================================================\n",
    "\n",
    "# Cr√©er une figure avec plusieurs sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Couleurs pour les clusters\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, kmeans_n_clusters))\n",
    "\n",
    "# 1. Clusters en 2D PCA\n",
    "scatter = axes[0,0].scatter(df_pca.iloc[:, 0], df_pca.iloc[:, 1], \n",
    "                           c=kmeans_labels, cmap='Set3', alpha=0.7)\n",
    "axes[0,0].set_xlabel('PC1')\n",
    "axes[0,0].set_ylabel('PC2')\n",
    "axes[0,0].set_title('K-Means - Clusters (2D PCA)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ajouter les centres des clusters\n",
    "centers_pca = pca_model.transform(scaler.transform(kmeans_model.cluster_centers_))\n",
    "axes[0,0].scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "                 marker='x', s=200, linewidths=3, color='red', label='Centres')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Distribution des clusters\n",
    "cluster_counts = pd.Series(kmeans_labels).value_counts().sort_index()\n",
    "bars = axes[0,1].bar(range(len(cluster_counts)), cluster_counts.values, \n",
    "                    color=[colors[i] for i in range(len(cluster_counts))])\n",
    "axes[0,1].set_xlabel('Cluster')\n",
    "axes[0,1].set_ylabel('Nombre de propri√©t√©s')\n",
    "axes[0,1].set_title('Distribution des clusters K-Means')\n",
    "axes[0,1].set_xticks(range(len(cluster_counts)))\n",
    "axes[0,1].set_xticklabels([f'Cluster {i}' for i in cluster_counts.index])\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for i, v in enumerate(cluster_counts.values):\n",
    "    axes[0,1].text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "\n",
    "# 3. √âvolution du score de silhouette\n",
    "axes[1,0].plot(n_clusters_list, scores, 'bo-', linewidth=2, markersize=8)\n",
    "axes[1,0].axvline(x=kmeans_n_clusters, color='red', linestyle='--', \n",
    "                 label=f'Optimal: {kmeans_n_clusters} clusters')\n",
    "axes[1,0].set_xlabel('Nombre de clusters')\n",
    "axes[1,0].set_ylabel('Score de silhouette')\n",
    "axes[1,0].set_title('Optimisation du nombre de clusters')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 4. Variance expliqu√©e par PCA\n",
    "axes[1,1].bar(range(len(explained_variance)), explained_variance * 100)\n",
    "axes[1,1].set_xlabel('Composante principale')\n",
    "axes[1,1].set_ylabel('Variance expliqu√©e (%)')\n",
    "axes[1,1].set_title('Variance expliqu√©e par PCA')\n",
    "axes[1,1].set_xticks(range(len(explained_variance)))\n",
    "axes[1,1].set_xticklabels([f'PC{i+1}' for i in range(len(explained_variance))])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d8f05",
   "metadata": {},
   "source": [
    "Cluster 2 = le plus gros groupe (4 propri√©t√©s)\n",
    "Cluster 4 = 3 propri√©t√©s\n",
    "Clusters 0,1,6,7 = 2 propri√©t√©s chacun\n",
    "Clusters 3,5 = 1 propri√©t√© chacun (singletons)\n",
    "Probl√®me : Beaucoup de clusters avec tr√®s peu de propri√©t√©s !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# INTERPR√âTATION ET CORRECTION DES R√âSULTATS K-MEANS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"üîç ANALYSE DES R√âSULTATS K-MEANS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. DIAGNOSTIC DU PROBL√àME\n",
    "print(f\"\\nüìä DIAGNOSTIC:\")\n",
    "print(f\"‚Ä¢ Nombre total de propri√©t√©s: {len(df_scaled)}\")\n",
    "print(f\"‚Ä¢ Nombre de clusters trouv√©s: {kmeans_n_clusters}\")\n",
    "print(f\"‚Ä¢ Ratio propri√©t√©s/cluster: {len(df_scaled)/kmeans_n_clusters:.1f}\")\n",
    "\n",
    "# Analyser la distribution des clusters\n",
    "cluster_counts = pd.Series(kmeans_labels).value_counts().sort_index()\n",
    "print(f\"\\nüìà DISTRIBUTION DES CLUSTERS:\")\n",
    "for cluster_id, count in cluster_counts.items():\n",
    "    percentage = (count / len(df_scaled)) * 100\n",
    "    status = \"‚úÖ OK\" if count >= 3 else \"‚ö†Ô∏è TROP PETIT\"\n",
    "    print(f\"Cluster {cluster_id}: {count} propri√©t√©s ({percentage:.1f}%) {status}\")\n",
    "\n",
    "# 2. RECOMMANDATION : FORCER 3-4 CLUSTERS\n",
    "print(f\"\\nüí° SOLUTION RECOMMAND√âE:\")\n",
    "print(f\"Forcer un nombre plus raisonnable de clusters (3-4)\")\n",
    "\n",
    "# ===================================================================\n",
    "# REFAIRE K-MEANS AVEC 3 CLUSTERS\n",
    "# ===================================================================\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"NOUVEAU K-MEANS AVEC 3 CLUSTERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Appliquer K-Means avec 3 clusters\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_3 = kmeans_3.fit_predict(df_scaled)\n",
    "\n",
    "# Calculer les m√©triques\n",
    "silhouette_3 = silhouette_score(df_scaled, labels_3)\n",
    "\n",
    "print(f\"üìä R√âSULTATS AVEC 3 CLUSTERS:\")\n",
    "print(f\"Score de silhouette: {silhouette_3:.4f}\")\n",
    "\n",
    "# Distribution des nouveaux clusters\n",
    "cluster_counts_3 = pd.Series(labels_3).value_counts().sort_index()\n",
    "print(f\"\\nüìà NOUVELLE DISTRIBUTION:\")\n",
    "for cluster_id, count in cluster_counts_3.items():\n",
    "    percentage = (count / len(df_scaled)) * 100\n",
    "    print(f\"Cluster {cluster_id}: {count} propri√©t√©s ({percentage:.1f}%)\")\n",
    "\n",
    "# ===================================================================\n",
    "# VISUALISATION AM√âLIOR√âE\n",
    "# ===================================================================\n",
    "print(f\"\\nüìä VISUALISATION COMPARATIVE:\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Graphique 1: K-Means original (8 clusters)\n",
    "scatter1 = axes[0].scatter(df_pca.iloc[:, 0], df_pca.iloc[:, 1], \n",
    "                          c=kmeans_labels, cmap='Set3', alpha=0.7)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title(f'K-Means Original: 8 clusters\\n(Silhouette: {kmeans_metrics[\"silhouette_score\"]:.3f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: K-Means am√©lior√© (3 clusters)\n",
    "scatter2 = axes[1].scatter(df_pca.iloc[:, 0], df_pca.iloc[:, 1], \n",
    "                          c=labels_3, cmap='viridis', alpha=0.7, s=80)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title(f'K-Means Am√©lior√©: 3 clusters\\n(Silhouette: {silhouette_3:.3f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Ajouter les centres des clusters pour le mod√®le am√©lior√©\n",
    "centers_3_pca = pca_model.transform(scaler.transform(kmeans_3.cluster_centers_))\n",
    "axes[1].scatter(centers_3_pca[:, 0], centers_3_pca[:, 1], \n",
    "               marker='x', s=300, linewidths=4, color='red', label='Centres')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===================================================================\n",
    "# ANALYSE BUSINESS DES 3 CLUSTERS\n",
    "# ===================================================================\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSE BUSINESS - 3 SEGMENTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ajouter les nouveaux clusters aux donn√©es\n",
    "filtered_3_clusters = filtered.loc[df_scaled.index].copy()\n",
    "filtered_3_clusters['Segment'] = labels_3\n",
    "\n",
    "# Analyser chaque segment\n",
    "segments_analysis = {}\n",
    "\n",
    "for cluster_id in sorted(set(labels_3)):\n",
    "    cluster_data = filtered_3_clusters[filtered_3_clusters['Segment'] == cluster_id]\n",
    "    \n",
    "    # Calculs statistiques\n",
    "    avg_price = cluster_data['price'].mean() if 'price' in cluster_data.columns else 0\n",
    "    avg_size = cluster_data['size'].mean() if 'size' in cluster_data.columns else 0\n",
    "    count = len(cluster_data)\n",
    "    \n",
    "    # D√©terminer le type de segment\n",
    "    price_quartiles = filtered_3_clusters['price'].quantile([0.33, 0.67])\n",
    "    \n",
    "    if avg_price <= price_quartiles[0.33]:\n",
    "        segment_type = \"√âCONOMIQUE\"\n",
    "        emoji = \"üí∞\"\n",
    "    elif avg_price <= price_quartiles[0.67]:\n",
    "        segment_type = \"MOYEN\"\n",
    "        emoji = \"üè†\"\n",
    "    else:\n",
    "        segment_type = \"PREMIUM\"\n",
    "        emoji = \"üíé\"\n",
    "    \n",
    "    segments_analysis[cluster_id] = {\n",
    "        'type': segment_type,\n",
    "        'emoji': emoji,\n",
    "        'count': count,\n",
    "        'avg_price': avg_price,\n",
    "        'avg_size': avg_size\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{emoji} SEGMENT {cluster_id} - {segment_type}\")\n",
    "    print(f\"   ‚Ä¢ {count} propri√©t√©s ({count/len(filtered_3_clusters)*100:.1f}%)\")\n",
    "    if 'price' in cluster_data.columns:\n",
    "        print(f\"   ‚Ä¢ Loyer moyen: {avg_price:.0f} TND/mois\")\n",
    "        print(f\"   ‚Ä¢ Range prix: {cluster_data['price'].min():.0f} - {cluster_data['price'].max():.0f} TND\")\n",
    "    if 'size' in cluster_data.columns:\n",
    "        print(f\"   ‚Ä¢ Superficie moyenne: {avg_size:.0f} m¬≤\")\n",
    "    \n",
    "    # Quartiers principaux\n",
    "    if 'neighborhood' in cluster_data.columns and not cluster_data['neighborhood'].dropna().empty:\n",
    "        neighborhoods = cluster_data['neighborhood'].value_counts().head(2)\n",
    "        print(f\"   ‚Ä¢ Quartiers: {neighborhoods.to_dict()}\")\n",
    "    \n",
    "    # Recommandations business\n",
    "    if segment_type == \"√âCONOMIQUE\":\n",
    "        print(f\"   üí° Cible: √âtudiants, jeunes professionnels, budgets serr√©s\")\n",
    "    elif segment_type == \"MOYEN\":\n",
    "        print(f\"   üí° Cible: Familles, professionnels, march√© principal\")\n",
    "    else:\n",
    "        print(f\"   üí° Cible: Cadres, expatri√©s, client√®le ais√©e\")\n",
    "\n",
    "# ===================================================================\n",
    "# COMPARAISON FINALE\n",
    "# ===================================================================\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARAISON FINALE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison_final = pd.DataFrame({\n",
    "    'Approche': ['K-Means Auto (8 clusters)', 'K-Means Optimis√© (3 clusters)'],\n",
    "    'Score Silhouette': [f\"{kmeans_metrics['silhouette_score']:.4f}\", f\"{silhouette_3:.4f}\"],\n",
    "    'Clusters viables': [f\"{sum(1 for c in cluster_counts.values if c >= 3)}/8\", \"3/3\"],\n",
    "    'Interpr√©tation': ['Difficile (trop fragment√©)', 'Claire (3 segments)'],\n",
    "    'Business': ['Non applicable', 'Applicable']\n",
    "})\n",
    "\n",
    "print(comparison_final.to_string(index=False))\n",
    "\n",
    "# ===================================================================\n",
    "# RECOMMANDATION FINALE\n",
    "# ===================================================================\n",
    "print(f\"\\nüéØ RECOMMANDATION FINALE:\")\n",
    "print(f\"=\"*30)\n",
    "\n",
    "if silhouette_3 >= kmeans_metrics['silhouette_score'] * 0.9:  # Si dans les 90%\n",
    "    print(f\"‚úÖ UTILISER 3 CLUSTERS\")\n",
    "    print(f\"   ‚Ä¢ Score silhouette acceptable: {silhouette_3:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Segments business viables\")\n",
    "    print(f\"   ‚Ä¢ Interpr√©tation claire\")\n",
    "    \n",
    "    # Sauvegarder les meilleurs r√©sultats\n",
    "    final_clusters = labels_3\n",
    "    final_model = kmeans_3\n",
    "    print(f\"\\nüíæ Variables cr√©√©es:\")\n",
    "    print(f\"   ‚Ä¢ final_clusters: labels des 3 segments\")\n",
    "    print(f\"   ‚Ä¢ final_model: mod√®le K-Means optimis√©\")\n",
    "    print(f\"   ‚Ä¢ filtered_3_clusters: donn√©es avec segments\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è CONSID√âRER D'AUTRES APPROCHES\")\n",
    "    print(f\"   ‚Ä¢ Essayer DBSCAN ou CAH\")\n",
    "    print(f\"   ‚Ä¢ Revoir les caract√©ristiques utilis√©es\")\n",
    "    print(f\"   ‚Ä¢ Augmenter le dataset\")\n",
    "\n",
    "print(f\"\\nüéâ ANALYSE TERMIN√âE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b890e04",
   "metadata": {},
   "source": [
    "PC1 capture ~50% de la variabilit√© des donn√©es\n",
    "PC2 capture ~12% de la variabilit√©\n",
    "Total : ~62% de l'information pr√©serv√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76f2cd",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_model, dbscan_labels, dbscan_metrics = model_functions.apply_dbscan_clustering(\n",
    "    df_scaled,\n",
    "    eps_range=(2.5, 3),      # Range pour eps\n",
    "    min_samples_range=(2, 18)   # Range pour min_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eece522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualisation DBSCAN avec matplotlib\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Clusters DBSCAN en 2D PCA\n",
    "unique_labels = sorted(set(dbscan_labels))\n",
    "colors_dbscan = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    mask = dbscan_labels == label\n",
    "    if label == -1:\n",
    "        # Points de bruit en noir\n",
    "        axes[0,0].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], \n",
    "                         c='black', label='Bruit', alpha=0.7, marker='x')\n",
    "    else:\n",
    "        axes[0,0].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], \n",
    "                         c=[colors_dbscan[i]], label=f'Cluster {label}', alpha=0.7)\n",
    "\n",
    "axes[0,0].set_xlabel('PC1')\n",
    "axes[0,0].set_ylabel('PC2')\n",
    "axes[0,0].set_title('DBSCAN - Clusters (2D PCA)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribution des clusters DBSCAN\n",
    "cluster_counts_dbscan = pd.Series(dbscan_labels).value_counts().sort_index()\n",
    "cluster_names = ['Bruit' if idx == -1 else f'Cluster {idx}' for idx in cluster_counts_dbscan.index]\n",
    "bar_colors = ['black' if idx == -1 else colors_dbscan[i] for i, idx in enumerate(cluster_counts_dbscan.index)]\n",
    "\n",
    "bars = axes[0,1].bar(range(len(cluster_counts_dbscan)), cluster_counts_dbscan.values, color=bar_colors)\n",
    "axes[0,1].set_xticks(range(len(cluster_counts_dbscan)))\n",
    "axes[0,1].set_xticklabels(cluster_names, rotation=45)\n",
    "axes[0,1].set_ylabel('Nombre de propri√©t√©s')\n",
    "axes[0,1].set_title('Distribution des clusters DBSCAN')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, count in zip(bars, cluster_counts_dbscan.values):\n",
    "    axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                   str(count), ha='center', va='bottom')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse DBSCAN: \n",
    "print(f\"‚Ä¢ Param√®tres DBSCAN: eps={dbscan_metrics['eps']:.3f}, min_samples={dbscan_metrics['min_samples']}\")\n",
    "print(f\"‚Ä¢ Nombre total de propri√©t√©s: {len(dbscan_labels)}\")\n",
    "print(f\"‚Ä¢ Nombre de clusters form√©s: {dbscan_metrics['n_clusters']}\")\n",
    "print(f\"‚Ä¢ Points de bruit: {dbscan_metrics['n_noise_points']} ({dbscan_metrics['noise_ratio']*100:.1f}%)\")\n",
    "\n",
    "if dbscan_metrics.get('silhouette_score', 0) > 0:\n",
    "    print(f\"‚Ä¢ Score de silhouette: {dbscan_metrics['silhouette_score']:.4f}\")\n",
    "\n",
    "# Analyser la distribution des clusters\n",
    "unique_labels = set(dbscan_labels)\n",
    "cluster_distribution = {}\n",
    "\n",
    "print(f\"\\nüìà DISTRIBUTION D√âTAILL√âE:\")\n",
    "for label in sorted(unique_labels):\n",
    "    count = sum(dbscan_labels == label)\n",
    "    percentage = (count / len(dbscan_labels)) * 100\n",
    "    cluster_distribution[label] = count\n",
    "    \n",
    "    if label == -1:\n",
    "        print(f\"üîç BRUIT: {count} propri√©t√©s ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"üè∑Ô∏è CLUSTER {label}: {count} propri√©t√©s ({percentage:.1f}%)\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. INTERPR√âTATION DE LA QUALIT√â DU CLUSTERING\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüéØ √âVALUATION DE LA QUALIT√â:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# √âvaluer la qualit√© selon diff√©rents crit√®res\n",
    "noise_ratio = dbscan_metrics['noise_ratio']\n",
    "n_clusters = dbscan_metrics['n_clusters']\n",
    "\n",
    "# Crit√®res de qualit√©\n",
    "print(f\"\\nüìä CRIT√àRES D'√âVALUATION:\")\n",
    "\n",
    "# 1. Ratio de bruit\n",
    "if noise_ratio < 0.1:\n",
    "    noise_quality = \"EXCELLENT\"\n",
    "    noise_emoji = \"‚úÖ\"\n",
    "elif noise_ratio < 0.2:\n",
    "    noise_quality = \"BON\"\n",
    "    noise_emoji = \"üëç\"\n",
    "elif noise_ratio < 0.4:\n",
    "    noise_quality = \"ACCEPTABLE\"\n",
    "    noise_emoji = \"‚ö†Ô∏è\"\n",
    "else:\n",
    "    noise_quality = \"PROBL√âMATIQUE\"\n",
    "    noise_emoji = \"‚ùå\"\n",
    "\n",
    "print(f\"{noise_emoji} Ratio de bruit: {noise_ratio*100:.1f}% - {noise_quality}\")\n",
    "\n",
    "# 2. Nombre de clusters\n",
    "if n_clusters == 0:\n",
    "    cluster_quality = \"AUCUN CLUSTER\"\n",
    "    cluster_emoji = \"‚ùå\"\n",
    "elif n_clusters == 1:\n",
    "    cluster_quality = \"UN SEUL GROUPE\"\n",
    "    cluster_emoji = \"‚ö†Ô∏è\"\n",
    "elif 2 <= n_clusters <= 4:\n",
    "    cluster_quality = \"OPTIMAL\"\n",
    "    cluster_emoji = \"‚úÖ\"\n",
    "else:\n",
    "    cluster_quality = \"TROP FRAGMENT√â\"\n",
    "    cluster_emoji = \"‚ö†Ô∏è\"\n",
    "\n",
    "print(f\"{cluster_emoji} Nombre de clusters: {n_clusters} - {cluster_quality}\")\n",
    "\n",
    "# 3. Taille des clusters\n",
    "min_cluster_size = min([count for label, count in cluster_distribution.items() if label != -1], default=0)\n",
    "if min_cluster_size >= 3:\n",
    "    size_quality = \"CLUSTERS VIABLES\"\n",
    "    size_emoji = \"‚úÖ\"\n",
    "elif min_cluster_size >= 2:\n",
    "    size_quality = \"CLUSTERS PETITS\"\n",
    "    size_emoji = \"‚ö†Ô∏è\"\n",
    "else:\n",
    "    size_quality = \"CLUSTERS TROP PETITS\"\n",
    "    size_emoji = \"‚ùå\"\n",
    "\n",
    "print(f\"{size_emoji} Taille minimale des clusters: {min_cluster_size} - {size_quality}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. ANALYSE D√âTAILL√âE PAR CLUSTER\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüîç ANALYSE D√âTAILL√âE PAR CLUSTER:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Cr√©er un DataFrame avec les donn√©es originales et les clusters\n",
    "filtered_with_dbscan = filtered_3_clusters.copy()\n",
    "filtered_with_dbscan['Cluster_DBSCAN'] = dbscan_labels\n",
    "\n",
    "# Analyser chaque cluster individuellement\n",
    "for label in sorted(unique_labels):\n",
    "    cluster_data = filtered_with_dbscan[filtered_with_dbscan['Cluster_DBSCAN'] == label]\n",
    "    \n",
    "    if label == -1:\n",
    "        print(f\"\\nüîç ANALYSE DES POINTS DE BRUIT - {len(cluster_data)} propri√©t√©s\")\n",
    "        print(\"-\" * 60)\n",
    "        print(\"‚ùì QUE REPR√âSENTENT CES PROPRI√âT√âS ?\")\n",
    "        print(\"‚Ä¢ Propri√©t√©s avec des caract√©ristiques UNIQUES/ATYPIQUES\")\n",
    "        print(\"‚Ä¢ Ne ressemblent √† aucun autre groupe\")\n",
    "        print(\"‚Ä¢ Peuvent √™tre des OPPORTUNIT√âS ou des PROBL√àMES\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüè∑Ô∏è CLUSTER {label} - {len(cluster_data)} propri√©t√©s\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"üéØ PROFIL DU GROUPE:\")\n",
    "    \n",
    "    # Analyser les caract√©ristiques du cluster/bruit\n",
    "    if len(cluster_data) > 0:\n",
    "        \n",
    "        # 1. PRIX\n",
    "        if 'price' in cluster_data.columns:\n",
    "            prix_stats = {\n",
    "                'moyenne': cluster_data['price'].mean(),\n",
    "                'mediane': cluster_data['price'].median(), \n",
    "                'min': cluster_data['price'].min(),\n",
    "                'max': cluster_data['price'].max(),\n",
    "                'ecart_type': cluster_data['price'].std()\n",
    "            }\n",
    "            \n",
    "            print(f\"üí∞ PRIX DE LOCATION:\")\n",
    "            print(f\"   ‚Ä¢ Moyenne: {prix_stats['moyenne']:.0f} TND/mois\")\n",
    "            print(f\"   ‚Ä¢ M√©diane: {prix_stats['mediane']:.0f} TND/mois\")\n",
    "            print(f\"   ‚Ä¢ Range: {prix_stats['min']:.0f} - {prix_stats['max']:.0f} TND\")\n",
    "            if len(cluster_data) > 1:\n",
    "                print(f\"   ‚Ä¢ √âcart-type: {prix_stats['ecart_type']:.0f} TND\")\n",
    "            \n",
    "            # Comparer √† la moyenne g√©n√©rale\n",
    "            prix_moyen_general = filtered_with_dbscan['price'].mean()\n",
    "            difference = prix_stats['moyenne'] - prix_moyen_general\n",
    "            if abs(difference) > 50:  # Si diff√©rence significative\n",
    "                direction = \"PLUS CHER\" if difference > 0 else \"MOINS CHER\"\n",
    "                print(f\"   üìä {direction} que la moyenne g√©n√©rale ({difference:+.0f} TND)\")\n",
    "        \n",
    "        # 2. SUPERFICIE\n",
    "        if 'size' in cluster_data.columns:\n",
    "            size_stats = {\n",
    "                'moyenne': cluster_data['size'].mean(),\n",
    "                'min': cluster_data['size'].min(),\n",
    "                'max': cluster_data['size'].max()\n",
    "            }\n",
    "            \n",
    "            print(f\"üìê SUPERFICIE:\")\n",
    "            print(f\"   ‚Ä¢ Moyenne: {size_stats['moyenne']:.0f} m¬≤\")\n",
    "            print(f\"   ‚Ä¢ Range: {size_stats['min']:.0f} - {size_stats['max']:.0f} m¬≤\")\n",
    "        \n",
    "        # 3. NOMBRE DE PI√àCES\n",
    "        if 'rooms' in cluster_data.columns:\n",
    "            rooms_avg = cluster_data['rooms'].mean()\n",
    "            print(f\"üè† PI√àCES: {rooms_avg:.1f} en moyenne\")\n",
    "        \n",
    "        # 4. LOCALISATION\n",
    "        if 'neighborhood' in cluster_data.columns and not cluster_data['neighborhood'].dropna().empty:\n",
    "            quartiers = cluster_data['neighborhood'].value_counts()\n",
    "            print(f\"üèòÔ∏è QUARTIERS PRINCIPAUX:\")\n",
    "            for quartier, count in quartiers.head(3).items():\n",
    "                percentage = (count / len(cluster_data)) * 100\n",
    "                print(f\"   ‚Ä¢ {quartier}: {count} propri√©t√©s ({percentage:.0f}%)\")\n",
    "        \n",
    "        # 5. √âTAT DES PROPRI√âT√âS\n",
    "        if 'condition' in cluster_data.columns and not cluster_data['condition'].dropna().empty:\n",
    "            conditions = cluster_data['condition'].value_counts()\n",
    "            print(f\"üîß √âTAT DES PROPRI√âT√âS:\")\n",
    "            for condition, count in conditions.head(3).items():\n",
    "                percentage = (count / len(cluster_data)) * 100\n",
    "                print(f\"   ‚Ä¢ {condition}: {count} propri√©t√©s ({percentage:.0f}%)\")\n",
    "        \n",
    "        # 6. FINITIONS\n",
    "        if 'finishing' in cluster_data.columns and not cluster_data['finishing'].dropna().empty:\n",
    "            finitions = cluster_data['finishing'].value_counts()\n",
    "            print(f\"‚ú® FINITIONS:\")\n",
    "            for finition, count in finitions.head(3).items():\n",
    "                percentage = (count / len(cluster_data)) * 100\n",
    "                print(f\"   ‚Ä¢ {finition}: {count} propri√©t√©s ({percentage:.0f}%)\")\n",
    "        \n",
    "        # 7. √âQUIPEMENTS (si disponibles)\n",
    "        equipment_cols = ['air_conditioning', 'elevator', 'garden', 'equipped_kitchen', 'swimming_pool']\n",
    "        available_equipment = [col for col in equipment_cols if col in cluster_data.columns]\n",
    "        \n",
    "        if available_equipment:\n",
    "            print(f\"‚ö° √âQUIPEMENTS:\")\n",
    "            for equip in available_equipment:\n",
    "                if cluster_data[equip].dtype in ['int64', 'float64']:\n",
    "                    percentage = (cluster_data[equip] == 1).mean() * 100\n",
    "                    if percentage > 0:\n",
    "                        print(f\"   ‚Ä¢ {equip}: {percentage:.0f}% des propri√©t√©s\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4. INTERPR√âTATION BUSINESS AVANC√âE\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüíº INTERPR√âTATION BUSINESS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analyser les segments de march√© identifi√©s\n",
    "segments_business = {}\n",
    "\n",
    "for label in sorted(unique_labels):\n",
    "    if label == -1:\n",
    "        continue  # On analyse le bruit s√©par√©ment\n",
    "    \n",
    "    cluster_data = filtered_with_dbscan[filtered_with_dbscan['Cluster_DBSCAN'] == label]\n",
    "    \n",
    "    if 'price' in cluster_data.columns and len(cluster_data) > 0:\n",
    "        avg_price = cluster_data['price'].mean()\n",
    "        avg_size = cluster_data['size'].mean() if 'size' in cluster_data.columns else 0\n",
    "        \n",
    "        # D√©terminer le segment de march√©\n",
    "        price_quartiles = filtered_with_dbscan['price'].quantile([0.25, 0.5, 0.75])\n",
    "        \n",
    "        if avg_price <= price_quartiles[0.25]:\n",
    "            segment_type = \"√âCONOMIQUE\"\n",
    "            segment_emoji = \"üí∞\"\n",
    "            target = \"√âtudiants, jeunes professionnels, budgets serr√©s\"\n",
    "            strategy = \"Prix comp√©titifs, localisation accessible\"\n",
    "        elif avg_price <= price_quartiles[0.5]:\n",
    "            segment_type = \"ENTR√âE DE GAMME\"\n",
    "            segment_emoji = \"üè†\"\n",
    "            target = \"Primo-locataires, petites familles\"\n",
    "            strategy = \"Bon rapport qualit√©/prix, commodit√©s de base\"\n",
    "        elif avg_price <= price_quartiles[0.75]:\n",
    "            segment_type = \"MOYEN STANDING\"\n",
    "            segment_emoji = \"üè°\"\n",
    "            target = \"Familles, professionnels √©tablis\"\n",
    "            strategy = \"Confort, √©quipements, quartiers r√©sidentiels\"\n",
    "        else:\n",
    "            segment_type = \"HAUT DE GAMME\"\n",
    "            segment_emoji = \"üíé\"\n",
    "            target = \"Cadres, expatri√©s, client√®le ais√©e\"\n",
    "            strategy = \"Luxe, services premium, localisations privil√©gi√©es\"\n",
    "        \n",
    "        segments_business[label] = {\n",
    "            'type': segment_type,\n",
    "            'emoji': segment_emoji,\n",
    "            'count': len(cluster_data),\n",
    "            'avg_price': avg_price,\n",
    "            'avg_size': avg_size,\n",
    "            'target': target,\n",
    "            'strategy': strategy\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{segment_emoji} CLUSTER {label}: SEGMENT {segment_type}\")\n",
    "        print(f\"   üìä {len(cluster_data)} propri√©t√©s ({len(cluster_data)/len(filtered_with_dbscan)*100:.1f}% du march√©)\")\n",
    "        print(f\"   üí∞ Prix moyen: {avg_price:.0f} TND/mois\")\n",
    "        if avg_size > 0:\n",
    "            print(f\"   üìê Superficie moyenne: {avg_size:.0f} m¬≤\")\n",
    "        print(f\"   üéØ Cible: {target}\")\n",
    "        print(f\"   üí° Strat√©gie: {strategy}\")\n",
    "\n",
    "# Analyser les points de bruit sp√©cifiquement\n",
    "bruit_data = filtered_with_dbscan[filtered_with_dbscan['Cluster_DBSCAN'] == -1]\n",
    "\n",
    "if len(bruit_data) > 0:\n",
    "    print(f\"\\nüîç ANALYSE SP√âCIALE: POINTS DE BRUIT\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"üéØ OPPORTUNIT√âS POTENTIELLES:\")\n",
    "    \n",
    "    if 'price' in bruit_data.columns:\n",
    "        prix_bruit = bruit_data['price'].tolist()\n",
    "        prix_median_general = filtered_with_dbscan['price'].median()\n",
    "        \n",
    "        print(f\"üí∞ Prix des propri√©t√©s atypiques: {prix_bruit}\")\n",
    "        print(f\"üìä Prix m√©dian g√©n√©ral: {prix_median_general:.0f} TND\")\n",
    "        \n",
    "        # Identifier les bonnes affaires potentielles\n",
    "        bonnes_affaires = bruit_data[bruit_data['price'] < prix_median_general]\n",
    "        proprietes_cheres = bruit_data[bruit_data['price'] > prix_median_general]\n",
    "        \n",
    "        if len(bonnes_affaires) > 0:\n",
    "            print(f\"‚úÖ BONNES AFFAIRES POTENTIELLES: {len(bonnes_affaires)} propri√©t√©s\")\n",
    "            print(f\"   ‚Ä¢ Prix sous la m√©diane du march√©\")\n",
    "            print(f\"   ‚Ä¢ √Ä investiguer: raison du prix bas?\")\n",
    "        \n",
    "        if len(proprietes_cheres) > 0:\n",
    "            print(f\"üíé PROPRI√âT√âS PREMIUM UNIQUES: {len(proprietes_cheres)} propri√©t√©s\")\n",
    "            print(f\"   ‚Ä¢ Caract√©ristiques exceptionnelles\")\n",
    "            print(f\"   ‚Ä¢ Segments de niche\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. RECOMMANDATIONS D'ACTIONS\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüöÄ RECOMMANDATIONS D'ACTIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nüìà STRAT√âGIES PAR CLUSTER:\")\n",
    "for label, info in segments_business.items():\n",
    "    print(f\"\\n{info['emoji']} CLUSTER {label} ({info['type']}):\")\n",
    "    print(f\"   üìä Marketing: Cibler {info['target'].lower()}\")\n",
    "    print(f\"   üí° Positionnement: {info['strategy']}\")\n",
    "    \n",
    "    # Recommandations sp√©cifiques selon la taille du cluster\n",
    "    if info['count'] >= 3:\n",
    "        print(f\"   ‚úÖ Segment viable: d√©velopper l'offre\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Petit segment: analyser la demande\")\n",
    "\n",
    "print(f\"\\nüîç ACTIONS POUR LES POINTS DE BRUIT:\")\n",
    "if len(bruit_data) > 0:\n",
    "    print(f\"‚Ä¢ V√©rifier la qualit√© des donn√©es\")\n",
    "    print(f\"‚Ä¢ Investiguer les raisons de l'atypisme\")\n",
    "    print(f\"‚Ä¢ Identifier les opportunit√©s de niche\")\n",
    "    print(f\"‚Ä¢ Contr√¥ler les prix aberrants\")\n",
    "else:\n",
    "    print(f\"‚Ä¢ Aucun point de bruit d√©tect√©\")\n",
    "    print(f\"‚Ä¢ March√© homog√®ne et pr√©visible\")\n",
    "\n",
    "# ===================================================================\n",
    "# 6. CONCLUSION G√âN√âRALE\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüéØ CONCLUSION G√âN√âRALE:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "if n_clusters >= 2 and noise_ratio < 0.3:\n",
    "    print(f\"‚úÖ DBSCAN A R√âUSSI √Ä SEGMENTER VOS DONN√âES\")\n",
    "    print(f\"   ‚Ä¢ {n_clusters} segments naturels identifi√©s\")\n",
    "    print(f\"   ‚Ä¢ {dbscan_metrics['n_noise_points']} propri√©t√©s atypiques d√©tect√©es\")\n",
    "    print(f\"   ‚Ä¢ Segmentation applicable pour le business\")\n",
    "    \n",
    "    # Identifier le segment principal\n",
    "    main_cluster = max(segments_business.items(), key=lambda x: x[1]['count'])\n",
    "    print(f\"\\nüéñÔ∏è SEGMENT PRINCIPAL: {main_cluster[1]['type']}\")\n",
    "    print(f\"   ‚Ä¢ {main_cluster[1]['count']} propri√©t√©s\")\n",
    "    print(f\"   ‚Ä¢ Repr√©sente le c≈ìur de votre march√©\")\n",
    "\n",
    "elif n_clusters == 1:\n",
    "    print(f\"‚ö†Ô∏è MARCH√â TR√àS HOMOG√àNE\")\n",
    "    print(f\"   ‚Ä¢ Un seul groupe principal d√©tect√©\")\n",
    "    print(f\"   ‚Ä¢ Peu de diff√©renciation dans l'offre\")\n",
    "    print(f\"   ‚Ä¢ Opportunit√© de cr√©er des niches\")\n",
    "\n",
    "elif n_clusters == 0:\n",
    "    print(f\"‚ùå DONN√âES TROP DISPERS√âES\")\n",
    "    print(f\"   ‚Ä¢ DBSCAN n'a trouv√© aucun cluster\")\n",
    "    print(f\"   ‚Ä¢ Tous les points consid√©r√©s comme du bruit\")\n",
    "    print(f\"   ‚Ä¢ Recommandation: utiliser K-Means\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è SEGMENTATION COMPLEXE\")\n",
    "    print(f\"   ‚Ä¢ {n_clusters} clusters d√©tect√©s\")\n",
    "    print(f\"   ‚Ä¢ March√© tr√®s fragment√©\")\n",
    "    print(f\"   ‚Ä¢ Analyser la viabilit√© de chaque segment\")\n",
    "\n",
    "print(f\"\\nüíæ DONN√âES DISPONIBLES:\")\n",
    "print(f\"‚Ä¢ filtered_with_dbscan: DataFrame avec clusters DBSCAN\")\n",
    "print(f\"‚Ä¢ dbscan_labels: labels des clusters pour chaque propri√©t√©\")\n",
    "print(f\"‚Ä¢ dbscan_metrics: m√©triques de performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77984c",
   "metadata": {},
   "source": [
    "## CAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAH avec m√©thode Ward pour les appartements mis √† la vente √† La Soukra  (>150 observations)\n",
    "\n",
    "filtered_df = df_scaled[(df['transaction'] == 'sale') & (df['city'] == 'La Soukra') & (df['property_type'] == 'appartement')]\n",
    "# 1 -  CAH\n",
    "linkage_matrix, cluster_labels, optimal_n_clusters, metrics = model_functions.apply_cah_clustering(\n",
    "    filtered_df, \n",
    "    max_clusters=10, \n",
    "    linkage_method='ward'\n",
    ")\n",
    "\n",
    "# 2  dendrogramme\n",
    "print(\"\\nüìä DENDROGRAMME:\")\n",
    "dendrogram_data = model_functions.visualize_cah_dendrogram(\n",
    "    linkage_matrix, \n",
    "    optimal_n_clusters=optimal_n_clusters,\n",
    "    max_display=100\n",
    ")\n",
    "\n",
    "# 3. analyse compl√®te\n",
    "results_df, detailed_df, hierarchy_df = model_functions.complete_cah_analysis_after_dendrogram(\n",
    "    df, filtered_df, linkage_matrix, cluster_labels, optimal_n_clusters, feature_names\n",
    ")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
