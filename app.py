import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Importer les fonctions depuis le fichier model_functions.py
from model_functions import *

# Configuration de la page
st.set_page_config(
    page_title="Analyse Immobili√®re ",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour am√©liorer l'apparence
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #2563EB;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #3B82F6;
        margin-top: 1.5rem;
        margin-bottom: 0.8rem;
    }
    .highlight {
        background-color: #EFF6FF;
        padding: 20px;
        border-radius: 5px;
        border-left: 5px solid #3B82F6;
        margin-bottom: 20px;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 15px;
    }
    .stat-card {
        background-color: #F8FAFC;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 15px;
        text-align: center;
    }
    .footer {
        margin-top: 50px;
        padding-top: 20px;
        border-top: 1px solid #E5E7EB;
        text-align: center;
        font-size: 0.9rem;
        color: #6B7280;
    }
</style>
""", unsafe_allow_html=True)

# Header de l'application
st.title("üè† Analyse du March√© Immobilier Tunisien")

# Introduction et contexte
with st.expander("üìå √Ä propos de cette application", expanded=True):
    st.markdown("""
    <div class="highlight">
    <h4>Contexte</h4>
    <p>Cette application vous permet d'analyser en profondeur le march√© immobilier tunisien √† travers des donn√©es collect√©es depuis des sites de franchises immobili√®res  (Century 21, REMAX, Tecnocasa et Newkey). Que vous soyez un investisseur, un agent immobilier, ou simplement √† la recherche d'un bien, cet outil vous fournit des insights pr√©cieux sur les tendances du march√©.</p>
    
    <h4>Fonctionnalit√©s</h4>
    <ul>
        <li><strong>Analyse exploratoire</strong> : Visualisez les distributions des prix, surfaces, et autres caract√©ristiques des biens</li>
        <li><strong>Traitement des donn√©es</strong> : Nettoyez et imputez les valeurs manquantes pour une analyse plus pr√©cise</li>
        <li><strong>Mod√©lisation pr√©dictive</strong> : Utilisez des algorithmes d'apprentissage automatique pour pr√©dire les prix et identifier les facteurs d√©terminants</li>
        <li><strong>Segmentation g√©ographique</strong> : Analysez les sp√©cificit√©s du march√© par ville et quartier</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
uploaded_file = st.file_uploader("T√©l√©charger un fichier CSV", type=['csv'])


# Fonction pour nettoyer et pr√©parer les donn√©es
def preprocess_data(df):
    # Liste des colonnes num√©riques √† convertir
    numeric_columns = ['price', 'size', 'rooms', 'bedrooms', 'bathrooms', 'parkings', 
                      'construction_year', 'age', 'air_conditioning', 'central_heating', 
                      'swimming_pool', 'elevator', 'garden', 'equipped_kitchen']
    
    # Convertir chaque colonne en num√©rique
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Convertir les dates
    if 'listing_date' in df.columns:
        try:
            df['listing_date'] = pd.to_datetime(df['listing_date'], errors='coerce')
        except:
            pass
    
    # Remplacer les valeurs potentiellement probl√©matiques
    df = df.replace(['\\N', 'N/A', 'NA', ''], np.nan)
    
    # Standardiser la casse pour les colonnes cat√©gorielles
    categorical_columns = ['property_type', 'transaction', 'city', 'state', 'neighborhood', 'finishing', 'condition']
    for col in categorical_columns:
        if col in df.columns and df[col].dtype == 'object':
            # Convertir tout en minuscules pour standardiser
            df[col] = df[col].str.lower()
    
    return df

# Fonction pour g√©n√©rer les visualisations basiques
def basic_visualizations(df):
    # Visualisation par ville
    if 'city' in df.columns:
        st.subheader("Nombre de propri√©t√©s par ville")
        city_counts = df['city'].value_counts().reset_index()
        city_counts.columns = ['ville', 'nombre']
        city_counts['ville'] = city_counts['ville'].str.title()
        
        fig = px.bar(city_counts, x='ville', y='nombre', 
                   title="Nombre de propri√©t√©s par ville")
        st.plotly_chart(fig, use_container_width=True)
    
    # Prix moyen par type de propri√©t√©
    if 'property_type' in df.columns and 'price' in df.columns:
        valid_price_df = df.dropna(subset=['price'])
        if not valid_price_df.empty:
            st.subheader("Prix moyen par type de propri√©t√©")
            price_by_type = valid_price_df.groupby('property_type')['price'].mean().reset_index()
            price_by_type.columns = ['type', 'prix_moyen']
            price_by_type['type'] = price_by_type['type'].str.capitalize()
            
            fig = px.bar(price_by_type, x='type', y='prix_moyen', 
                       title="Prix moyen par type de propri√©t√©",
                       labels={'prix_moyen': 'Prix moyen (TND)', 'type': 'Type de bien'})
            st.plotly_chart(fig, use_container_width=True)
    
    # Relation taille vs prix
    if 'size' in df.columns and 'price' in df.columns:
        valid_data = df.dropna(subset=['size', 'price'])
        if len(valid_data) > 5:
            st.subheader("Relation entre taille et prix")
            
            if 'property_type' in valid_data.columns:
                plot_data = valid_data.copy()
                plot_data['property_type_display'] = plot_data['property_type'].str.capitalize()
                
                fig = px.scatter(plot_data, x='size', y='price', 
                               color='property_type_display',
                               title="Relation entre taille et prix",
                               labels={'size': 'Surface (m¬≤)', 'price': 'Prix (TND)', 
                                     'property_type_display': 'Type de bien'})
            else:
                fig = px.scatter(valid_data, x='size', y='price', 
                               title="Relation entre taille et prix",
                               labels={'size': 'Surface (m¬≤)', 'price': 'Prix (TND)'})
            
            st.plotly_chart(fig, use_container_width=True)

# Nouvelles visualisations
def advanced_visualizations(df):
    if df is None or df.empty:
        st.warning("Aucune donn√©e disponible pour les visualisations avanc√©es.")
        return
        
    col1, col2 = st.columns(2)
    
    # Distribution des conditions
    with col1:
        if 'condition' in df.columns and not df['condition'].isna().all():
            st.subheader("Distribution des √©tats de propri√©t√©")
            condition_counts = df['condition'].value_counts().reset_index()
            condition_counts.columns = ['√©tat', 'nombre']
            condition_counts['√©tat'] = condition_counts['√©tat'].str.capitalize()
            
            fig = px.pie(condition_counts, values='nombre', names='√©tat', 
                      title="Distribution des √©tats de propri√©t√©",
                      color_discrete_sequence=px.colors.qualitative.Pastel)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
    
    # Distribution des finitions
    with col2:
        if 'finishing' in df.columns and not df['finishing'].isna().all():
            st.subheader("Niveau de finition des propri√©t√©s")
            finishing_counts = df['finishing'].value_counts().reset_index()
            finishing_counts.columns = ['finition', 'nombre']
            finishing_counts['finition'] = finishing_counts['finition'].str.capitalize()
            
            fig = px.pie(finishing_counts, values='nombre', names='finition', 
                      title="Niveau de finition des propri√©t√©s",
                      color_discrete_sequence=px.colors.qualitative.Bold)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
    
    # Visualisation des transactions par quartier
    if 'transaction' in df.columns and 'neighborhood' in df.columns and not df['neighborhood'].isna().all():
        st.subheader("Types de transaction par quartier")
        try:
            transaction_by_neighborhood = pd.crosstab(df['neighborhood'], df['transaction'])
            transaction_by_neighborhood = transaction_by_neighborhood.reset_index()
            transaction_by_neighborhood_melted = pd.melt(
                transaction_by_neighborhood, 
                id_vars=['neighborhood'], 
                var_name='transaction', 
                value_name='count'
            )
            transaction_by_neighborhood_melted['neighborhood'] = transaction_by_neighborhood_melted['neighborhood'].str.title()
            transaction_by_neighborhood_melted['transaction'] = transaction_by_neighborhood_melted['transaction'].str.capitalize()
            
            # Limiter aux 15 quartiers les plus fr√©quents pour lisibilit√©
            top_neighborhoods = df['neighborhood'].value_counts().nlargest(15).index
            filtered_data = transaction_by_neighborhood_melted[
                transaction_by_neighborhood_melted['neighborhood'].str.lower().isin(top_neighborhoods)
            ]
            
            if not filtered_data.empty:
                fig = px.bar(filtered_data, x='neighborhood', y='count', color='transaction',
                           title="Types de transaction par quartier (top 15)",
                           labels={'count': 'Nombre', 'neighborhood': 'Quartier', 'transaction': 'Type de transaction'},
                           barmode='stack')
                fig.update_layout(xaxis={'categoryorder': 'total descending'})
                st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"Impossible de g√©n√©rer la visualisation des transactions par quartier: {e}")
    
    # Matrice de corr√©lation
    numeric_df = df.select_dtypes(include=['number'])
    if numeric_df.shape[1] > 2:
        st.subheader("Matrice de corr√©lation")
        
        # S√©lectionner seulement les colonnes num√©riques et supprimer les colonnes avec trop de NA
        cols_to_keep = numeric_df.columns[numeric_df.isnull().mean() < 0.5]
        if len(cols_to_keep) >= 2:  # Besoin d'au moins 2 colonnes pour une corr√©lation
            try:
                corr_df = numeric_df[cols_to_keep].corr()
                
                fig = px.imshow(corr_df, 
                               text_auto=True, 
                               aspect="auto",
                               color_continuous_scale='RdBu_r',
                               title="Corr√©lation entre les variables")
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de g√©n√©rer la matrice de corr√©lation: {e}")
    
    # Distribution des prix par type de propri√©t√©
    if 'price' in df.columns and 'property_type' in df.columns:
        valid_data = df.dropna(subset=['price', 'property_type'])
        if len(valid_data) > 5:
            st.subheader("Distribution des prix par type de propri√©t√©")
            
            fig = px.box(valid_data, x='property_type', y='price',
                       labels={'property_type': 'Type de propri√©t√©', 'price': 'Prix (TND)'},
                       title="Distribution des prix par type de propri√©t√©",
                       category_orders={"property_type": sorted(valid_data['property_type'].unique())})
            
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)

# Nouvelle section pour les imputations de donn√©es
def imputation_section(df):
    st.header("Imputation des donn√©es manquantes")
    
    if df is None or df.empty:
        st.error("Aucune donn√©e disponible pour l'imputation.")
        return df
    
    # Cr√©ation de l'interface d'imputation
    st.write("Cette section vous permet de compl√©ter les valeurs manquantes dans votre jeu de donn√©es.")
    
    try:
        # Analyser les donn√©es manquantes
        missing_data_df = analyze_missing_data(df)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("√âtat des valeurs manquantes")
            st.dataframe(missing_data_df)
        
        with col2:
            # Graphique des valeurs manquantes
            missing_cols = missing_data_df[missing_data_df['Valeurs NA'] > 0]
            if not missing_cols.empty:
                fig = px.bar(
                    missing_cols.reset_index(), 
                    x='index', 
                    y='Pourcentage NA (%)',
                    title="Pourcentage de valeurs manquantes par colonne",
                    labels={'index': 'Colonne', 'Pourcentage NA (%)': '% manquant'}
                )
                fig.update_layout(xaxis={'categoryorder': 'total descending'})
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("üëç Aucune valeur manquante dans vos donn√©es!")
        
        # S√©lection des colonnes √† imputer
        st.subheader("Choisir les colonnes √† imputer")
        
        # Organisation par cat√©gories
        price_cols = st.multiselect(
            "Colonnes de prix",
            [col for col in df.columns if col in ['price', 'price_ttc', 'listing_price']],
            [col for col in df.columns if col in ['price', 'price_ttc', 'listing_price'] and df[col].isna().sum() > 0]
        )
        
        condition_finishing_cols = st.multiselect(
            "Qualit√© et finition",
            [col for col in df.columns if col in ['condition', 'finishing']],
            [col for col in df.columns if col in ['condition', 'finishing'] and df[col].isna().sum() > 0]
        )
        
        age_year_cols = st.multiselect(
            "√Çge et ann√©e de construction",
            [col for col in df.columns if col in ['age', 'construction_year']],
            [col for col in df.columns if col in ['age', 'construction_year'] and df[col].isna().sum() > 0]
        )
        
        room_cols = st.multiselect(
            "Pi√®ces, chambres, salles de bain, etc.",
            [col for col in df.columns if col in ['rooms', 'bedrooms', 'bathrooms', 'parkings']],
            [col for col in df.columns if col in ['rooms', 'bedrooms', 'bathrooms', 'parkings'] and df[col].isna().sum() > 0]
        )
        
        binary_cols = st.multiselect(
            "√âquipements (variables binaires)",
            [col for col in df.columns if df[col].nunique() <= 2 and col not in ['transaction', 'city', 'property_type', 'neighborhood']],
            [col for col in df.columns if df[col].nunique() <= 2 and df[col].isna().sum() > 0 and col not in ['transaction', 'city', 'property_type', 'neighborhood']]
        )
        
        # Bouton pour lancer l'imputation
        impute_button = st.button("Imputer les valeurs manquantes", type="primary")
        
        if impute_button:
            if df is None or df.empty:
                st.error("Aucune donn√©e disponible pour l'imputation.")
                return df
                
            # Cr√©er une copie pour l'imputation
            try:
                df_imputed = df.copy()
                progress_placeholder = st.empty()
                
                with st.spinner("Imputation en cours..."):
                    # Imputation progressive avec barre de progression
                    progress_bar = st.progress(0)
                    
                    # 1. Imputation des prix
                    # 
                    
                    # 2. Imputation de la condition
                    if 'condition' in condition_finishing_cols:
                        progress_placeholder.write("Imputation de la condition...")
                        try:
                            df_imputed = impute_condition_simple(df_imputed)
                            progress_bar.progress(40)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de la condition: {e}")
                    
                    # 3. Imputation de la finition
                    if 'finishing' in condition_finishing_cols:
                        progress_placeholder.write("Imputation du niveau de finition...")
                        try:
                            df_imputed = impute_finishing_simple(df_imputed)
                            progress_bar.progress(60)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de la finition: {e}")
                    
                    # 4. Imputation de l'√¢ge et ann√©e de construction
                    if age_year_cols:
                        progress_placeholder.write("Imputation de l'√¢ge et ann√©e de construction...")
                        try:
                            df_imputed = impute_property_year_age(
                                df_imputed, 
                                impute_year='construction_year' in age_year_cols, 
                                impute_age='age' in age_year_cols
                            )
                            df_imputed['construction_year']=2025-df_imputed['age']
                            progress_bar.progress(75)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de l'√¢ge/ann√©e: {e}")
                    
                    # 5. Imputation des caract√©ristiques binaires
                    if binary_cols:
                        progress_placeholder.write("Imputation des √©quipements...")
                        try:
                            df_imputed = impute_binary_amenities(df_imputed, binary_columns=binary_cols)
                            progress_bar.progress(85)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation des √©quipements: {e}")
                    
                    # 6. Imputation des pi√®ces et caract√©ristiques
                    for room_col in room_cols:
                        progress_placeholder.write(f"Imputation de {room_col}...")
                        try:
                            df_imputed = simple_impute_rooms(df_imputed, rooms_col=room_col)
                            time.sleep(0.3)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de {room_col}: {e}")
                    # imputation des prix
                    if price_cols:
                        progress_placeholder.write("Imputation des prix...")
                        try:
                            # df_imputed = impute_missing_prices(df_imputed)
                            df_imputed['price'] = df_imputed.groupby(['neighborhood', 'property_type','transaction'])['price'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price_ttc'] = df_imputed.groupby(['neighborhood', 'property_type','transaction'])['price_ttc'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price'] = df.groupby(['city','transaction'])['price'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price_ttc'] = df.groupby(['city','transaction'])['price_ttc'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed = df_imputed[df_imputed['price'].notnull()]
    
                            df_imputed['suffix'] = df_imputed['suffix'].fillna('TTC')
                            
                            df_imputed['listing_price'] = df_imputed['listing_price'].fillna(df_imputed['price'])
                            
                            progress_bar.progress(100)
                            time.sleep(0.5)  
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation des prix: {e}")
                    progress_bar.progress(100)
                    progress_placeholder.empty()
                
                # Comparer l'avant/apr√®s
                st.subheader("R√©sultats de l'imputation")
                
                col1, col2 = st.columns(2)
                
                # Analyse des valeurs manquantes avant
                with col1:
                    df.drop(columns=['amenities'], inplace=True)
                    st.write("Avant imputation")
                    missing_before = analyze_missing_data(df)
                    st.dataframe(missing_before)
                    
                    # Pourcentage global des donn√©es manquantes avant
                    total_elements = df.shape[0] * df.shape[1]
                    total_missing = df.isna().sum().sum()
                    pct_missing_before = (total_missing / total_elements) * 100
                    
                    st.metric(
                        "Pourcentage global de donn√©es manquantes",
                        f"{pct_missing_before:.2f}%"
                    )
                
                # Analyse des valeurs manquantes apr√®s
                with col2:
                    st.write("Apr√®s imputation")
                    df_imputed.drop(columns=['amenities'], inplace=True)
                    missing_after = analyze_missing_data(df_imputed)
                    st.dataframe(missing_after)
                    
                    # Pourcentage global des donn√©es manquantes apr√®s
                    total_missing_after = df_imputed.isna().sum().sum()
                    pct_missing_after = (total_missing_after / total_elements) * 100
                    
                    st.metric(
                        "Pourcentage global de donn√©es manquantes",
                        f"{pct_missing_after:.2f}%",
                        f"-{pct_missing_before - pct_missing_after:.2f}%"
                    )
                
                # Visualisation de l'impact de l'imputation
                st.subheader("Visualisation de l'impact de l'imputation")
                
                # S√©lectionnez une colonne pour visualiser l'impact de l'imputation
                all_imputed_cols = price_cols + condition_finishing_cols + age_year_cols + room_cols + binary_cols
                
                if True:
                    vis_col = st.selectbox(
                        "S√©lectionner une colonne pour visualiser l'impact de l'imputation",
                        all_imputed_cols
                    )
                    
                    if vis_col in df_imputed.columns:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"Distribution de {vis_col} avant imputation")
                            
                            if pd.api.types.is_numeric_dtype(df[vis_col]):
                                # Histogramme pour les donn√©es num√©riques
                                fig = px.histogram(
                                    df.dropna(subset=[vis_col]), 
                                    x=vis_col,
                                    title=f"Distribution de {vis_col} avant imputation",
                                    nbins=30,
                                    opacity=0.7
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                # Barres pour les donn√©es cat√©gorielles
                                value_counts = df[vis_col].value_counts().reset_index()
                                value_counts.columns = ['valeur', 'nombre']
                                
                                fig = px.bar(
                                    value_counts,
                                    x='valeur',
                                    y='nombre',
                                    title=f"Distribution de {vis_col} avant imputation"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            st.write(f"Distribution de {vis_col} apr√®s imputation")
                            
                            if pd.api.types.is_numeric_dtype(df_imputed[vis_col]):
                                # Histogramme pour les donn√©es num√©riques
                                fig = px.histogram(
                                    df_imputed, 
                                    x=vis_col,
                                    title=f"Distribution de {vis_col} apr√®s imputation",
                                    nbins=30,
                                    opacity=0.7
                                )
                                # Ajouter une ligne pour marquer les valeurs imput√©es
                                orig_values = df[~df[vis_col].isna()][vis_col]
                                fig.add_traces(
                                    px.histogram(
                                        orig_values, 
                                        x=orig_values,
                                        nbins=30,
                                        opacity=0.7
                                    ).data
                                )
                                fig.data[0].marker.color = 'blue'  # Toutes les valeurs
                                fig.data[1].marker.color = 'lightgreen'  # Valeurs originales
                                fig.data[0].name = 'Toutes les valeurs (incluant imput√©es)'
                                fig.data[1].name = 'Valeurs originales uniquement'
                                fig.update_layout(barmode='overlay', legend=dict(orientation='h'))
                                
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                # Barres pour les donn√©es cat√©gorielles
                                value_counts = df_imputed[vis_col].value_counts().reset_index()
                                value_counts.columns = ['valeur', 'nombre']
                                
                                fig = px.bar(
                                    value_counts,
                                    x='valeur',
                                    y='nombre',
                                    title=f"Distribution de {vis_col} apr√®s imputation"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                
                # Option pour continuer avec les donn√©es imput√©es
                if st.button("Utiliser les donn√©es imput√©es pour la suite de l'analyse"):
                    st.session_state['df_imputed'] = df_imputed
                    st.success("‚úÖ Les donn√©es imput√©es sont maintenant utilis√©es pour l'analyse!")
                    st.rerun()  # R√©ex√©cuter l'application pour utiliser les donn√©es imput√©es
                    
                return df_imputed  # Retourner les donn√©es imput√©es
                
            except Exception as e:
                st.error(f"Erreur lors de l'imputation: {e}")
                st.info("Conseil: V√©rifiez les donn√©es et essayez √† nouveau.")
                return df
    except Exception as e:
        st.error(f"Erreur lors de l'analyse des donn√©es manquantes: {e}")
        return df
        
    return df

# REMPLACER VOTRE FONCTION add_price_prediction_section PAR CELLE-CI

def simple_price_calculator(model, feature_names, df_regression, model_type="R√©gression Lin√©aire"):
    """
    Calculateur de prix simple corrig√© pour √©viter l'erreur de dimensionnalit√©
    """
    
    st.markdown("---")
    st.subheader(f"üîÆ Calculateur de Prix - {model_type}")
    
    # Obtenir un √©chantillon des donn√©es d'entra√Ænement pour la structure
    sample_row = df_regression.iloc[0:1].copy()  # Prendre la premi√®re ligne comme template
    
    # Statistiques pour valeurs par d√©faut
    stats = df_regression.describe()
    
    # Interface simple en 2 colonnes
    col1, col2 = st.columns(2)
    
    # Dictionnaire pour stocker les inputs utilisateur
    user_inputs = {}
    
    with col1:
        st.markdown("#### üìê **Caract√©ristiques Principales**")
        
        # Surface
        if 'size' in feature_names:
            size_default = int(stats.loc['mean', 'size']) if 'size' in stats.columns else 100
            user_inputs['size'] = st.number_input("Surface (m¬≤)", value=size_default, min_value=20, max_value=1000, step=5, key=f"size_{model_type}")
        
        # Pi√®ces
        if 'rooms' in feature_names:
            rooms_default = int(stats.loc['mean', 'rooms']) if 'rooms' in stats.columns else 3
            user_inputs['rooms'] = st.number_input("Pi√®ces", value=rooms_default, min_value=1, max_value=15, step=1, key=f"rooms_{model_type}")
        
        # Chambres
        if 'bedrooms' in feature_names:
            bedrooms_default = int(stats.loc['mean', 'bedrooms']) if 'bedrooms' in stats.columns else 2
            user_inputs['bedrooms'] = st.number_input("Chambres", value=bedrooms_default, min_value=0, max_value=10, step=1, key=f"bedrooms_{model_type}")
        
        # Salles de bain
        if 'bathrooms' in feature_names:
            bathrooms_default = int(stats.loc['mean', 'bathrooms']) if 'bathrooms' in stats.columns else 1
            user_inputs['bathrooms'] = st.number_input("Salles de bain", value=bathrooms_default, min_value=1, max_value=5, step=1, key=f"bathrooms_{model_type}")
        
        # Parkings
        if 'parkings' in feature_names:
            parkings_default = int(stats.loc['mean', 'parkings']) if 'parkings' in stats.columns else 1
            user_inputs['parkings'] = st.number_input("Parkings", value=parkings_default, min_value=0, max_value=5, step=1, key=f"parkings_{model_type}")
    
    with col2:
        st.markdown("#### ‚≠ê **Qualit√© & √âquipements**")
        
        # √Çge
        if 'age' in feature_names:
            age_default = int(stats.loc['mean', 'age']) if 'age' in stats.columns else 10
            user_inputs['age'] = st.number_input("√Çge (ann√©es)", value=age_default, min_value=0, max_value=100, step=1, key=f"age_{model_type}")
        
        # √âtat
        if 'condition' in feature_names:
            user_inputs['condition'] = st.selectbox(
                "√âtat",
                options=[0, 1, 2, 3, 4],
                format_func=lambda x: ["√Ä r√©nover", "√Ä rafra√Æchir", "Bonne", "Excellente", "Neuf"][x],
                index=2,
                key=f"condition_{model_type}"
            )
        
        # Standing
        if 'finishing' in feature_names:
            user_inputs['finishing'] = st.selectbox(
                "Standing",
                options=[0, 1, 2, 3, 4],
                format_func=lambda x: ["Social", "√âconomique", "Moyen", "Haut", "Tr√®s haut"][x],
                index=2,
                key=f"finishing_{model_type}"
            )
        
        # √âquipements
        if 'elevator' in feature_names:
            user_inputs['elevator'] = 1 if st.checkbox("üè¢ Ascenseur", key=f"elevator_{model_type}") else 0
        
        if 'air_conditioning' in feature_names:
            user_inputs['air_conditioning'] = 1 if st.checkbox("‚ùÑÔ∏è Climatisation", key=f"ac_{model_type}") else 0
        
        if 'central_heating' in feature_names:
            user_inputs['central_heating'] = 1 if st.checkbox("üî• Chauffage", value=True, key=f"heating_{model_type}") else 0
        
        if 'swimming_pool' in feature_names:
            user_inputs['swimming_pool'] = 1 if st.checkbox("üèä Piscine", key=f"pool_{model_type}") else 0
        
        if 'garden' in feature_names:
            user_inputs['garden'] = 1 if st.checkbox("üå≥ Jardin", key=f"garden_{model_type}") else 0
        
        if 'equipped_kitchen' in feature_names:
            user_inputs['equipped_kitchen'] = 1 if st.checkbox("üë®‚Äçüç≥ Cuisine √©quip√©e", value=True, key=f"kitchen_{model_type}") else 0
    
    
    
    # CALCUL EN TEMPS R√âEL
    try:
        # Cr√©er une copie de la ligne sample pour la pr√©diction
        prediction_row = sample_row.copy()
        
        # Mettre √† jour avec les valeurs de l'utilisateur
        for feature, value in user_inputs.items():
            if feature in prediction_row.columns:
                prediction_row[feature] = value
        
        # Supprimer la colonne 'price' si elle existe (c'est la variable cible)
        if 'price' in prediction_row.columns:
            prediction_row = prediction_row.drop('price', axis=1)
        
        # S'assurer que toutes les features attendues sont pr√©sentes
        missing_features = set(feature_names) - set(prediction_row.columns)
        if missing_features:
            st.warning(f"‚ö†Ô∏è Features manquantes: {missing_features}")
            # Ajouter les features manquantes avec des valeurs par d√©faut
            for feature in missing_features:
                prediction_row[feature] = 0
        
        # R√©organiser les colonnes dans l'ordre attendu par le mod√®le
        prediction_row = prediction_row[feature_names]
        
        # Pr√©diction
        predicted_price = model.predict(prediction_row)[0]
        
        # AFFICHAGE DU PRIX
        st.markdown("### üí∞ **Prix Estim√©**")
        
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
            padding: 1.5rem;
            border-radius: 10px;
            text-align: center;
            color: white;
            margin: 1rem 0;
        ">
            <h1 style="margin: 0; font-size: 2.5rem; color: white;">
                {predicted_price:,.0f} TND
            </h1>
        </div>
        """, unsafe_allow_html=True)
        
        # M√©triques rapides
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'size' in user_inputs and user_inputs['size'] > 0:
                price_per_sqm = predicted_price / user_inputs['size']
                st.metric("Prix/m¬≤", f"{price_per_sqm:,.0f} TND")
        
        with col2:
            if 'price' in df_regression.columns:
                market_avg = df_regression['price'].mean()
                diff_pct = ((predicted_price - market_avg) / market_avg) * 100
                st.metric("vs March√©", f"{diff_pct:+.1f}%")
        
        with col3:
            lower = predicted_price * 0.9
            upper = predicted_price * 1.1
            st.metric("Fourchette", f"{lower:,.0f} - {upper:,.0f}")
        
        # Debug info (optionnel)
        with st.expander("üîß Info Debug", expanded=False):
            st.write(f"Features utilis√©es: {len(feature_names)}")
            st.write(f"Valeurs utilisateur: {len(user_inputs)}")
            st.write(f"Shape finale: {prediction_row.shape}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Inputs utilisateur:**")
                for k, v in user_inputs.items():
                    st.write(f"‚Ä¢ {k}: {v}")
            
            with col2:
                st.write("**Features mod√®le:**")
                for i, feature in enumerate(feature_names[:10]):  # Afficher les 10 premi√®res
                    st.write(f"‚Ä¢ {feature}")
                if len(feature_names) > 10:
                    st.write(f"... et {len(feature_names)-10} autres")
    
    except Exception as e:
        st.error(f"‚ùå Erreur dans le calcul: {str(e)}")
        
        # Debug d√©taill√©
        st.write("**Debug d√©taill√©:**")
        st.write(f"‚Ä¢ Mod√®le attend: {len(feature_names)} features")
        st.write(f"‚Ä¢ Features: {feature_names}")
        st.write(f"‚Ä¢ User inputs: {len(user_inputs)} valeurs")
        
        if 'prediction_row' in locals():
            st.write(f"‚Ä¢ Prediction row shape: {prediction_row.shape}")
            st.write(f"‚Ä¢ Prediction row columns: {list(prediction_row.columns)}")


def supervised_learning_section(df, filtered_df):
    st.header("ü§ñ Apprentissage Supervis√© - Pr√©diction des Prix")
    
    if df is None or filtered_df is None or df.empty or filtered_df.empty:
        st.error("‚ùå Aucune donn√©e disponible pour l'apprentissage supervis√©.")
        return
    
    st.markdown("""
    <div class="info-box">
    L'apprentissage supervis√© permet de pr√©dire les prix immobiliers en analysant les relations entre 
    les caract√©ristiques des propri√©t√©s et leurs prix. Trois algorithmes sont disponibles : 
    R√©gression Lin√©aire, Random Forest et XGBoost.
    </div>
    """, unsafe_allow_html=True)
    
    # ============================================
    # SECTION 1: V√âRIFICATION ET PR√âPARATION DES DONN√âES
    # ============================================
    
   
    # ============================================
    # SECTION 2: FILTRES POUR LA MOD√âLISATION
    # ============================================
    
    st.subheader("üîß Configuration du Mod√®le")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Filtre par ville
        if 'city' in df.columns:
            city_options = ["Toutes"] + sorted(df['city'].dropna().unique().tolist())
            selected_city = st.selectbox("Ville pour le mod√®le", city_options, key="regression_city")
            selected_city = None if selected_city == "Toutes" else selected_city
        else:
            selected_city = None
            st.info("Information sur la ville non disponible")
    
    with col2:
        # Filtre par type de propri√©t√©
        if 'property_type' in df.columns:
            property_options = ["Tous"] + sorted(df['property_type'].dropna().unique().tolist())
            selected_property = st.selectbox("Type de propri√©t√© pour le mod√®le", property_options, key="regression_property")
            selected_property = None if selected_property == "Tous" else selected_property
        else:
            selected_property = None
            st.info("Information sur le type de propri√©t√© non disponible")
    
    with col3:
        # Filtre par type de transaction
        if 'transaction' in df.columns:
            transaction_options = ["Toutes"] + sorted(df['transaction'].dropna().unique().tolist())
            selected_transaction = st.selectbox("Type de transaction pour le mod√®le", transaction_options, key="regression_transaction")
            selected_transaction = None if selected_transaction == "Toutes" else selected_transaction
        else:
            selected_transaction = None
            st.info("Information sur le type de transaction non disponible")
    
    # ============================================
    # SECTION 3: S√âLECTION DE L'ALGORITHME
    # ============================================
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        algorithm = st.selectbox(
            "S√©lectionner l'algorithme",
            [
                "R√©gression Lin√©aire", 
                "Random Forest Classification Prix",  # ‚Üê Nouvelle option
                "XGBoost Classification Prix"  # ‚Üê Nouvelle option
            ],
            help="Choisissez l'algorithme d'apprentissage supervis√© √† utiliser"
        )
    
    with col2:
        # Options avanc√©es
        with st.expander("‚öôÔ∏è Options avanc√©es"):
            test_size = st.slider("Taille ensemble test (%)", 10, 40, 20) / 100
            random_state = st.number_input("Graine al√©atoire", value=42, min_value=0)
            
            # Param√®tres sp√©cifiques aux mod√®les
            if algorithm in ["Random Forest", "Comparaison des 3 mod√®les"]:
                n_estimators = st.slider("Nombre d'arbres (Random Forest)", 50, 500, 100)
                max_depth_rf = st.slider("Profondeur max (Random Forest)", 3, 20, 10)
            
            if algorithm in ["XGBoost Classification Prix", "Comparaison des 3 mod√®les"]:
                optimize_params = st.checkbox("Optimiser les hyperparam√®tres", value=False, 
                                                    help="Recherche automatique des meilleurs param√®tres",
                                                    key="xgb_class_optimize")
               
                threshold_low = st.slider("Seuil sous-estimation", 0.5, 0.9, 0.75, 0.05,
                                                key="xgb_class_threshold_low")
                threshold_high = st.slider("Seuil surestimation", 1.1, 1.5, 1.25, 0.05,
                                                key="xgb_class_threshold_high")
            if algorithm in ["Random Forest Classification Prix"]:
                pass
            
    
    
    # ============================================
    # SECTION 4: PR√âPARATION S√âCURIS√âE DES DONN√âES
    # ============================================
    
    def prepare_data_safely(df, selected_city, selected_property, selected_transaction):
        """Pr√©paration s√©curis√©e des donn√©es avec gestion d'erreurs"""
        try:
            # Copier les donn√©es
            df_work = df.copy()
            
            # Appliquer les filtres
            filters_applied = []
            if selected_city is not None:
                df_work = df_work[df_work['city'] == selected_city]
                filters_applied.append(f"Ville: {selected_city}")
            if selected_property is not None:
                df_work = df_work[df_work['property_type'] == selected_property]
                filters_applied.append(f"Type: {selected_property}")
            if selected_transaction is not None:
                df_work = df_work[df_work['transaction'] == selected_transaction]
                filters_applied.append(f"Transaction: {selected_transaction}")
            
            st.info(f"üîç Filtres appliqu√©s: {', '.join(filters_applied) if filters_applied else 'Aucun'}")
            
            # V√©rifier qu'on a assez de donn√©es
            if len(df_work) < 10:
                st.error(f"‚ùå Pas assez de donn√©es apr√®s filtrage ({len(df_work)} observations). Minimum requis: 10")
                return None, None
            
            # Supprimer les lignes avec prix manquant
            df_work = df_work.dropna(subset=['price'])
            
            if len(df_work) < 10:
                st.error(f"‚ùå Pas assez de donn√©es avec prix valides ({len(df_work)} observations). Minimum requis: 10")
                return None, None
            
            # Pr√©parer les donn√©es pour la r√©gression
            df_regression = prepare_data_for_regression(df_work)
            
            # V√©rifier les valeurs manquantes dans les caract√©ristiques
            numeric_cols = df_regression.select_dtypes(include=['number']).columns
            features_cols = [col for col in numeric_cols if col != 'price']
            
            # Afficher les statistiques de pr√©paration
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Observations apr√®s filtrage", len(df_work))
            with col2:
                st.metric("Observations avec prix valides", len(df_regression))
            with col3:
                st.metric("Caract√©ristiques disponibles", len(features_cols))
            
            # Traiter les valeurs manquantes dans les caract√©ristiques
            missing_in_features = df_regression[features_cols].isna().sum()
            if missing_in_features.sum() > 0:
                # st.warning("‚ö†Ô∏è Valeurs manquantes d√©tect√©es dans les caract√©ristiques. Imputation en cours...")
                
                # Imputation simple
                from sklearn.impute import SimpleImputer
                imputer = SimpleImputer(strategy='median')
                df_regression[features_cols] = imputer.fit_transform(df_regression[features_cols])
                
                # st.success("‚úÖ Imputation des valeurs manquantes termin√©e.")
            
            return df_regression, filters_applied
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la pr√©paration des donn√©es: {e}")
            return None, None
    
    # ============================================
    # SECTION 5: EX√âCUTION DES MOD√àLES
    # ============================================
    
    if st.button("üöÄ Entra√Æner le Mod√®le", type="primary"):
        with st.spinner("üîÑ Pr√©paration des donn√©es..."):
            df_regression, filters_applied = prepare_data_safely(
                df, selected_city, selected_property, selected_transaction
            )
        
        if df_regression is None:
            st.stop()
        
        try:
            st.success(f"‚úÖ Donn√©es pr√©par√©es: {len(df_regression)} observations pr√™tes pour l'entra√Ænement")
            
            # ============================================
            # EX√âCUTION SELON L'ALGORITHME S√âLECTIONN√â
            # ============================================
            
            if algorithm == "R√©gression Lin√©aire":
                st.subheader("üìà R√©sultats - R√©gression Lin√©aire")
                
                with st.spinner("üîÑ Entra√Ænement de la r√©gression lin√©aire..."):
                    try:
                        model, importance, metrics = regression_par_segment(
                            df_regression,
                            city=selected_city,
                            property_type=selected_property,
                            transaction=selected_transaction,
                            target_column='price'
                        )
                        
                        # Afficher les m√©triques
                        display_regression_metrics(metrics, "R√©gression Lin√©aire")
                        
                        # NOUVEAU: Affichage d√©taill√© des coefficients
                        display_linear_regression_coefficients(importance, model if hasattr(model, 'intercept_') else None)
                        
                        # Graphique d'importance des caract√©ristiques
                        display_feature_importance(importance, "R√©gression Lin√©aire", "Coefficient")
                        
                        # Capturer et afficher les graphiques matplotlib
                        st.pyplot(plt.gcf())
                        plt.close()
                        
                        # Enlever la variable cible ET les variables cat√©gorielles non d√©sir√©es
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la r√©gression lin√©aire: {e}")
                            
            elif algorithm == "Random Forest Classification Prix":
                st.subheader("üå≤ Classification Random Forest - Estimation des Prix")
                
                # Options sp√©cifiques √† la classification Random Forest
                with st.expander("‚öôÔ∏è Options de Classification Random Forest", expanded=True):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        optimize_params_rf = st.checkbox("Optimiser les hyperparam√®tres", value=False, 
                                                        help="Recherche automatique des meilleurs param√®tres",
                                                        key="rf_class_optimize")
                        test_size_rf = st.slider("Taille ensemble test (%)", 10, 40, 20, 
                                                key="rf_class_test_size") / 100
                    
                    with col2:
                        n_estimators_rf = st.slider("Nombre d'arbres", 50, 500, 200,
                                                key="rf_class_n_estimators")
                        max_depth_rf = st.slider("Profondeur max", 3, 20, 10,
                                                key="rf_class_max_depth")
                        threshold_low_rf = st.slider("Seuil sous-estimation", 0.5, 0.9, 0.75, 0.05,
                                                    key="rf_class_threshold_low")
                        threshold_high_rf = st.slider("Seuil surestimation", 1.1, 1.5, 1.25, 0.05,
                                                    key="rf_class_threshold_high")
                
                with st.spinner("üîÑ Cr√©ation des cat√©gories de prix..."):
                    try:
                        # 1. Cr√©er les cat√©gories de prix
                        st.info("üìä √âtape 1: Cr√©ation des cat√©gories de prix bas√©es sur le march√© local")
                        
                        # Modifier la fonction create_price_category pour utiliser les seuils personnalis√©s
                        def create_price_category_custom(df, grouping_columns=['city', 'property_type', 'transaction'], 
                                                    low_threshold=threshold_low_rf, high_threshold=threshold_high_rf):
                            df_category = df.copy()
                            df_category['price_per_sqm'] = df_category['price'] / df_category['size']
                            
                            # Filtrer les valeurs aberrantes
                            price_per_sqm_median = df_category['price_per_sqm'].median()
                            price_per_sqm_std = df_category['price_per_sqm'].std()
                            lower_bound = price_per_sqm_median - 3 * price_per_sqm_std
                            upper_bound = price_per_sqm_median + 3 * price_per_sqm_std
                            valid_mask = (df_category['price_per_sqm'] >= lower_bound) & (df_category['price_per_sqm'] <= upper_bound)
                            df_category = df_category[valid_mask]
                            
                            # Calculer moyennes par march√© local
                            market_avg_price_per_sqm = df_category.groupby(grouping_columns)['price_per_sqm'].mean().reset_index()
                            market_avg_price_per_sqm.columns = list(grouping_columns) + ['market_avg_price_per_sqm']
                            df_category = df_category.merge(market_avg_price_per_sqm, on=grouping_columns, how='left')
                            df_category['price_ratio'] = df_category['price_per_sqm'] / df_category['market_avg_price_per_sqm']
                            
                            # Cat√©gorisation binaire avec seuils personnalis√©s
                            def categorize_price(ratio):
                                if pd.isna(ratio):
                                    return 1
                                elif ratio < low_threshold or ratio > high_threshold:
                                    return 0  # Mal estim√©
                                else:
                                    return 1  # Bien estim√©
                            
                            df_category['price_category'] = df_category['price_ratio'].apply(categorize_price)
                            category_labels = {0: 'Mal estim√©', 1: 'Bien estim√©'}
                            df_category['price_category_label'] = df_category['price_category'].map(category_labels)
                            
                            return df_category
                        
                        df_with_categories = create_price_category_custom(df_regression)
                        
                        # Afficher les statistiques des cat√©gories
                        category_stats = df_with_categories['price_category'].value_counts().sort_index()
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Observations avec cat√©gories", len(df_with_categories))
                        with col2:
                            mal_estime = category_stats.get(0, 0)
                            st.metric("Mal estim√©", f"{mal_estime} ({mal_estime/len(df_with_categories)*100:.1f}%)")
                        with col3:
                            bien_estime = category_stats.get(1, 0)
                            st.metric("Bien estim√©", f"{bien_estime} ({bien_estime/len(df_with_categories)*100:.1f}%)")
                        
                        st.success("‚úÖ Cat√©gories de prix cr√©√©es avec succ√®s")
                        
                        # 2. Classification Random Forest
                        st.info("üå≤ √âtape 2: Classification avec Random Forest")
                        
                        model, results, feature_importance = random_forest_price_classification(
                            df_with_categories,
                            city=selected_city,
                            property_type=selected_property,
                            transaction=selected_transaction,
                            test_size=test_size_rf,
                            optimize_params=optimize_params_rf,
                            n_estimators=n_estimators_rf,
                            max_depth=max_depth_rf
                        )
                        
                        # 3. Afficher les r√©sultats
                        st.subheader("üìä R√©sultats de la Classification Random Forest")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("üéØ Pr√©cision (Test)", f"{results['test_accuracy']:.3f}")
                        with col2:
                            st.metric("üìà Pr√©cision (Train)", f"{results['train_accuracy']:.3f}")
                        with col3:
                            n_test = len(results['y_test'])
                            st.metric("üî¢ √âchantillon test", n_test)
                        with col4:
                            overfitting = results['train_accuracy'] - results['test_accuracy']
                            if overfitting > 0.1:
                                st.metric("‚ö†Ô∏è Surapprentissage", f"+{overfitting:.3f}", delta_color="off")
                            else:
                                st.metric("‚úÖ G√©n√©ralisation", f"{overfitting:.3f}")
                        
                        # 4. Matrice de confusion
                        st.subheader("üîç Matrice de Confusion")
                        
                        cm = results['confusion_matrix']
                        class_names = results['class_names']
                        
                        # Cr√©er une heatmap avec plotly
                        fig_cm = px.imshow(
                            cm,
                            x=class_names,
                            y=class_names,
                            color_continuous_scale='Greens',  # Vert pour Random Forest
                            text_auto=True,
                            title="Matrice de Confusion - Random Forest",
                            labels=dict(x="Pr√©diction", y="R√©alit√©")
                        )
                        fig_cm.update_layout(width=400, height=400)
                        
                        col1, col2 = st.columns([1, 2])
                        with col1:
                            st.plotly_chart(fig_cm, use_container_width=True)
                        
                        with col2:
                            st.write("**Interpr√©tation de la matrice :**")
                            
                            # Calculs d√©taill√©s
                            tn, fp, fn, tp = cm.ravel()
                            precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0
                            precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
                            recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0
                            recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
                            
                            st.write(f"‚Ä¢ **Vrais Positifs (Bien class√© comme Bien):** {tp}")
                            st.write(f"‚Ä¢ **Vrais N√©gatifs (Mal class√© comme Mal):** {tn}")
                            st.write(f"‚Ä¢ **Faux Positifs (Mal class√© comme Bien):** {fp}")
                            st.write(f"‚Ä¢ **Faux N√©gatifs (Bien class√© comme Mal):** {fn}")
                            
                            st.write("**M√©triques par classe :**")
                            st.write(f"‚Ä¢ **Pr√©cision 'Mal estim√©':** {precision_0:.3f}")
                            st.write(f"‚Ä¢ **Pr√©cision 'Bien estim√©':** {precision_1:.3f}")
                            st.write(f"‚Ä¢ **Rappel 'Mal estim√©':** {recall_0:.3f}")
                            st.write(f"‚Ä¢ **Rappel 'Bien estim√©':** {recall_1:.3f}")
                        
                        # 5. Importance des caract√©ristiques
                        st.subheader("üìà Importance des Caract√©ristiques - Random Forest")
                        
                        # Graphique d'importance
                        top_features = feature_importance.head(10)
                        fig_importance = px.bar(
                            top_features,
                            x='Importance',
                            y='Caract√©ristique',
                            orientation='h',
                            title="Top 10 des caract√©ristiques les plus importantes (Random Forest)",
                            color='Importance',
                            color_continuous_scale='Greens'
                        )
                        fig_importance.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig_importance, use_container_width=True)
                        
                        # Tableau d√©taill√©
                        with st.expander("üìã Tableau complet des caract√©ristiques"):
                            st.dataframe(feature_importance, use_container_width=True)
                        
                        # 6. Rapport de classification d√©taill√©
                        st.subheader("üìã Rapport de Classification D√©taill√©")
                        
                        # Convertir le rapport en DataFrame pour un meilleur affichage
                        report_dict = results['classification_report']
                        report_df = pd.DataFrame(report_dict).transpose()
                        
                        # Formater les valeurs num√©riques
                        for col in ['precision', 'recall', 'f1-score']:
                            if col in report_df.columns:
                                report_df[col] = report_df[col].apply(lambda x: f"{x:.3f}" if isinstance(x, (int, float)) else x)
                        
                        st.dataframe(report_df, use_container_width=True)
                        
                        # 7. Analyse des erreurs sp√©cifique √† Random Forest
                        with st.spinner("Analyse des erreurs en cours..."):
                            try:
                                # Utiliser la version s√©curis√©e
                                error_data, error_types = analyze_misclassified_properties_rf_safe(
                                    df_with_categories, results, model, feature_importance
                                )
                                
                                if len(error_data) > 0:
                                    st.subheader("‚ùå Analyse des Erreurs - Random Forest")
                                    
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        st.metric("Total d'erreurs", len(error_data))
                                        st.metric("Taux d'erreur", f"{len(error_data)/len(results['y_test'])*100:.1f}%")
                                    
                                    with col2:
                                        # Types d'erreurs
                                        if len(error_types) > 0:
                                            for _, row in error_types.iterrows():
                                                st.write(f"‚Ä¢ {row['actual_label']} ‚Üí {row['predicted_label']}: {row['count']} cas")
                                    
                                    # Exemples d'erreurs avec probabilit√©s Random Forest
                                    st.write("**Exemples de propri√©t√©s mal classifi√©es (avec probabilit√©s) :**")
                                    
                                    if len(error_data) > 0:
                                        # Afficher le DataFrame des erreurs
                                        display_cols = ['actual_label', 'predicted_label', 'prob_mal_estime', 'prob_bien_estime', 'confiance']
                                        st.dataframe(error_data[display_cols].round(3), use_container_width=True)
                                        
                                        # Analyse de confiance
                                        st.write("**Analyse de confiance des erreurs :**")
                                        low_confidence = (error_data['confiance'] < 0.6).sum()
                                        high_confidence = (error_data['confiance'] > 0.8).sum()
                                        
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("Erreurs peu confiantes (<60%)", low_confidence)
                                        with col2:
                                            st.metric("Erreurs tr√®s confiantes (>80%)", high_confidence)
                                        with col3:
                                            avg_confidence = error_data['confiance'].mean()
                                            st.metric("Confiance moyenne", f"{avg_confidence:.3f}")
                                        
                                        # Graphique de distribution des confiances
                                        fig_conf = px.histogram(
                                            error_data, 
                                            x='confiance', 
                                            nbins=10,
                                            title="Distribution des niveaux de confiance des erreurs",
                                            labels={'confiance': 'Niveau de confiance', 'count': 'Nombre d\'erreurs'}
                                        )
                                        st.plotly_chart(fig_conf, use_container_width=True)
                                else:
                                    st.success("üéâ Aucune erreur de classification ! Mod√®le parfait.")
                                    
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Impossible d'analyser les erreurs en d√©tail: {e}")
                                st.info("Le mod√®le fonctionne correctement, mais l'analyse d√©taill√©e des erreurs n'est pas disponible.")
                                
                                # Afficher quand m√™me les m√©triques de base
                                total_errors = (results['y_test'] != results['y_test_pred']).sum()
                                error_rate = total_errors / len(results['y_test']) * 100
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("Total d'erreurs (estimation)", total_errors)
                                with col2:
                                    st.metric("Taux d'erreur (estimation)", f"{error_rate:.1f}%")
                        # 8. Sp√©cificit√©s Random Forest
                        st.subheader("üå≤ Sp√©cificit√©s Random Forest")
                        
                        # Information sur les arbres
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Nombre d'arbres", model.n_estimators)
                        with col2:
                            st.metric("Profondeur max", model.max_depth if model.max_depth else "Illimit√©e")
                        with col3:
                            # Calcul de la diversit√© des arbres (estimation)
                            oob_score = getattr(model, 'oob_score_', None)
                            if oob_score:
                                st.metric("Score OOB", f"{oob_score:.3f}")
                            else:
                                st.metric("Features par arbre", f"{model.max_features}")
                        
                        # 9. Recommandations sp√©cifiques Random Forest
                        st.subheader("üí° Recommandations - Random Forest")
                        
                        accuracy = results['test_accuracy']
                        if accuracy > 0.9:
                            st.success("üåü **Excellent mod√®le Random Forest** : Tr√®s haute pr√©cision, excellent pour la production")
                            st.info("üéØ Random Forest excelle avec cette complexit√© de donn√©es")
                        elif accuracy > 0.8:
                            st.success("‚úÖ **Bon mod√®le Random Forest** : Pr√©cision satisfaisante, robuste aux outliers")
                            st.info("üå≤ La nature d'ensemble de Random Forest apporte de la stabilit√©")
                        elif accuracy > 0.7:
                            st.warning("‚ö†Ô∏è **Mod√®le Random Forest acceptable** : Pourrait b√©n√©ficier de plus d'arbres ou de donn√©es")
                        elif accuracy > 0.6:
                            st.warning("üîÑ **Random Forest √† am√©liorer** : Augmenter n_estimators ou optimiser les param√®tres")
                        else:
                            st.error("‚ùå **Random Forest insuffisant** : Revoir la s√©lection des features ou les seuils")
                        
                        # Conseils d'am√©lioration sp√©cifiques Random Forest
                        st.write("**Conseils d'am√©lioration Random Forest :**")
                        st.write("‚Ä¢ Augmenter le nombre d'arbres (n_estimators) pour plus de stabilit√©")
                        st.write("‚Ä¢ Ajuster max_depth pour contr√¥ler le surapprentissage")
                        st.write("‚Ä¢ Utiliser max_features='sqrt' pour plus de diversit√© entre arbres")
                        st.write("‚Ä¢ Consid√©rer min_samples_split et min_samples_leaf pour la r√©gularisation")
                        st.write("‚Ä¢ Random Forest est naturellement robuste aux valeurs aberrantes")
                        
                        # Comparaison avec XGBoost
                        st.info("üîÑ **Comparaison avec XGBoost** : Random Forest est g√©n√©ralement plus stable et moins sensible aux hyperparam√®tres, tandis que XGBoost peut atteindre une pr√©cision l√©g√®rement sup√©rieure avec un bon tuning.")
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la classification Random Forest: {e}")
                        st.info("üí° V√©rifiez que vos donn√©es contiennent les colonnes n√©cessaires (price, size, city, property_type, transaction)")
                        
                        # Debug info pour Random Forest
                        if 'df_regression' in locals():
                            st.write("**Colonnes disponibles dans df_regression:**")
                            st.write(list(df_regression.columns))
                        
                        # Suggestions sp√©cifiques
                        st.write("**Suggestions de d√©bogage Random Forest :**")
                        st.write("‚Ä¢ V√©rifiez que le dataset contient assez d'observations (>100 recommand√©)")
                        st.write("‚Ä¢ Assurez-vous que les seuils ne cr√©ent pas de classes d√©s√©quilibr√©es")
                        st.write("‚Ä¢ Random Forest n√©cessite des variables num√©riques bien encod√©es")
            elif algorithm == "XGBoost Classification Prix":
                st.subheader("üéØ Classification XGBoost - Estimation des Prix")
                
               
                with st.spinner("üîÑ Cr√©ation des cat√©gories de prix..."):
                    try:
                        # 1. Cr√©er les cat√©gories de prix
                        st.info("üìä √âtape 1: Cr√©ation des cat√©gories de prix bas√©es sur le march√© local")
                        
                        # Modifier la fonction create_price_category pour utiliser les seuils personnalis√©s
                        def create_price_category_custom(df, grouping_columns=['city', 'property_type', 'transaction'], 
                                                    low_threshold=threshold_low, high_threshold=threshold_high):
                            df_category = df.copy()
                            df_category['price_per_sqm'] = df_category['price'] / df_category['size']
                            
                            # Filtrer les valeurs aberrantes
                            price_per_sqm_median = df_category['price_per_sqm'].median()
                            price_per_sqm_std = df_category['price_per_sqm'].std()
                            lower_bound = price_per_sqm_median - 3 * price_per_sqm_std
                            upper_bound = price_per_sqm_median + 3 * price_per_sqm_std
                            valid_mask = (df_category['price_per_sqm'] >= lower_bound) & (df_category['price_per_sqm'] <= upper_bound)
                            df_category = df_category[valid_mask]
                            
                            # Calculer moyennes par march√© local
                            market_avg_price_per_sqm = df_category.groupby(grouping_columns)['price_per_sqm'].mean().reset_index()
                            market_avg_price_per_sqm.columns = list(grouping_columns) + ['market_avg_price_per_sqm']
                            df_category = df_category.merge(market_avg_price_per_sqm, on=grouping_columns, how='left')
                            df_category['price_ratio'] = df_category['price_per_sqm'] / df_category['market_avg_price_per_sqm']
                            
                            # Cat√©gorisation binaire avec seuils personnalis√©s
                            def categorize_price(ratio):
                                if pd.isna(ratio):
                                    return 1
                                elif ratio < low_threshold or ratio > high_threshold:
                                    return 0  # Mal estim√©
                                else:
                                    return 1  # Bien estim√©
                            
                            df_category['price_category'] = df_category['price_ratio'].apply(categorize_price)
                            category_labels = {0: 'Mal estim√©', 1: 'Bien estim√©'}
                            df_category['price_category_label'] = df_category['price_category'].map(category_labels)
                            
                            return df_category
                        
                        df_with_categories = create_price_category_custom(df_regression)
                        
                        # Afficher les statistiques des cat√©gories
                        category_stats = df_with_categories['price_category'].value_counts().sort_index()
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Observations avec cat√©gories", len(df_with_categories))
                        with col2:
                            mal_estime = category_stats.get(0, 0)
                            st.metric("Mal estim√©", f"{mal_estime} ({mal_estime/len(df_with_categories)*100:.1f}%)")
                        with col3:
                            bien_estime = category_stats.get(1, 0)
                            st.metric("Bien estim√©", f"{bien_estime} ({bien_estime/len(df_with_categories)*100:.1f}%)")
                        
                        st.success("‚úÖ Cat√©gories de prix cr√©√©es avec succ√®s")
                        
                        # 2. Classification XGBoost
                        st.info("ü§ñ √âtape 2: Classification avec XGBoost")
                        
                        model, results, feature_importance = xgboost_price_classification(
                            df_with_categories,
                            city=selected_city,
                            property_type=selected_property,
                            transaction=selected_transaction,
                            test_size=test_size,
                            optimize_params=optimize_params
                        )
                        
                        # 3. Afficher les r√©sultats
                        st.subheader("üìä R√©sultats de la Classification")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("üéØ Pr√©cision (Test)", f"{results['test_accuracy']:.3f}")
                        with col2:
                            st.metric("üìà Pr√©cision (Train)", f"{results['train_accuracy']:.3f}")
                        with col3:
                            n_test = len(results['y_test'])
                            st.metric("üî¢ √âchantillon test", n_test)
                        with col4:
                            overfitting = results['train_accuracy'] - results['test_accuracy']
                            if overfitting > 0.1:
                                st.metric("‚ö†Ô∏è Surapprentissage", f"+{overfitting:.3f}", delta_color="off")
                            else:
                                st.metric("‚úÖ G√©n√©ralisation", f"{overfitting:.3f}")
                        
                        # 4. Matrice de confusion
                        st.subheader("üîç Matrice de Confusion")
                        
                        cm = results['confusion_matrix']
                        class_names = results['class_names']
                        
                        # Cr√©er une heatmap avec plotly
                        fig_cm = px.imshow(
                            cm,
                            x=class_names,
                            y=class_names,
                            color_continuous_scale='Blues',
                            text_auto=True,
                            title="Matrice de Confusion",
                            labels=dict(x="Pr√©diction", y="R√©alit√©")
                        )
                        fig_cm.update_layout(width=400, height=400)
                        
                        col1, col2 = st.columns([1, 2])
                        with col1:
                            st.plotly_chart(fig_cm, use_container_width=True)
                        
                        with col2:
                            st.write("**Interpr√©tation de la matrice :**")
                            
                            # Calculs d√©taill√©s
                            tn, fp, fn, tp = cm.ravel()
                            precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0
                            precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0
                            recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0
                            recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0
                            
                            st.write(f"‚Ä¢ **Vrais Positifs (Bien class√© comme Bien):** {tp}")
                            st.write(f"‚Ä¢ **Vrais N√©gatifs (Mal class√© comme Mal):** {tn}")
                            st.write(f"‚Ä¢ **Faux Positifs (Mal class√© comme Bien):** {fp}")
                            st.write(f"‚Ä¢ **Faux N√©gatifs (Bien class√© comme Mal):** {fn}")
                            
                            st.write("**M√©triques par classe :**")
                            st.write(f"‚Ä¢ **Pr√©cision 'Mal estim√©':** {precision_0:.3f}")
                            st.write(f"‚Ä¢ **Pr√©cision 'Bien estim√©':** {precision_1:.3f}")
                            st.write(f"‚Ä¢ **Rappel 'Mal estim√©':** {recall_0:.3f}")
                            st.write(f"‚Ä¢ **Rappel 'Bien estim√©':** {recall_1:.3f}")
                        
                        # 5. Importance des caract√©ristiques
                        st.subheader("üìà Importance des Caract√©ristiques")
                        
                        # Graphique d'importance
                        top_features = feature_importance.head(10)
                        fig_importance = px.bar(
                            top_features,
                            x='Importance',
                            y='Caract√©ristique',
                            orientation='h',
                            title="Top 10 des caract√©ristiques les plus importantes",
                            color='Importance',
                            color_continuous_scale='Viridis'
                        )
                        fig_importance.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig_importance, use_container_width=True)
                        
                        # Tableau d√©taill√©
                        with st.expander("üìã Tableau complet des caract√©ristiques"):
                            st.dataframe(feature_importance, use_container_width=True)
                        
                        # 6. Rapport de classification d√©taill√©
                        st.subheader("üìã Rapport de Classification D√©taill√©")
                        
                        # Convertir le rapport en DataFrame pour un meilleur affichage
                        report_dict = results['classification_report']
                        report_df = pd.DataFrame(report_dict).transpose()
                        
                        # Formater les valeurs num√©riques
                        for col in ['precision', 'recall', 'f1-score']:
                            if col in report_df.columns:
                                report_df[col] = report_df[col].apply(lambda x: f"{x:.3f}" if isinstance(x, (int, float)) else x)
                        
                        st.dataframe(report_df, use_container_width=True)
                        
                        # 7. Analyse des erreurs
                        # if st.button("üîç Analyser les Erreurs de Classification", key="xgb_class_analyze_errors"):
                        with st.spinner("Analyse des erreurs en cours..."):
                            error_data, error_types = analyze_misclassified_properties(
                                df_with_categories, results, model, feature_importance
                            )
                            
                            if len(error_data) > 0:
                                st.subheader("‚ùå Analyse des Erreurs")
                                
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.metric("Total d'erreurs", len(error_data))
                                    st.metric("Taux d'erreur", f"{len(error_data)/len(results['y_test'])*100:.1f}%")
                                
                                with col2:
                                    # Types d'erreurs
                                    for _, row in error_types.iterrows():
                                        st.write(f"‚Ä¢ {row['actual_label']} ‚Üí {row['predicted_label']}: {row['count']} cas")
                                
                                # Exemples d'erreurs
                                st.write("**Exemples de propri√©t√©s mal classifi√©es :**")
                                examples = error_data.head(5)[['price', 'size', 'price_ratio', 'market_avg_price_per_sqm', 
                                                            'actual_label', 'predicted_label']]
                                st.dataframe(examples, use_container_width=True)
                            else:
                                st.success("üéâ Aucune erreur de classification ! Mod√®le parfait.")
                        
                        # 8. Recommandations
                        st.subheader("üí° Recommandations")
                        
                        accuracy = results['test_accuracy']
                        if accuracy > 0.9:
                            st.success("üåü **Excellent mod√®le** : Tr√®s haute pr√©cision, d√©ployable en production")
                        elif accuracy > 0.8:
                            st.success("‚úÖ **Bon mod√®le** : Pr√©cision satisfaisante, peut √™tre utilis√© avec confiance")
                        elif accuracy > 0.7:
                            st.warning("‚ö†Ô∏è **Mod√®le acceptable** : Pr√©cision correcte, mais des am√©liorations sont possibles")
                        elif accuracy > 0.6:
                            st.warning("üîÑ **Mod√®le √† am√©liorer** : Pr√©cision faible, revoir les donn√©es ou les param√®tres")
                        else:
                            st.error("‚ùå **Mod√®le insuffisant** : Pr√©cision tr√®s faible, revoir compl√®tement l'approche")
                        
                        # Conseils d'am√©lioration
                        st.write("**Conseils d'am√©lioration :**")
                        st.write("‚Ä¢ Ajuster les seuils de cat√©gorisation selon votre connaissance du march√©")
                        st.write("‚Ä¢ Ajouter plus de donn√©es pour les segments sous-repr√©sent√©s")
                        st.write("‚Ä¢ Consid√©rer des variables suppl√©mentaires (localisation pr√©cise, √©quipements...)")
                        st.write("‚Ä¢ Essayer l'optimisation des hyperparam√®tres si non activ√©e")
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la classification: {e}")
                        st.info("üí° V√©rifiez que vos donn√©es contiennent les colonnes n√©cessaires (price, size, city, property_type, transaction)")
            # else:  # Comparaison des 3 mod√®les
            #     st.subheader("üîÑ Comparaison des 3 Mod√®les")
                
            #     results = {}
            #     errors = {}
                
            #     # R√©gression Lin√©aire
            #     with st.spinner("üîÑ Test R√©gression Lin√©aire..."):
            #         try:
            #             model_lr, importance_lr, metrics_lr = regression_par_segment(
            #                 df_regression, selected_city, selected_property, selected_transaction
            #             )
            #             results['R√©gression Lin√©aire'] = {
            #                 'model': model_lr,
            #                 'importance': importance_lr,
            #                 'metrics': metrics_lr,
            #                 'r2': metrics_lr['test_r2'],
            #                 'rmse': metrics_lr['test_rmse'],
            #                 'mae': metrics_lr['test_mae']
            #             }
            #             plt.close()  # Fermer les graphiques matplotlib
            #         except Exception as e:
            #             errors['R√©gression Lin√©aire'] = str(e)
                
            #     # Random Forest
            #     with st.spinner("üîÑ Test Random Forest..."):
            #         try:
            #             model_rf, importance_rf, metrics_rf = random_forest_par_segment(
            #                 df_regression, selected_city, selected_property, selected_transaction,
            #                 n_estimators=n_estimators if 'n_estimators' in locals() else 100,
            #                 max_depth=max_depth_rf if 'max_depth_rf' in locals() else None
            #             )
            #             results['Random Forest'] = {
            #                 'model': model_rf,
            #                 'importance': importance_rf,
            #                 'metrics': metrics_rf,
            #                 'r2': metrics_rf['test_r2'],
            #                 'rmse': metrics_rf['test_rmse'],
            #                 'mae': metrics_rf['test_mae']
            #             }
            #             plt.close()  # Fermer les graphiques matplotlib
            #         except Exception as e:
            #             errors['Random Forest'] = str(e)
                
            #     # XGBoost
            #     with st.spinner("üîÑ Test XGBoost..."):
            #         try:
            #             model_xgb, importance_xgb, r2_xgb = xgboost_simple(
            #                 df_regression, selected_city, selected_property, selected_transaction
            #             )
            #             results['XGBoost'] = {
            #                 'model': model_xgb,
            #                 'importance': importance_xgb,
            #                 'r2': r2_xgb,
            #                 'rmse': 'N/A',  # XGBoost simple ne retourne que R2
            #                 'mae': 'N/A'
            #             }
            #             plt.close()  # Fermer les graphiques matplotlib
            #         except Exception as e:
            #             errors['XGBoost'] = str(e)
                
            #     # Afficher les erreurs s'il y en a
            #     if errors:
            #         st.warning("‚ö†Ô∏è Certains mod√®les ont √©chou√©:")
            #         for model_name, error in errors.items():
            #             st.error(f"‚ùå {model_name}: {error}")
                
            #     # Afficher la comparaison si on a au moins un r√©sultat
            #     if results:
            #         display_model_comparison(results)
            #     else:
            #         st.error("‚ùå Aucun mod√®le n'a pu √™tre entra√Æn√© avec succ√®s.")
        
        except Exception as e:
            st.error(f"‚ùå Erreur g√©n√©rale lors de l'entra√Ænement: {e}")
            st.info("üí° V√©rifiez la qualit√© de vos donn√©es et r√©essayez avec des filtres diff√©rents.")

def display_regression_metrics(metrics, model_name):
    """Afficher les m√©triques de r√©gression de mani√®re claire"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä R¬≤ Test", f"{metrics['test_r2']:.4f}")
    with col2:
        st.metric("üìà R¬≤ Train", f"{metrics['train_r2']:.4f}")
    with col3:
        st.metric("üìè RMSE", f"{metrics['test_rmse']:.0f}")
    with col4:
        st.metric("üìê MAE", f"{metrics['test_mae']:.0f}")
    
    # √âvaluation qualitative
    performance = get_performance_label(metrics['test_r2'])
    overfitting = check_overfitting(metrics['train_r2'], metrics['test_r2'])
    
    col1, col2 = st.columns(2)
    with col1:
        if metrics['test_r2'] > 0.7:
            st.success(f"‚úÖ {performance}")
        elif metrics['test_r2'] > 0.5:
            st.info(f"üëç {performance}")
        elif metrics['test_r2'] > 0.3:
            st.warning(f"‚ö†Ô∏è {performance}")
        else:
            st.error(f"‚ùå {performance}")
    
    with col2:
        if overfitting:
            st.warning("‚ö†Ô∏è Surapprentissage d√©tect√©")
        else:
            st.success("‚úÖ Pas de surapprentissage")

def display_feature_importance(importance_df, model_name, value_col):
    """Afficher l'importance des caract√©ristiques avec Plotly"""
    st.subheader(f"üìä Importance des Caract√©ristiques - {model_name}")
    
    # Prendre les 10 plus importantes
    top_features = importance_df.head(10).copy()
    
    # Cr√©er le graphique Plotly
    if value_col == "Coefficient":
        # Pour la r√©gression lin√©aire, utiliser une √©chelle de couleur divergente
        fig = px.bar(
            top_features,
            x=value_col,
            y='Caract√©ristique',
            orientation='h',
            title=f"Top 10 des caract√©ristiques - {model_name}",
            color=value_col,
            color_continuous_scale='RdBu_r',
            color_continuous_midpoint=0
        )
    else:
        # Pour les autres mod√®les, utiliser une √©chelle normale
        fig = px.bar(
            top_features,
            x=value_col,
            y='Caract√©ristique',
            orientation='h',
            title=f"Top 10 des caract√©ristiques - {model_name}",
            color=value_col,
            color_continuous_scale='Viridis'
        )
    
    fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
    st.plotly_chart(fig, use_container_width=True)
    
    # Tableau d√©taill√©
    with st.expander("üìã D√©tail de toutes les caract√©ristiques"):
        st.dataframe(importance_df, use_container_width=True)

def display_model_comparison(results):
    """Afficher la comparaison des mod√®les"""
    st.subheader("üèÜ Comparaison des Mod√®les")
    
    # Cr√©er le tableau de comparaison
    comparison_data = []
    for model_name, result in results.items():
        comparison_data.append({
            'Mod√®le': model_name,
            'R¬≤ Score': f"{result['r2']:.4f}",
            'RMSE': f"{result['rmse']:.0f}" if result['rmse'] != 'N/A' else 'N/A',
            'MAE': f"{result['mae']:.0f}" if result['mae'] != 'N/A' else 'N/A',
            'Performance': get_performance_label(result['r2'])
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    st.dataframe(comparison_df, use_container_width=True)
    
    # Identifier le meilleur mod√®le
    best_model = max(results.items(), key=lambda x: x[1]['r2'])
    st.success(f"üèÜ **Meilleur mod√®le:** {best_model[0]} (R¬≤ = {best_model[1]['r2']:.4f})")
    
    # Graphique de comparaison
    r2_scores = [result['r2'] for result in results.values()]
    model_names = list(results.keys())
    
    fig = px.bar(
        x=model_names,
        y=r2_scores,
        title="Comparaison des scores R¬≤",
        labels={'x': 'Mod√®le', 'y': 'Score R¬≤'},
        color=r2_scores,
        color_continuous_scale='Viridis'
    )
    fig.update_layout(showlegend=False)
    st.plotly_chart(fig, use_container_width=True)
    
    # Recommandations
    st.subheader("üí° Recommandations")
    
    best_r2 = best_model[1]['r2']
    if best_r2 > 0.8:
        st.success("‚úÖ Excellente performance ! Le mod√®le est tr√®s fiable pour la pr√©diction.")
    elif best_r2 > 0.6:
        st.info("üëç Bonne performance. Le mod√®le peut √™tre utilis√© avec confiance.")
    elif best_r2 > 0.4:
        st.warning("‚ö†Ô∏è Performance mod√©r√©e. Consid√©rez l'ajout de plus de donn√©es ou de caract√©ristiques.")
    else:
        st.error("‚ùå Performance faible. Revoyez la s√©lection des caract√©ristiques ou la qualit√© des donn√©es.")

def display_linear_regression_coefficients(importance_df, model=None):
    """Afficher les coefficients de la r√©gression lin√©aire de mani√®re d√©taill√©e"""
    st.subheader("üî¢ Coefficients de la R√©gression Lin√©aire")
    
    # Trier par valeur absolue d√©croissante pour voir les plus importants
    coeffs_sorted = importance_df.copy()
    coeffs_sorted['Coefficient_Abs'] = coeffs_sorted['Coefficient'].abs()
    coeffs_sorted = coeffs_sorted.sort_values('Coefficient_Abs', ascending=False)
    
    # Affichage en colonnes
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.write("### üìä √âquation de R√©gression")
        
        # Construire l'√©quation
        equation_parts = []
        for idx, row in coeffs_sorted.head(10).iterrows():  # Top 10 pour lisibilit√©
            coeff = row['Coefficient']
            feature = row['Caract√©ristique']
            
            if coeff > 0:
                sign = "+" if len(equation_parts) > 0 else ""
                equation_parts.append(f"{sign} {coeff:.3f} √ó {feature}")
            else:
                equation_parts.append(f"- {abs(coeff):.3f} √ó {feature}")
        
        # Afficher l'√©quation
        if equation_parts:
            equation = "**Prix** = " + " ".join(equation_parts[:5])  # Limiter √† 5 termes
            if len(equation_parts) > 5:
                equation += " + ..."
            
            if model and hasattr(model, 'intercept_'):
                equation += f" + {model.intercept_:.2f}"
            
            st.markdown(equation)
        
        # Tableau d√©taill√© des coefficients
        st.write("### üìã Tableau D√©taill√© des Coefficients")
        
        # Cr√©er un DataFrame enrichi pour l'affichage
        display_coeffs = coeffs_sorted.copy()
        display_coeffs['Impact'] = display_coeffs['Coefficient'].apply(get_coefficient_impact)
        display_coeffs['Coefficient_Format√©'] = display_coeffs['Coefficient'].apply(lambda x: f"{x:+.4f}")
        display_coeffs['Interpr√©tation'] = display_coeffs.apply(get_coefficient_interpretation, axis=1)
        
        # Afficher le tableau
        st.dataframe(
            display_coeffs[['Caract√©ristique', 'Coefficient_Format√©', 'Impact', 'Interpr√©tation']],
            use_container_width=True,
            hide_index=True
        )
    
    with col2:
        st.write("### üéØ Analyse des Impacts")
        
        # Statistiques sur les coefficients
        positive_coeffs = coeffs_sorted[coeffs_sorted['Coefficient'] > 0]
        negative_coeffs = coeffs_sorted[coeffs_sorted['Coefficient'] < 0]
        
        st.metric("üìà Variables positives", len(positive_coeffs))
        st.metric("üìâ Variables n√©gatives", len(negative_coeffs))
        
        if len(positive_coeffs) > 0:
            max_positive = positive_coeffs.iloc[0]
            st.success(f"üîù Plus fort impact positif:\n**{max_positive['Caract√©ristique']}**\n(+{max_positive['Coefficient']:.3f})")
        
        if len(negative_coeffs) > 0:
            max_negative = negative_coeffs.iloc[0]
            st.error(f"üîª Plus fort impact n√©gatif:\n**{max_negative['Caract√©ristique']}**\n({max_negative['Coefficient']:.3f})")
        
        # Guide d'interpr√©tation
        st.write("### üí° Guide d'Interpr√©tation")
        st.info("""
        **Coefficient positif (+)** : 
        Augmente le prix
        
        **Coefficient n√©gatif (-)** : 
        Diminue le prix
        
        **Valeur absolue** : 
        Force de l'impact
        """)
    
    # Graphique des coefficients avec interpretation
    st.write("### üìä Visualisation des Coefficients")
    
    # Cr√©er un graphique avec des couleurs selon l'impact
    top_coeffs = coeffs_sorted.head(15)  # Top 15 pour la visualisation
    
    colors = ['green' if x > 0 else 'red' for x in top_coeffs['Coefficient']]
    
    fig = px.bar(
        top_coeffs,
        x='Coefficient',
        y='Caract√©ristique',
        orientation='h',
        title="Impact des Caract√©ristiques sur le Prix (Top 15)",
        color='Coefficient',
        color_continuous_scale='RdBu_r',
        color_continuous_midpoint=0,
        hover_data={'Coefficient': ':.4f'}
    )
    
    # Ajouter une ligne verticale √† z√©ro
    fig.add_vline(x=0, line_dash="dash", line_color="black", line_width=1)
    
    # Annotations pour clarification
    fig.add_annotation(
        x=top_coeffs['Coefficient'].max() * 0.7,
        y=len(top_coeffs) - 1,
        text="Augmente le prix",
        showarrow=False,
        font=dict(color="green", size=12)
    )
    
    if top_coeffs['Coefficient'].min() < 0:
        fig.add_annotation(
            x=top_coeffs['Coefficient'].min() * 0.7,
            y=len(top_coeffs) - 1,
            text="Diminue le prix",
            showarrow=False,
            font=dict(color="red", size=12)
        )
    
    fig.update_layout(
        height=600,
        yaxis={'categoryorder': 'total ascending'},
        xaxis_title="Coefficient de R√©gression",
        yaxis_title="Caract√©ristiques"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Analyse contextuelle pour l'immobilier
    st.write("### üè† Analyse Contextuelle Immobilier")
    
    # Identifier les variables immobili√®res classiques et leurs impacts
    real_estate_analysis = analyze_real_estate_coefficients(coeffs_sorted)
    
    if real_estate_analysis:
        for category, analysis in real_estate_analysis.items():
            with st.expander(f"üìä {category}", expanded=False):
                st.write(analysis)

def get_coefficient_impact(coeff):
    """D√©terminer l'impact d'un coefficient"""
    abs_coeff = abs(coeff)
    if abs_coeff > 1000:
        return "üî• Tr√®s Fort"
    elif abs_coeff > 500:
        return "‚ö° Fort"
    elif abs_coeff > 100:
        return "üìà Mod√©r√©"
    elif abs_coeff > 10:
        return "üí® Faible"
    else:
        return "üî∏ Tr√®s Faible"

def get_coefficient_interpretation(row):
    """Interpr√©ter un coefficient dans le contexte immobilier"""
    coeff = row['Coefficient']
    feature = row['Caract√©ristique'].lower()
    
    if coeff > 0:
        direction = "augmente"
        emoji = "üìà"
    else:
        direction = "diminue"
        emoji = "üìâ"
    
    # Interpr√©tations sp√©cifiques √† l'immobilier
    if 'size' in feature or 'surface' in feature:
        return f"{emoji} Chaque m¬≤ suppl√©mentaire {direction} le prix de {abs(coeff):.0f} TND"
    elif 'room' in feature or 'piece' in feature:
        return f"{emoji} Chaque pi√®ce suppl√©mentaire {direction} le prix de {abs(coeff):.0f} TND"
    elif 'age' in feature or 'ancien' in feature:
        return f"{emoji} Chaque ann√©e d'anciennet√© {direction} le prix de {abs(coeff):.0f} TND"
    elif 'bathroom' in feature or 'salle' in feature:
        return f"{emoji} Chaque salle de bain suppl√©mentaire {direction} le prix de {abs(coeff):.0f} TND"
    elif 'parking' in feature:
        return f"{emoji} Chaque place de parking {direction} le prix de {abs(coeff):.0f} TND"
    elif 'elevator' in feature or 'ascenseur' in feature:
        return f"{emoji} La pr√©sence d'un ascenseur {direction} le prix de {abs(coeff):.0f} TND"
    elif 'condition' in feature or 'etat' in feature:
        return f"{emoji} L'am√©lioration de l'√©tat {direction} le prix de {abs(coeff):.0f} TND"
    elif 'finishing' in feature or 'finition' in feature:
        return f"{emoji} L'am√©lioration du standing {direction} le prix de {abs(coeff):.0f} TND"
    else:
        return f"{emoji} Cette caract√©ristique {direction} le prix de {abs(coeff):.0f} TND"

def analyze_real_estate_coefficients(coeffs_df):
    """Analyser les coefficients dans le contexte immobilier"""
    analysis = {}
    
    # Identifier les diff√©rentes cat√©gories
    size_vars = coeffs_df[coeffs_df['Caract√©ristique'].str.contains('size|surface', case=False, na=False)]
    room_vars = coeffs_df[coeffs_df['Caract√©ristique'].str.contains('room|piece|bedroom|bathroom', case=False, na=False)]
    age_vars = coeffs_df[coeffs_df['Caract√©ristique'].str.contains('age|year|ancien', case=False, na=False)]
    amenity_vars = coeffs_df[coeffs_df['Caract√©ristique'].str.contains('elevator|parking|garden|pool|kitchen', case=False, na=False)]
    quality_vars = coeffs_df[coeffs_df['Caract√©ristique'].str.contains('condition|finishing|standing', case=False, na=False)]
    
    # Analyse de la superficie
    if not size_vars.empty:
        size_coeff = size_vars.iloc[0]['Coefficient']
        if size_coeff > 0:
            analysis['üìê Impact de la Superficie'] = f"""
            ‚úÖ **Coefficient positif**: {size_coeff:.2f} TND/m¬≤
            
            üìä **Interpr√©tation**: Chaque m√®tre carr√© suppl√©mentaire augmente le prix de {size_coeff:.0f} TND.
            
            üí° **Insight Business**: La superficie est un facteur valorisant, ce qui est normal sur le march√© immobilier.
            """
        else:
            analysis['üìê Impact de la Superficie'] = f"""
            ‚ö†Ô∏è **Coefficient n√©gatif**: {size_coeff:.2f} TND/m¬≤
            
            ü§î **Attention**: R√©sultat contre-intuitif qui peut indiquer un probl√®me dans les donn√©es ou une corr√©lation avec d'autres variables.
            """
    
    # Analyse des pi√®ces
    if not room_vars.empty:
        room_analysis = "üè† **Impact du Nombre de Pi√®ces**:\n\n"
        for _, room_var in room_vars.iterrows():
            coeff = room_var['Coefficient']
            feature = room_var['Caract√©ristique']
            if coeff > 0:
                room_analysis += f"‚úÖ {feature}: +{coeff:.0f} TND par pi√®ce suppl√©mentaire\n"
            else:
                room_analysis += f"‚ö†Ô∏è {feature}: {coeff:.0f} TND (impact n√©gatif)\n"
        
        analysis['üè† Configuration des Pi√®ces'] = room_analysis
    
    # Analyse de l'√¢ge
    if not age_vars.empty:
        age_coeff = age_vars.iloc[0]['Coefficient']
        if age_coeff < 0:
            analysis['‚è∞ Impact de l\'√Çge'] = f"""
            ‚úÖ **D√©pr√©ciation normale**: {age_coeff:.2f} TND/an
            
            üìä **Interpr√©tation**: Chaque ann√©e d'anciennet√© r√©duit le prix de {abs(age_coeff):.0f} TND.
            
            üí° **Insight**: D√©pr√©ciation annuelle de {abs(age_coeff):.0f} TND, soit {abs(age_coeff)*10:.0f} TND sur 10 ans.
            """
        else:
            analysis['‚è∞ Impact de l\'√Çge'] = f"""
            ü§î **Coefficient positif**: {age_coeff:.2f} TND/an
            
            ‚ö†Ô∏è **Attention**: R√©sultat contre-intuitif. Possible effet "vintage" ou corr√©lation avec la localisation.
            """
    
    # Analyse des √©quipements
    if not amenity_vars.empty:
        amenity_analysis = "‚ö° **Impact des √âquipements**:\n\n"
        for _, amenity in amenity_vars.iterrows():
            coeff = amenity['Coefficient']
            feature = amenity['Caract√©ristique']
            if coeff > 0:
                amenity_analysis += f"‚úÖ {feature}: +{coeff:.0f} TND\n"
            else:
                amenity_analysis += f"‚ùå {feature}: {coeff:.0f} TND\n"
        
        analysis['‚ö° √âquipements et Commodit√©s'] = amenity_analysis
    
    # Analyse de la qualit√©
    if not quality_vars.empty:
        quality_analysis = "‚ú® **Impact de la Qualit√©**:\n\n"
        for _, quality in quality_vars.iterrows():
            coeff = quality['Coefficient']
            feature = quality['Caract√©ristique']
            quality_analysis += f"‚Ä¢ {feature}: {coeff:+.0f} TND par niveau de qualit√©\n"
        
        analysis['‚ú® Qualit√© et Finitions'] = quality_analysis
    
    return analysis

def check_overfitting(train_r2, test_r2):
    """V√©rifier s'il y a du surapprentissage"""
    return (train_r2 - test_r2) > 0.1

# ============================================
# SECTION D'AIDE POUR L'INTERPR√âTATION
# ============================================

def add_supervised_learning_help():
    """Section d'aide pour l'apprentissage supervis√©"""
    with st.expander("üí° Guide d'Interpr√©tation - Apprentissage Supervis√©", expanded=False):
        st.markdown("""
        ## üìà M√©triques de Performance
        
        ### **R¬≤ (Coefficient de D√©termination)**
        - **0.8-1.0** : Excellent mod√®le, pr√©dictions tr√®s fiables
        - **0.6-0.8** : Bon mod√®le, pr√©dictions fiables
        - **0.4-0.6** : Mod√®le mod√©r√©, pr√©dictions acceptables
        - **0.2-0.4** : Mod√®le faible, pr√©dictions peu fiables
        - **< 0.2** : Mod√®le tr√®s faible, √† revoir compl√®tement
        
        ### **RMSE (Root Mean Square Error)**
        - Erreur moyenne en TND
        - Plus faible = mieux
        - √Ä comparer au prix moyen des biens
        
        ### **MAE (Mean Absolute Error)**
        - Erreur absolue moyenne en TND
        - Plus faible = mieux
        - Plus robuste aux valeurs aberrantes que RMSE
        
        ---
        
        ## ü§ñ Algorithmes
        
        ### **üìà R√©gression Lin√©aire**
        **Avantages :**
        - Simple et interpr√©table
        - Rapide √† entra√Æner
        - Coefficients indiquent l'impact de chaque variable
        
        **Inconv√©nients :**
        - Suppose des relations lin√©aires
        - Sensible aux valeurs aberrantes
        - Peut sous-performer sur des donn√©es complexes
        
        ### **üå≤ Random Forest**
        **Avantages :**
        - G√®re les relations non-lin√©aires
        - Robuste aux valeurs aberrantes
        - Fournit l'importance des variables
        - √âvite souvent le surapprentissage
        
        **Inconv√©nients :**
        - Moins interpr√©table
        - Plus lent √† entra√Æner
        - Peut sur-ajuster avec peu de donn√©es
        
        ### **‚ö° XGBoost**
        **Avantages :**
        - Tr√®s haute performance
        - G√®re bien les donn√©es manquantes
        - Optimisations avanc√©es
        
        **Inconv√©nients :**
        - Complexe √† param√©trer
        - Risque de surapprentissage
        - Moins interpr√©table
        
        ---
        
        ## üö® Signaux d'Alerte
        
        - **Surapprentissage** : R¬≤ train >> R¬≤ test (diff√©rence > 0.1)
        - **Sous-apprentissage** : R¬≤ train et test tr√®s faibles
        - **Donn√©es insuffisantes** : < 50 observations
        - **Caract√©ristiques peu informatives** : Toutes les importances similaires
        
        ---
        
        ## üí° Conseils d'Am√©lioration
        
        1. **Plus de donn√©es** : Augmenter la taille de l'√©chantillon
        2. **Ing√©nierie des caract√©ristiques** : Cr√©er de nouvelles variables
        3. **Nettoyage des donn√©es** : √âliminer les outliers
        4. **Segmentation** : Entra√Æner des mod√®les par segment (ville, type)
        5. **Validation crois√©e** : Tester sur plusieurs √©chantillons
        """)
def get_performance_label(r2_score):
    """Obtenir un label de performance bas√© sur le score R¬≤"""
    if r2_score > 0.8:
        return "Excellent"
    elif r2_score > 0.6:
        return "Bon"
    elif r2_score > 0.4:
        return "Mod√©r√©"
    elif r2_score > 0.2:
        return "Faible"
    else:
        return "Tr√®s faible"

def check_overfitting(train_r2, test_r2):
    """V√©rifier s'il y a du surapprentissage"""
    return (train_r2 - test_r2) > 0.1


# Version compl√®te avec aide
def supervised_learning_section_complete(df, filtered_df):
    """Version compl√®te avec section d'aide"""
    supervised_learning_section(df, filtered_df)
    add_supervised_learning_help()
# Version compl√®te avec aide


    
def unsupervised_learning_section(df, filtered_df):
    st.header("ü§ñ Apprentissage Non Supervis√© - Clustering")
    
    if df is None or filtered_df is None or df.empty or filtered_df.empty:
        st.error("Aucune donn√©e disponible pour l'apprentissage non supervis√©.")
        return
    
    st.markdown("""
    <div class="info-box">
    L'apprentissage non supervis√© permet de d√©couvrir des structures cach√©es dans les donn√©es sans avoir de variable cible.
    Nous utiliserons trois algorithmes de clustering : K-Means, DBSCAN et CAH (Classification Ascendante Hi√©rarchique).
    </div>
    """, unsafe_allow_html=True)
    
    # ============================================
    # SECTION 1: FILTRES ET S√âLECTION DES DONN√âES
    # ============================================
    
    st.subheader("üîç Filtres et S√©lection des Donn√©es")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Filtre par ville
        if 'city' in filtered_df.columns:
            city_options = ["Toutes"] + sorted(filtered_df['city'].dropna().unique().tolist())
            selected_city = st.selectbox("Ville", city_options, key="clustering_city")
            selected_city = None if selected_city == "Toutes" else selected_city
        else:
            selected_city = None
            st.info("Information sur la ville non disponible")
    
    with col2:
        # Filtre par type de propri√©t√©
        if 'property_type' in filtered_df.columns:
            property_options = ["Tous"] + sorted(filtered_df['property_type'].dropna().unique().tolist())
            selected_property = st.selectbox("Type de propri√©t√©", property_options, key="clustering_property")
            selected_property = None if selected_property == "Tous" else selected_property
        else:
            selected_property = None
            st.info("Information sur le type de propri√©t√© non disponible")
    
    with col3:
        # Filtre par type de transaction
        if 'transaction' in filtered_df.columns:
            transaction_options = ["Toutes"] + sorted(filtered_df['transaction'].dropna().unique().tolist())
            selected_transaction = st.selectbox("Type de transaction", transaction_options, key="clustering_transaction")
            selected_transaction = None if selected_transaction == "Toutes" else selected_transaction
        else:
            selected_transaction = None
            st.info("Information sur le type de transaction non disponible")
    
    # Appliquer les filtres
    df_for_clustering = filtered_df.copy()
    filter_applied = False
    
    if selected_city is not None:
        df_for_clustering = df_for_clustering[df_for_clustering['city'] == selected_city]
        filter_applied = True
    if selected_property is not None:
        df_for_clustering = df_for_clustering[df_for_clustering['property_type'] == selected_property]
        filter_applied = True
    if selected_transaction is not None:
        df_for_clustering = df_for_clustering[df_for_clustering['transaction'] == selected_transaction]
        filter_applied = True
    
    # Afficher les informations sur le filtrage
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Observations avant filtrage", len(filtered_df))
    with col2:
        st.metric("Observations apr√®s filtrage", len(df_for_clustering))
    with col3:
        reduction_pct = ((len(filtered_df) - len(df_for_clustering)) / len(filtered_df)) * 100 if len(filtered_df) > 0 else 0
        st.metric("R√©duction", f"-{reduction_pct:.1f}%")
    
    # V√©rifier qu'on a assez de donn√©es
    if len(df_for_clustering) < 10:
        st.warning("‚ö†Ô∏è Pas assez de donn√©es pour l'analyse de clustering (minimum 10 observations). Veuillez √©largir les filtres.")
        return
    
    # ============================================
    # SECTION 2: S√âLECTION DES CARACT√âRISTIQUES
    # ============================================
    
    st.subheader("üìä S√©lection des Caract√©ristiques")
    
    # Obtenir les colonnes num√©riques disponibles
    numeric_cols = df_for_clustering.select_dtypes(include=['number']).columns.tolist()
    exclude_cols = ['date', 'source', 'neighborhood', 'suffix', 'listing_price', 'price_ttc', 'construction_year']
    available_features = [col for col in numeric_cols if col not in exclude_cols]
    
    if not available_features:
        st.error("‚ùå Aucune caract√©ristique num√©rique disponible pour le clustering.")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        selected_features = st.multiselect(
            "S√©lectionner les caract√©ristiques pour le clustering",
            available_features,
            default=available_features[:6] if len(available_features) >= 6 else available_features,
            help="Choisissez les caract√©ristiques qui seront utilis√©es pour identifier les groupes de propri√©t√©s similaires"
        )
    
    with col2:
        st.write("**Caract√©ristiques disponibles:**")
        st.write(f"‚Ä¢ Total: {len(available_features)}")
        st.write(f"‚Ä¢ S√©lectionn√©es: {len(selected_features)}")
        if selected_features:
            st.write("**Liste s√©lectionn√©e:**")
            for feature in selected_features:
                st.write(f"- {feature}")
    
    if not selected_features:
        st.warning("‚ö†Ô∏è Veuillez s√©lectionner au moins une caract√©ristique pour continuer.")
        return
    
    # ============================================
    # SECTION 3: PARAM√àTRES DES ALGORITHMES
    # ============================================
    
    st.subheader("‚öôÔ∏è Configuration des Algorithmes")
    
    col1, col2 = st.columns(2)
    
    with col1:
        algorithm = st.selectbox(
            "Algorithme de clustering",
            ["K-Means", "DBSCAN", "CAH (Classification Ascendante Hi√©rarchique)", "Comparaison des 3 m√©thodes"],
            help="Choisissez l'algorithme de clustering √† utiliser"
        )
    
    with col2:
        n_components_pca = st.slider(
            "Nombre de composantes PCA pour visualisation",
            min_value=2,
            max_value=min(len(selected_features), 10),
            value=min(3, len(selected_features)),
            help="Nombre de composantes principales √† conserver pour la visualisation"
        )
    
    # Param√®tres sp√©cifiques selon l'algorithme
    st.write("**Param√®tres sp√©cifiques:**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Param√®tres K-Means
        if algorithm in ["K-Means", "Comparaison des 3 m√©thodes"]:
            st.write("üîµ **K-Means**")
            max_clusters = min(10, len(df_for_clustering) // 5)
            n_clusters_range = st.slider(
                "Nombre de clusters √† tester",
                min_value=2,
                max_value=max_clusters,
                value=(2, min(8, max_clusters)),
                key="kmeans_range"
            )
    
    with col2:
        # Param√®tres DBSCAN
        if algorithm in ["DBSCAN", "Comparaison des 3 m√©thodes"]:
            st.write("üî¥ **DBSCAN**")
            eps_range = st.slider(
                "Range eps",
                min_value=0.1,
                max_value=5.0,
                value=(0.3, 2.0),
                step=0.1,
                key="dbscan_eps"
            )
            min_samples_range = st.slider(
                "Range min_samples",
                min_value=2,
                max_value=20,
                value=(3, 10),
                key="dbscan_samples"
            )
    
    with col3:
        # Param√®tres CAH
        if algorithm in ["CAH (Classification Ascendante Hi√©rarchique)", "Comparaison des 3 m√©thodes"]:
            st.write("üü¢ **CAH**")
            linkage_method = st.selectbox(
                "M√©thode de liaison",
                ["ward", "complete", "average", "single"],
                index=0,
                key="cah_linkage"
            )
            max_clusters_cah = st.slider(
                "Nombre max de clusters CAH",
                min_value=2,
                max_value=min(15, len(df_for_clustering) // 3),
                value=min(10, len(df_for_clustering) // 3),
                key="cah_max"
            )
    
    # ============================================
    # SECTION 4: LANCEMENT DE L'ANALYSE
    # ============================================
    
    if st.button("üöÄ Lancer l'Analyse de Clustering", type="primary"):
        with st.spinner("üîÑ Pr√©paration des donn√©es..."):
            try:
                # Pr√©parer les donn√©es pour le clustering
                df_scaled, scaler, feature_names = prepare_data_for_clustering(
                    df_for_clustering, 
                    features_for_clustering=selected_features
                )
                
                if len(df_scaled) < 10:
                    st.error("‚ùå Pas assez de donn√©es valides apr√®s nettoyage. V√©rifiez vos donn√©es.")
                    return
                
                st.success(f"‚úÖ Donn√©es pr√©par√©es: {len(df_scaled)} observations avec {len(feature_names)} caract√©ristiques")
                
                # Afficher les caract√©ristiques utilis√©es
                st.info(f"**Caract√©ristiques utilis√©es:** {', '.join(feature_names)}")
                
                # Appliquer PCA pour la visualisation
                with st.spinner("üîÑ Application de l'analyse PCA..."):
                    pca_model, df_pca, explained_variance = apply_pca_analysis(df_scaled, n_components_pca)
                
                st.write(f"**Variance expliqu√©e par PCA:** {explained_variance.sum()*100:.1f}% (composantes 1-{n_components_pca})")
                
                # ============================================
                # EX√âCUTION DES ALGORITHMES
                # ============================================
                
                if algorithm == "K-Means":
                    st.subheader("üîµ R√©sultats K-Means")
                    
                    with st.spinner("üîÑ Ex√©cution de K-Means..."):
                        kmeans_model, best_n_clusters, cluster_labels, metrics, scores, n_clusters_list = apply_kmeans_clustering(
                            df_scaled, 
                            n_clusters_range=n_clusters_range,
                            random_state=42
                        )
                    
                    # Afficher les m√©triques
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üéØ Clusters optimaux", best_n_clusters)
                    with col2:
                        st.metric("üìä Score Silhouette", f"{metrics['silhouette_score']:.4f}")
                    with col3:
                        st.metric("üìà Score Calinski-Harabasz", f"{metrics['calinski_harabasz_score']:.0f}")
                    with col4:
                        st.metric("‚ö° Inertie", f"{metrics['inertia']:.0f}")
                    
                    # Graphique d'optimisation
                    fig_optimization = px.line(
                        x=n_clusters_list, 
                        y=scores,
                        title="Optimisation du nombre de clusters - Score de Silhouette",
                        labels={'x': 'Nombre de clusters', 'y': 'Score de Silhouette'},
                        markers=True
                    )
                    fig_optimization.add_vline(
                        x=best_n_clusters, 
                        line_dash="dash", 
                        line_color="red", 
                        annotation_text=f"Optimal: {best_n_clusters}"
                    )
                    fig_optimization.update_layout(hovermode="x unified")
                    st.plotly_chart(fig_optimization, use_container_width=True)
                    
                    # Visualisation avec matplotlib
                    st.subheader("üìä Visualisations K-Means")
                    try:
                        # Utiliser le code corrig√© avec matplotlib
                        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
                        
                        # 1. Clusters en 2D PCA
                        colors = plt.cm.Set3(np.linspace(0, 1, len(set(cluster_labels))))
                        for i, label in enumerate(sorted(set(cluster_labels))):
                            mask = cluster_labels == label
                            axes[0,0].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], 
                                             c=[colors[i]], label=f'Cluster {label}', alpha=0.7)
                        axes[0,0].set_xlabel('PC1')
                        axes[0,0].set_ylabel('PC2')
                        axes[0,0].set_title('K-Means - Clusters (2D PCA)')
                        axes[0,0].legend()
                        axes[0,0].grid(True, alpha=0.3)
                        
                        # 2. Distribution des clusters
                        cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
                        bars = axes[0,1].bar(cluster_counts.index, cluster_counts.values, color=colors[:len(cluster_counts)])
                        axes[0,1].set_xlabel('Cluster')
                        axes[0,1].set_ylabel('Nombre de propri√©t√©s')
                        axes[0,1].set_title('Distribution des clusters K-Means')
                        axes[0,1].grid(True, alpha=0.3)
                        
                        # Ajouter les valeurs sur les barres
                        for bar, count in zip(bars, cluster_counts.values):
                            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                                           str(count), ha='center', va='bottom')
                        
                        # 3. √âvolution du score de silhouette
                        axes[1,0].plot(n_clusters_list, scores, 'o-', linewidth=2, markersize=8)
                        axes[1,0].axvline(x=best_n_clusters, color='red', linestyle='--', 
                                          label=f'Optimal: {best_n_clusters} clusters')
                        axes[1,0].set_xlabel('Nombre de clusters')
                        axes[1,0].set_ylabel('Score de silhouette')
                        axes[1,0].set_title('Optimisation du nombre de clusters')
                        axes[1,0].legend()
                        axes[1,0].grid(True, alpha=0.3)
                        
                        # 4. Variance expliqu√©e par PCA
                        pc_names = [f'PC{i+1}' for i in range(len(explained_variance))]
                        axes[1,1].bar(pc_names, explained_variance * 100, color='lightblue', edgecolor='black')
                        axes[1,1].set_xlabel('Composantes principales')
                        axes[1,1].set_ylabel('Variance expliqu√©e (%)')
                        axes[1,1].set_title('Variance expliqu√©e par PCA')
                        axes[1,1].grid(True, alpha=0.3)
                        
                        # Ajouter les pourcentages sur les barres
                        for i, var in enumerate(explained_variance):
                            axes[1,1].text(i, var * 100 + 1, f'{var*100:.1f}%', ha='center', va='bottom')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        # Analyser les clusters
                        analyze_kmeans_clusters(df_for_clustering, df_scaled, cluster_labels, feature_names)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la visualisation: {e}")
                
                elif algorithm == "DBSCAN":
                    st.subheader("üî¥ R√©sultats DBSCAN")
                    
                    with st.spinner("üîÑ Ex√©cution de DBSCAN..."):
                        dbscan_model, cluster_labels, metrics = apply_dbscan_clustering(
                            df_scaled,
                            eps_range=eps_range,
                            min_samples_range=min_samples_range
                        )
                    
                    # Afficher les m√©triques
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üéØ Clusters trouv√©s", metrics['n_clusters'])
                    with col2:
                        st.metric("üîç Points de bruit", metrics['n_noise_points'])
                    with col3:
                        st.metric("üìä Ratio de bruit", f"{metrics['noise_ratio']*100:.1f}%")
                    with col4:
                        if metrics['silhouette_score'] > 0:
                            st.metric("üìà Score Silhouette", f"{metrics['silhouette_score']:.4f}")
                        else:
                            st.metric("üìà Score Silhouette", "N/A")
                    
                    # Afficher les param√®tres optimaux
                    st.info(f"**Param√®tres optimaux:** eps={metrics['eps']:.3f}, min_samples={metrics['min_samples']}")
                    
                    # Visualisation DBSCAN
                    st.subheader("üìä Visualisations DBSCAN")
                    try:
                        visualize_dbscan_results(df_pca, cluster_labels, explained_variance)
                        
                        # Analyser les clusters DBSCAN
                        analyze_dbscan_clusters(df_for_clustering, df_scaled, cluster_labels, feature_names, metrics)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la visualisation DBSCAN: {e}")
                
                elif algorithm == "CAH (Classification Ascendante Hi√©rarchique)":
                    st.subheader("üü¢ R√©sultats CAH")
                    
                    with st.spinner("üîÑ Ex√©cution de CAH..."):
                        linkage_matrix, cluster_labels, optimal_n_clusters, cah_metrics = apply_cah_clustering(
                            df_scaled,
                            max_clusters=max_clusters_cah,
                            linkage_method=linkage_method
                        )
                    
                    # Afficher les m√©triques
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üéØ Clusters optimaux", optimal_n_clusters)
                    with col2:
                        st.metric("üìä Score Silhouette", f"{cah_metrics['silhouette_score']:.4f}")
                    with col3:
                        st.metric("üîó M√©thode de liaison", linkage_method)
                    
                    # Dendrogramme
                    st.subheader("üå≥ Dendrogramme")
                    try:
                        dendrogram_data = visualize_cah_dendrogram(
                            linkage_matrix,
                            optimal_n_clusters=optimal_n_clusters,
                            max_display=min(50, len(df_scaled))
                        )
                        st.pyplot(plt.gcf())
                        
                        # Analyse compl√®te CAH
                        results_df, detailed_df, hierarchy_df = complete_cah_analysis_after_dendrogram(
                            df, df_scaled, linkage_matrix, cluster_labels, optimal_n_clusters, feature_names
                        )
                        
                        # Afficher les r√©sultats sous forme de tableaux
                        st.subheader("üìã Analyse des Clusters CAH")
                        st.dataframe(results_df, use_container_width=True)
                        
                        with st.expander("üîç D√©tail de toutes les propri√©t√©s par cluster"):
                            st.dataframe(detailed_df, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de l'analyse CAH: {e}")
                
                else:  # Comparaison des 3 m√©thodes
                    st.subheader("üîÑ Comparaison des 3 M√©thodes")
                    
                    results = {}
                    
                    # K-Means
                    with st.spinner("üîÑ Ex√©cution de K-Means..."):
                        kmeans_model, kmeans_n_clusters, kmeans_labels, kmeans_metrics, _, _ = apply_kmeans_clustering(
                            df_scaled, n_clusters_range=n_clusters_range, random_state=42
                        )
                        results['K-Means'] = {
                            'labels': kmeans_labels,
                            'n_clusters': kmeans_n_clusters,
                            'silhouette_score': kmeans_metrics['silhouette_score'],
                            'method': 'K-Means'
                        }
                    
                    # DBSCAN
                    with st.spinner("üîÑ Ex√©cution de DBSCAN..."):
                        dbscan_model, dbscan_labels, dbscan_metrics = apply_dbscan_clustering(
                            df_scaled, eps_range=eps_range, min_samples_range=min_samples_range
                        )
                        results['DBSCAN'] = {
                            'labels': dbscan_labels,
                            'n_clusters': dbscan_metrics['n_clusters'],
                            'silhouette_score': dbscan_metrics['silhouette_score'],
                            'noise_points': dbscan_metrics['n_noise_points'],
                            'method': 'DBSCAN'
                        }
                    
                    # CAH
                    with st.spinner("üîÑ Ex√©cution de CAH..."):
                        linkage_matrix, cah_labels, cah_n_clusters, cah_metrics = apply_cah_clustering(
                            df_scaled, max_clusters=max_clusters_cah, linkage_method=linkage_method
                        )
                        results['CAH'] = {
                            'labels': cah_labels,
                            'n_clusters': cah_n_clusters,
                            'silhouette_score': cah_metrics['silhouette_score'],
                            'method': 'CAH'
                        }
                    
                    # Tableau de comparaison
                    comparison_data = {
                        'M√©thode': ['K-Means', 'DBSCAN', 'CAH'],
                        'Nombre de clusters': [
                            results['K-Means']['n_clusters'],
                            results['DBSCAN']['n_clusters'],
                            results['CAH']['n_clusters']
                        ],
                        'Score Silhouette': [
                            f"{results['K-Means']['silhouette_score']:.4f}",
                            f"{results['DBSCAN']['silhouette_score']:.4f}" if results['DBSCAN']['silhouette_score'] > 0 else "N/A",
                            f"{results['CAH']['silhouette_score']:.4f}"
                        ],
                        'Points de bruit': [
                            "0",
                            str(results['DBSCAN']['noise_points']),
                            "0"
                        ]
                    }
                    
                    comparison_df = pd.DataFrame(comparison_data)
                    st.dataframe(comparison_df, use_container_width=True)
                    
                    # Visualisations comparatives
                    st.subheader("üìä Visualisations Comparatives")
                    
                    fig, axes = plt.subplots(1, 3, figsize=(20, 6))
                    
                    methods = ['K-Means', 'DBSCAN', 'CAH']
                    labels_list = [kmeans_labels, dbscan_labels, cah_labels]
                    
                    for idx, (method, labels) in enumerate(zip(methods, labels_list)):
                        unique_labels = sorted(set(labels))
                        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
                        
                        for i, label in enumerate(unique_labels):
                            mask = labels == label
                            if label == -1:
                                axes[idx].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], 
                                                 c='black', label='Bruit', alpha=0.7, marker='x')
                            else:
                                axes[idx].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], 
                                                 c=[colors[i]], label=f'Cluster {label}', alpha=0.7)
                        
                        axes[idx].set_xlabel('PC1')
                        axes[idx].set_ylabel('PC2')
                        axes[idx].set_title(f'{method}')
                        axes[idx].legend()
                        axes[idx].grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # Recommandations
                    st.subheader("üí° Recommandations")
                    
                    best_method = max(results.items(), key=lambda x: x[1]['silhouette_score'])
                    st.success(f"üèÜ **Meilleure m√©thode:** {best_method[0]} (Score Silhouette: {best_method[1]['silhouette_score']:.4f})")
                    
                    # Recommandations contextuelles
                    if results['DBSCAN']['noise_points'] > len(df_scaled) * 0.3:
                        st.warning("‚ö†Ô∏è DBSCAN d√©tecte beaucoup de bruit (>30%). Consid√©rez K-Means ou CAH.")
                    
                    if results['K-Means']['silhouette_score'] > 0.5:
                        st.info("üëç K-Means montre une bonne s√©paration des clusters.")
                    
                    if results['CAH']['silhouette_score'] > results['K-Means']['silhouette_score']:
                        st.info("üå≥ CAH pourrait √™tre plus appropri√© pour vos donn√©es hi√©rarchiques.")
            
            except Exception as e:
                st.error(f"‚ùå Une erreur s'est produite lors de l'analyse: {e}")
                st.info("üí° V√©rifiez que vos donn√©es sont bien format√©es et qu'il y a suffisamment d'observations.")

# ============================================
# FONCTIONS AUXILIAIRES POUR LES VISUALISATIONS
# ============================================

def analyze_kmeans_clusters(df_original, df_scaled, cluster_labels, feature_names):
    """Analyse d√©taill√©e des clusters K-Means"""
    st.subheader("üîç Analyse D√©taill√©e des Clusters K-Means")
    
    # Cr√©er un DataFrame avec les r√©sultats
    # Ensure indices match between df_original and df_scaled
    analysis_df = df_original.reset_index(drop=True).iloc[:len(cluster_labels)].copy()
    analysis_df['Cluster'] = cluster_labels
    
    for cluster_id in sorted(set(cluster_labels)):
        with st.expander(f"üìä Cluster {cluster_id} - Analyse", expanded=False):
            cluster_data = analysis_df[analysis_df['Cluster'] == cluster_id]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Nombre de propri√©t√©s", len(cluster_data))
                
                if 'price' in cluster_data.columns:
                    st.metric("Prix moyen", f"{cluster_data['price'].mean():.0f} TND")
                    st.metric("Prix m√©dian", f"{cluster_data['price'].median():.0f} TND")
                
                if 'size' in cluster_data.columns:
                    st.metric("Taille moyenne", f"{cluster_data['size'].mean():.0f} m¬≤")
            
            with col2:
                if 'neighborhood' in cluster_data.columns:
                    neighborhoods = cluster_data['neighborhood'].value_counts().head(3)
                    st.write("**Top 3 quartiers:**")
                    for neighborhood, count in neighborhoods.items():
                        st.write(f"‚Ä¢ {neighborhood}: {count} propri√©t√©s")
                
                if 'condition' in cluster_data.columns:
                    conditions = cluster_data['condition'].value_counts().head(3)
                    st.write("**√âtats principaux:**")
                    for condition, count in conditions.items():
                        st.write(f"‚Ä¢ {condition}: {count} propri√©t√©s")

def visualize_dbscan_results(df_pca, cluster_labels, explained_variance):
    """Visualisation sp√©cifique pour DBSCAN"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Clusters DBSCAN en 2D PCA
    unique_labels = sorted(set(cluster_labels))
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    
    for i, label in enumerate(unique_labels):
        mask = cluster_labels == label
        if label == -1:
            axes[0,0].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], 
                             c='black', label='Bruit', alpha=0.7, marker='x')
        else:
            axes[0,0].scatter(df_pca.iloc[mask, 0], df_pca.iloc[mask, 1], 
                             c=[colors[i]], label=f'Cluster {label}', alpha=0.7)
    
    axes[0,0].set_xlabel('PC1')
    axes[0,0].set_ylabel('PC2')
    axes[0,0].set_title('DBSCAN - Clusters (2D PCA)')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    
    # 2. Distribution des clusters DBSCAN
    cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
    cluster_names = ['Bruit' if idx == -1 else f'Cluster {idx}' for idx in cluster_counts.index]
    bar_colors = ['black' if idx == -1 else colors[i] for i, idx in enumerate(cluster_counts.index)]
    
    bars = axes[0,1].bar(range(len(cluster_counts)), cluster_counts.values, color=bar_colors)
    axes[0,1].set_xticks(range(len(cluster_counts)))
    axes[0,1].set_xticklabels(cluster_names, rotation=45)
    axes[0,1].set_ylabel('Nombre de propri√©t√©s')
    axes[0,1].set_title('Distribution des clusters DBSCAN')
    axes[0,1].grid(True, alpha=0.3)
    
    # Ajouter les valeurs sur les barres
    for bar, count in zip(bars, cluster_counts.values):
        axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                       str(count), ha='center', va='bottom')
    
    # 3. Variance expliqu√©e par PCA
    pc_names = [f'PC{i+1}' for i in range(len(explained_variance))]
    axes[1,0].bar(pc_names, explained_variance * 100, color='lightblue', edgecolor='black')
    axes[1,0].set_xlabel('Composantes principales')
    axes[1,0].set_ylabel('Variance expliqu√©e (%)')
    axes[1,0].set_title('Variance expliqu√©e par PCA')
    axes[1,0].grid(True, alpha=0.3)
    
    # Ajouter les pourcentages sur les barres
    for i, var in enumerate(explained_variance):
        axes[1,0].text(i, var * 100 + 1, f'{var*100:.1f}%', ha='center', va='bottom')
    
    # 4. Histogramme des distances aux points centraux (si applicable)
    axes[1,1].hist(cluster_labels, bins=len(unique_labels), color='lightcoral', edgecolor='black', alpha=0.7)
    axes[1,1].set_xlabel('Cluster ID')
    axes[1,1].set_ylabel('Fr√©quence')
    axes[1,1].set_title('Distribution des assignations de clusters')
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)

def analyze_dbscan_clusters(df_original, df_scaled, cluster_labels, feature_names, metrics):
    """Analyse d√©taill√©e des clusters DBSCAN"""
    st.subheader("üîç Analyse D√©taill√©e des Clusters DBSCAN")
    
    # √âvaluation de la qualit√©
    noise_ratio = metrics['noise_ratio']
    n_clusters = metrics['n_clusters']
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if noise_ratio < 0.1:
            st.success("‚úÖ Excellent ratio de bruit (<10%)")
        elif noise_ratio < 0.2:
            st.info("üëç Bon ratio de bruit (<20%)")
        elif noise_ratio < 0.4:
            st.warning("‚ö†Ô∏è Ratio de bruit acceptable (<40%)")
        else:
            st.error("‚ùå Ratio de bruit probl√©matique (>40%)")
    
    with col2:
        if n_clusters >= 2 and n_clusters <= 6:
            st.success(f"‚úÖ Nombre optimal de clusters: {n_clusters}")
        elif n_clusters == 1:
            st.warning("‚ö†Ô∏è Un seul cluster d√©tect√©")
        elif n_clusters == 0:
            st.error("‚ùå Aucun cluster d√©tect√©")
        else:
            st.info(f"üìä {n_clusters} clusters d√©tect√©s")
    
    with col3:
        if metrics['silhouette_score'] > 0.5:
            st.success(f"‚úÖ Excellente coh√©sion: {metrics['silhouette_score']:.3f}")
        elif metrics['silhouette_score'] > 0.3:
            st.info(f"üëç Bonne coh√©sion: {metrics['silhouette_score']:.3f}")
        elif metrics['silhouette_score'] > 0:
            st.warning(f"‚ö†Ô∏è Coh√©sion faible: {metrics['silhouette_score']:.3f}")
        else:
            st.error("‚ùå Impossible de calculer la coh√©sion")
    
    # Analyser chaque cluster + bruit
    analysis_df = df_original.reset_index(drop=True).iloc[:len(cluster_labels)].copy()
    analysis_df['Cluster'] = cluster_labels
    
    unique_labels = sorted(set(cluster_labels))
    
    for label in unique_labels:
        cluster_data = analysis_df[analysis_df['Cluster'] == label]
        
        if label == -1:
            with st.expander(f"üîç Points de Bruit - {len(cluster_data)} propri√©t√©s", expanded=False):
                st.warning("‚ö†Ô∏è Ces propri√©t√©s ont des caract√©ristiques uniques/atypiques")
                
                if 'price' in cluster_data.columns:
                    st.write(f"**Prix:** {cluster_data['price'].min():.0f} - {cluster_data['price'].max():.0f} TND")
                    prix_median_general = analysis_df[analysis_df['Cluster'] != -1]['price'].median()
                    bonnes_affaires = cluster_data[cluster_data['price'] < prix_median_general]
                    if len(bonnes_affaires) > 0:
                        st.info(f"üí∞ {len(bonnes_affaires)} propri√©t√©s sous le prix m√©dian (bonnes affaires potentielles)")
                
                if len(cluster_data) <= 10:
                    st.dataframe(cluster_data[['price', 'size', 'neighborhood'] if all(col in cluster_data.columns for col in ['price', 'size', 'neighborhood']) else cluster_data.columns[:5]])
        else:
            with st.expander(f"üìä Cluster {label} - {len(cluster_data)} propri√©t√©s", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'price' in cluster_data.columns:
                        st.metric("Prix moyen", f"{cluster_data['price'].mean():.0f} TND")
                        st.metric("√âcart-type prix", f"{cluster_data['price'].std():.0f} TND")
                    
                    if 'size' in cluster_data.columns:
                        st.metric("Taille moyenne", f"{cluster_data['size'].mean():.0f} m¬≤")
                
                with col2:
                    if 'neighborhood' in cluster_data.columns:
                        neighborhoods = cluster_data['neighborhood'].value_counts().head(3)
                        st.write("**Quartiers principaux:**")
                        for neighborhood, count in neighborhoods.items():
                            pct = (count / len(cluster_data)) * 100
                            st.write(f"‚Ä¢ {neighborhood}: {count} ({pct:.0f}%)")
                    
                    if 'condition' in cluster_data.columns:
                        conditions = cluster_data['condition'].value_counts().head(2)
                        st.write("**√âtats principaux:**")
                        for condition, count in conditions.items():
                            pct = (count / len(cluster_data)) * 100
                            st.write(f"‚Ä¢ {condition}: {count} ({pct:.0f}%)")

def create_cluster_profile_radar(df_with_clusters, selected_features, cluster_labels):
    """Cr√©er un graphique radar pour profiler les clusters"""
    unique_clusters = [c for c in sorted(set(cluster_labels)) if c != -1]  # Exclure le bruit
    
    if len(unique_clusters) <= 1 or len(selected_features) <= 2:
        return None
    
    # Calculer les moyennes par cluster
    cluster_means = df_with_clusters.groupby('Cluster')[selected_features].mean()
    
    # Normaliser les valeurs (0-1) pour le radar chart
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    cluster_means_normalized = pd.DataFrame(
        scaler.fit_transform(cluster_means),
        columns=cluster_means.columns,
        index=cluster_means.index
    )
    
    # Cr√©er le graphique radar avec Plotly
    fig = go.Figure()
    
    colors = px.colors.qualitative.Set3
    
    for i, (cluster_id, row) in enumerate(cluster_means_normalized.iterrows()):
        if cluster_id != -1:  # Exclure le bruit
            fig.add_trace(go.Scatterpolar(
                r=row.values.tolist() + [row.values[0]],  # Fermer le polygone
                theta=row.index.tolist() + [row.index[0]],
                fill='toself',
                name=f'Cluster {cluster_id}',
                marker_color=colors[i % len(colors)],
                opacity=0.6
            ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1],
                tickmode='linear',
                tick0=0,
                dtick=0.2
            )
        ),
        showlegend=True,
        title="Profil des clusters (valeurs normalis√©es 0-1)",
        height=500
    )
    
    return fig

# ============================================
# SECTION D'AIDE ET INTERPR√âTATION
# ============================================

def add_clustering_help_section():
    """Section d'aide pour l'interpr√©tation des r√©sultats"""
    with st.expander("üí° Guide d'Interpr√©tation des R√©sultats de Clustering", expanded=False):
        st.markdown("""
        ## üîµ K-Means
        **Principe :** Divise les donn√©es en k clusters en minimisant la variance intra-cluster.
        
        **M√©triques importantes :**
        - **Score de Silhouette** (0 √† 1) : Mesure la qualit√© du clustering. Plus proche de 1 = meilleur.
        - **Inertie** : Somme des distances au carr√© des points √† leur centro√Øde. Plus faible = mieux.
        - **Score Calinski-Harabasz** : Ratio de dispersion entre/dans les clusters. Plus √©lev√© = mieux.
        
        **Avantages :** Rapide, stable, bon pour clusters sph√©riques.
        **Inconv√©nients :** N√©cessite de sp√©cifier k, sensible aux outliers.
        
        ---
        
        ## üî¥ DBSCAN
        **Principe :** Identifie des clusters de densit√© et marque les points isol√©s comme bruit.
        
        **Param√®tres cl√©s :**
        - **eps** : Distance maximale entre deux points pour qu'ils soient voisins.
        - **min_samples** : Nombre minimum de points pour former un cluster.
        
        **M√©triques importantes :**
        - **Points de bruit** : Points qui ne peuvent √™tre assign√©s √† aucun cluster.
        - **Ratio de bruit** : Pourcentage de points de bruit. <20% = bon, >40% = probl√©matique.
        
        **Avantages :** D√©tecte automatiquement le nombre de clusters, robuste aux outliers, clusters de forme arbitraire.
        **Inconv√©nients :** Sensible aux param√®tres, difficile avec densit√©s variables.
        
        ---
        
        ## üü¢ CAH (Classification Ascendante Hi√©rarchique)
        **Principe :** Construit une hi√©rarchie de clusters en fusionnant progressivement les plus proches.
        
        **M√©thodes de liaison :**
        - **Ward** : Minimise la variance intra-cluster (recommand√©).
        - **Complete** : Distance maximale entre clusters.
        - **Average** : Distance moyenne entre clusters.
        - **Single** : Distance minimale entre clusters.
        
        **Avantages :** Dendrogramme informatif, pas besoin de sp√©cifier k √† l'avance, d√©terministe.
        **Inconv√©nients :** Co√ªteux en calcul, sensible au bruit.
        
        ---
        
        ## üìä Interpr√©tation Business
        
        ### Types de Segments Immobiliers Typiques :
        
        **üè† Segment √âconomique**
        - Prix bas, tailles modestes
        - Cible : √âtudiants, jeunes professionnels
        - Strat√©gie : Accessibilit√©, localisation transport
        
        **üè° Segment Familial**
        - Prix moyen, surfaces g√©n√©reuses
        - Cible : Familles, primo-acc√©dants
        - Strat√©gie : Rapport qualit√©/prix, commodit√©s
        
        **üíé Segment Premium**
        - Prix √©lev√©, √©quipements haut de gamme
        - Cible : Cadres, investisseurs
        - Strat√©gie : Luxe, services, localisations privil√©gi√©es
        
        **üîç Points Atypiques (Bruit DBSCAN)**
        - Propri√©t√©s uniques ou mal valoris√©es
        - Opportunit√©s d'investissement potentielles
        - √Ä investiguer individuellement
        
        ---
        
        ## üéØ Conseils d'Analyse
        
        1. **Validation M√©tier** : Les clusters doivent avoir du sens business.
        2. **Taille des Clusters** : √âviter les clusters trop petits (<5% des donn√©es).
        3. **Stabilit√©** : Tester plusieurs algorithmes pour confirmer.
        4. **Actionabilit√©** : Chaque cluster doit permettre des actions marketing distinctes.
        5. **√âquilibrage** : Pr√©f√©rer des clusters de tailles relativement √©quilibr√©es.
        
        ### Signaux d'Alerte :
        - Score Silhouette < 0.2 : Clustering peu fiable
        - Trop de bruit DBSCAN (>50%) : Revoir les param√®tres
        - Un seul gros cluster : Donn√©es trop homog√®nes ou param√®tres inad√©quats
        """)

# Ajouter la section d'aide √† la fin de la fonction principale
def unsupervised_learning_section_complete(df, filtered_df):
    """Version compl√®te avec section d'aide"""
    # Appeler la fonction principale
    unsupervised_learning_section(df, filtered_df)
    
    # Ajouter la section d'aide
    add_clustering_help_section()

# ============================================
# FONCTIONS UTILITAIRES SUPPL√âMENTAIRES
# ============================================

def export_clustering_results(df_with_clusters, algorithm_name, cluster_labels):
    """Permettre l'export des r√©sultats de clustering"""
    st.subheader(f"üíæ Export des R√©sultats {algorithm_name}")
    
    if st.button(f"T√©l√©charger les r√©sultats {algorithm_name}"):
        # Pr√©parer les donn√©es pour export
        export_df = df_with_clusters.copy()
        export_df[f'Cluster_{algorithm_name}'] = cluster_labels
        
        # Convertir en CSV
        csv = export_df.to_csv(index=False)
        
        st.download_button(
            label=f"üìÅ T√©l√©charger CSV avec clusters {algorithm_name}",
            data=csv,
            file_name=f"clustering_results_{algorithm_name}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
        
        st.success("‚úÖ Fichier pr√™t pour t√©l√©chargement!")

def display_cluster_statistics_summary(results_dict):
    """Afficher un r√©sum√© statistique des diff√©rents algorithmes"""
    st.subheader("üìà R√©sum√© Statistique Comparatif")
    
    summary_data = []
    for method, result in results_dict.items():
        summary_data.append({
            'Algorithme': method,
            'Nombre de Clusters': result['n_clusters'],
            'Score Silhouette': f"{result['silhouette_score']:.4f}",
            'Points de Bruit': result.get('noise_points', 0),
            'Recommandation': get_algorithm_recommendation(result)
        })
    
    summary_df = pd.DataFrame(summary_data)
    st.dataframe(summary_df, use_container_width=True)

def get_algorithm_recommendation(result):
    """G√©n√©rer une recommandation bas√©e sur les r√©sultats"""
    silhouette = result['silhouette_score']
    n_clusters = result['n_clusters']
    noise_points = result.get('noise_points', 0)
    
    if silhouette > 0.6:
        return "üåü Excellent"
    elif silhouette > 0.4:
        return "üëç Bon"
    elif silhouette > 0.2:
        return "‚ö†Ô∏è Acceptable"
    elif n_clusters == 0:
        return "‚ùå √âchec"
    else:
        return "üîÑ √Ä revoir"
# Application principale
# Initialiser les variables de session
if 'df_imputed' not in st.session_state:
    st.session_state['df_imputed'] = None

# T√©l√©chargement du fichier

if uploaded_file is not None:
    try:
        # Essayer de charger avec diff√©rents s√©parateurs
        df = None
        try:
            df = pd.read_csv(uploaded_file, sep=',')
        except:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=';')
            except:
                try:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, sep='\t')
                except Exception as e:
                    st.error(f"Impossible de lire le fichier CSV: {e}")
        
        if df is None or df.empty:
            st.error("Le fichier est vide ou n'a pas pu √™tre lu correctement.")
        else:
            # Pr√©traiter les donn√©es
            df = preprocess_data(df)
            
            # Utiliser les donn√©es imput√©es si disponibles
            if st.session_state['df_imputed'] is not None:
                df = st.session_state['df_imputed']
                st.success("Utilisation des donn√©es imput√©es!")
            else:
                st.success("Fichier charg√© avec succ√®s!")
            
            # Filtres dans la barre lat√©rale
            st.sidebar.title("Filtres")
            
            if 'transaction' in df.columns:
                unique_transactions = sorted(df['transaction'].dropna().unique().tolist())
                display_transactions = ["Tous"] + [t.capitalize() for t in unique_transactions if isinstance(t, str)]
                transaction_map = {t.capitalize(): t for t in unique_transactions if isinstance(t, str)}
                transaction_map["Tous"] = "Tous"
                
                selected_display_transaction = st.sidebar.selectbox("Type de Transaction", display_transactions)
                selected_transaction = transaction_map[selected_display_transaction]
            else:
                selected_transaction = "Tous"
            
            if 'property_type' in df.columns:
                unique_property_types = sorted(df['property_type'].dropna().unique().tolist())
                display_property_types = ["Tous"] + [p.capitalize() for p in unique_property_types if isinstance(p, str)]
                property_type_map = {p.capitalize(): p for p in unique_property_types if isinstance(p, str)}
                property_type_map["Tous"] = "Tous"
                
                selected_display_property = st.sidebar.selectbox("Type de Bien", display_property_types)
                selected_property = property_type_map[selected_display_property]
            else:
                selected_property = "Tous"
            
            if 'city' in df.columns:
                unique_cities = sorted(df['city'].dropna().unique().tolist())
                display_cities = ["Toutes"] + [c.title() for c in unique_cities if isinstance(c, str)]
                city_map = {c.title(): c for c in unique_cities if isinstance(c, str)}
                city_map["Toutes"] = "Toutes"
                
                selected_display_city = st.sidebar.selectbox("Ville", display_cities)
                selected_city = city_map[selected_display_city]
            else:
                selected_city = "Toutes"
            
            # Appliquer les filtres
            filtered_df = df.copy()
            if selected_transaction != "Tous" and 'transaction' in df.columns:
                filtered_df = filtered_df[filtered_df['transaction'] == selected_transaction]
            if selected_property != "Tous" and 'property_type' in df.columns:
                filtered_df = filtered_df[filtered_df['property_type'] == selected_property]
            if selected_city != "Toutes" and 'city' in df.columns:
                filtered_df = filtered_df[filtered_df['city'] == selected_city]
            
            # Cr√©er des onglets pour organiser l'interface
            tab1, tab2, tab3, tab4, tab5,tab6 = st.tabs(["Aper√ßu des donn√©es", "Statistiques de base","Visualisations avanc√©es", "Imputation" , "Apprentissage supervis√©","Apprentissage non supervis√©"])
            
            with tab1:
                st.subheader("Aper√ßu des donn√©es")
                st.dataframe(filtered_df.head())
                
                st.subheader("Informations sur les colonnes")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("Types de donn√©es:")
                    st.write(pd.DataFrame({'Type': filtered_df.dtypes}))
                
                with col2:
                    st.write("Valeurs manquantes:")
                    missing_data = pd.DataFrame({
                        'Manquantes': filtered_df.isna().sum(), 
                        'Pourcentage': (filtered_df.isna().sum() / len(filtered_df) * 100).round(2)
                    })
                    st.write(missing_data)
            
            with tab2:
                # Statistiques de base
                st.subheader("Statistiques descriptives")
                
                # S√©lectionner uniquement les colonnes num√©riques pour describe()
                numeric_df = filtered_df.select_dtypes(include=['number'])
                if not numeric_df.empty:
                    st.dataframe(numeric_df.describe())
                else:
                    st.warning("Aucune colonne num√©rique disponible pour l'analyse statistique.")
                
                # M√©triques cl√©s
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Nombre de propri√©t√©s", len(filtered_df))
                
                with col2:
                    if 'price' in filtered_df.columns:
                        avg_price_sale = filtered_df.loc[filtered_df['transaction'] == 'sale', 'price'].dropna().mean()
                        if pd.notna(avg_price_sale):
                            st.metric("Prix moyen de vente", f"{avg_price_sale:,.0f} TND")
                        else:
                            st.metric("Prix moyen", "N/A")
                        avg_price_rent = filtered_df.loc[filtered_df['transaction'] == 'rent', 'price'].dropna().mean()
                        if pd.notna(avg_price_rent):
                            st.metric("Prix moyen de location", f"{avg_price_rent:,.0f} TND")
                    else:
                        st.metric("Prix moyen", "Colonne manquante")
                
                with col3:
                    if 'size' in filtered_df.columns:
                        avg_size = filtered_df['size'].dropna().mean()
                        if pd.notna(avg_size):
                            st.metric("Surface moyenne", f"{avg_size:.1f} m¬≤")
                        else:
                            st.metric("Surface moyenne", "N/A")
                    else:
                        st.metric("Surface moyenne", "Colonne manquante")
                
                # Visualisations de base
                basic_visualizations(filtered_df)
            with tab3:
                # Visualisations avanc√©es
                advanced_visualizations(filtered_df)
                
            with tab4:
                # Section d'imputation
                df = imputation_section(df)
            
            with tab5:
                # Section d'apprentissage supervis√©
                supervised_learning_section_complete(df, filtered_df)
                
            with tab6:
                
                unsupervised_learning_section(df, filtered_df)
        
    except Exception as e:
        st.error(f"Une erreur s'est produite lors du traitement du fichier: {e}")
        st.info("Conseil: V√©rifiez le format de votre fichier CSV et assurez-vous que les colonnes sont correctement nomm√©es.")