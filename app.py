import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Importer les fonctions depuis le fichier model_functions.py
from model_functions import (
    # Fonctions d'apprentissage supervis√©
    prepare_data_for_regression,
    regression_par_segment,
    random_forest_par_segment,
    xgboost_simple,
    comparer_modeles,
    prepare_data_for_clustering,
    apply_dbscan_clustering,
    visualize_clustering_results,
    apply_pca_analysis,
    apply_kmeans_clustering,
    apply_dbscan_clustering,
    impute_missing_prices,
    impute_condition_simple,
    impute_finishing_simple,
    impute_property_year_age,
    impute_binary_amenities,
    simple_impute_rooms,
    analyze_missing_data
)

# Configuration de la page
st.set_page_config(
    page_title="Analyse Immobili√®re ML",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour am√©liorer l'apparence
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #2563EB;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #3B82F6;
        margin-top: 1.5rem;
        margin-bottom: 0.8rem;
    }
    .highlight {
        background-color: #EFF6FF;
        padding: 20px;
        border-radius: 5px;
        border-left: 5px solid #3B82F6;
        margin-bottom: 20px;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 15px;
    }
    .stat-card {
        background-color: #F8FAFC;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 15px;
        text-align: center;
    }
    .footer {
        margin-top: 50px;
        padding-top: 20px;
        border-top: 1px solid #E5E7EB;
        text-align: center;
        font-size: 0.9rem;
        color: #6B7280;
    }
</style>
""", unsafe_allow_html=True)

# Header de l'application
st.title("üè† Analyse du March√© Immobilier Tunisien")

# Introduction et contexte
with st.expander("üìå √Ä propos de cette application", expanded=True):
    st.markdown("""
    <div class="highlight">
    <h4>Contexte</h4>
    <p>Cette application vous permet d'analyser en profondeur le march√© immobilier tunisien √† travers des donn√©es collect√©es depuis des sites de franchises immobili√®res  (Century 21, REMAX, Tecnocasa et Newkey). Que vous soyez un investisseur, un agent immobilier, ou simplement √† la recherche d'un bien, cet outil vous fournit des insights pr√©cieux sur les tendances du march√©.</p>
    
    <h4>Fonctionnalit√©s</h4>
    <ul>
        <li><strong>Analyse exploratoire</strong> : Visualisez les distributions des prix, surfaces, et autres caract√©ristiques des biens</li>
        <li><strong>Traitement des donn√©es</strong> : Nettoyez et imputez les valeurs manquantes pour une analyse plus pr√©cise</li>
        <li><strong>Mod√©lisation pr√©dictive</strong> : Utilisez des algorithmes d'apprentissage automatique pour pr√©dire les prix et identifier les facteurs d√©terminants</li>
        <li><strong>Segmentation g√©ographique</strong> : Analysez les sp√©cificit√©s du march√© par ville et quartier</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
uploaded_file = st.file_uploader("T√©l√©charger un fichier CSV", type=['csv'])


# Fonction pour nettoyer et pr√©parer les donn√©es
def preprocess_data(df):
    # Liste des colonnes num√©riques √† convertir
    numeric_columns = ['price', 'size', 'rooms', 'bedrooms', 'bathrooms', 'parkings', 
                      'construction_year', 'age', 'air_conditioning', 'central_heating', 
                      'swimming_pool', 'elevator', 'garden', 'equipped_kitchen']
    
    # Convertir chaque colonne en num√©rique
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Convertir les dates
    if 'listing_date' in df.columns:
        try:
            df['listing_date'] = pd.to_datetime(df['listing_date'], errors='coerce')
        except:
            pass
    
    # Remplacer les valeurs potentiellement probl√©matiques
    df = df.replace(['\\N', 'N/A', 'NA', ''], np.nan)
    
    # Standardiser la casse pour les colonnes cat√©gorielles
    categorical_columns = ['property_type', 'transaction', 'city', 'state', 'neighborhood', 'finishing', 'condition']
    for col in categorical_columns:
        if col in df.columns and df[col].dtype == 'object':
            # Convertir tout en minuscules pour standardiser
            df[col] = df[col].str.lower()
    
    return df

# Fonction pour g√©n√©rer les visualisations basiques
def basic_visualizations(df):
    # Visualisation par ville
    if 'city' in df.columns:
        st.subheader("Nombre de propri√©t√©s par ville")
        city_counts = df['city'].value_counts().reset_index()
        city_counts.columns = ['ville', 'nombre']
        city_counts['ville'] = city_counts['ville'].str.title()
        
        fig = px.bar(city_counts, x='ville', y='nombre', 
                   title="Nombre de propri√©t√©s par ville")
        st.plotly_chart(fig, use_container_width=True)
    
    # Prix moyen par type de propri√©t√©
    if 'property_type' in df.columns and 'price' in df.columns:
        valid_price_df = df.dropna(subset=['price'])
        if not valid_price_df.empty:
            st.subheader("Prix moyen par type de propri√©t√©")
            price_by_type = valid_price_df.groupby('property_type')['price'].mean().reset_index()
            price_by_type.columns = ['type', 'prix_moyen']
            price_by_type['type'] = price_by_type['type'].str.capitalize()
            
            fig = px.bar(price_by_type, x='type', y='prix_moyen', 
                       title="Prix moyen par type de propri√©t√©",
                       labels={'prix_moyen': 'Prix moyen (TND)', 'type': 'Type de bien'})
            st.plotly_chart(fig, use_container_width=True)
    
    # Relation taille vs prix
    if 'size' in df.columns and 'price' in df.columns:
        valid_data = df.dropna(subset=['size', 'price'])
        if len(valid_data) > 5:
            st.subheader("Relation entre taille et prix")
            
            if 'property_type' in valid_data.columns:
                plot_data = valid_data.copy()
                plot_data['property_type_display'] = plot_data['property_type'].str.capitalize()
                
                fig = px.scatter(plot_data, x='size', y='price', 
                               color='property_type_display',
                               title="Relation entre taille et prix",
                               labels={'size': 'Surface (m¬≤)', 'price': 'Prix (TND)', 
                                     'property_type_display': 'Type de bien'})
            else:
                fig = px.scatter(valid_data, x='size', y='price', 
                               title="Relation entre taille et prix",
                               labels={'size': 'Surface (m¬≤)', 'price': 'Prix (TND)'})
            
            st.plotly_chart(fig, use_container_width=True)

# Nouvelles visualisations
def advanced_visualizations(df):
    if df is None or df.empty:
        st.warning("Aucune donn√©e disponible pour les visualisations avanc√©es.")
        return
        
    col1, col2 = st.columns(2)
    
    # Distribution des conditions
    with col1:
        if 'condition' in df.columns and not df['condition'].isna().all():
            st.subheader("Distribution des √©tats de propri√©t√©")
            condition_counts = df['condition'].value_counts().reset_index()
            condition_counts.columns = ['√©tat', 'nombre']
            condition_counts['√©tat'] = condition_counts['√©tat'].str.capitalize()
            
            fig = px.pie(condition_counts, values='nombre', names='√©tat', 
                      title="Distribution des √©tats de propri√©t√©",
                      color_discrete_sequence=px.colors.qualitative.Pastel)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
    
    # Distribution des finitions
    with col2:
        if 'finishing' in df.columns and not df['finishing'].isna().all():
            st.subheader("Niveau de finition des propri√©t√©s")
            finishing_counts = df['finishing'].value_counts().reset_index()
            finishing_counts.columns = ['finition', 'nombre']
            finishing_counts['finition'] = finishing_counts['finition'].str.capitalize()
            
            fig = px.pie(finishing_counts, values='nombre', names='finition', 
                      title="Niveau de finition des propri√©t√©s",
                      color_discrete_sequence=px.colors.qualitative.Bold)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
    
    # Visualisation des transactions par quartier
    if 'transaction' in df.columns and 'neighborhood' in df.columns and not df['neighborhood'].isna().all():
        st.subheader("Types de transaction par quartier")
        try:
            transaction_by_neighborhood = pd.crosstab(df['neighborhood'], df['transaction'])
            transaction_by_neighborhood = transaction_by_neighborhood.reset_index()
            transaction_by_neighborhood_melted = pd.melt(
                transaction_by_neighborhood, 
                id_vars=['neighborhood'], 
                var_name='transaction', 
                value_name='count'
            )
            transaction_by_neighborhood_melted['neighborhood'] = transaction_by_neighborhood_melted['neighborhood'].str.title()
            transaction_by_neighborhood_melted['transaction'] = transaction_by_neighborhood_melted['transaction'].str.capitalize()
            
            # Limiter aux 15 quartiers les plus fr√©quents pour lisibilit√©
            top_neighborhoods = df['neighborhood'].value_counts().nlargest(15).index
            filtered_data = transaction_by_neighborhood_melted[
                transaction_by_neighborhood_melted['neighborhood'].str.lower().isin(top_neighborhoods)
            ]
            
            if not filtered_data.empty:
                fig = px.bar(filtered_data, x='neighborhood', y='count', color='transaction',
                           title="Types de transaction par quartier (top 15)",
                           labels={'count': 'Nombre', 'neighborhood': 'Quartier', 'transaction': 'Type de transaction'},
                           barmode='stack')
                fig.update_layout(xaxis={'categoryorder': 'total descending'})
                st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"Impossible de g√©n√©rer la visualisation des transactions par quartier: {e}")
    
    # Matrice de corr√©lation
    numeric_df = df.select_dtypes(include=['number'])
    if numeric_df.shape[1] > 2:
        st.subheader("Matrice de corr√©lation")
        
        # S√©lectionner seulement les colonnes num√©riques et supprimer les colonnes avec trop de NA
        cols_to_keep = numeric_df.columns[numeric_df.isnull().mean() < 0.5]
        if len(cols_to_keep) >= 2:  # Besoin d'au moins 2 colonnes pour une corr√©lation
            try:
                corr_df = numeric_df[cols_to_keep].corr()
                
                fig = px.imshow(corr_df, 
                               text_auto=True, 
                               aspect="auto",
                               color_continuous_scale='RdBu_r',
                               title="Corr√©lation entre les variables")
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de g√©n√©rer la matrice de corr√©lation: {e}")
    
    # Distribution des prix par type de propri√©t√©
    if 'price' in df.columns and 'property_type' in df.columns:
        valid_data = df.dropna(subset=['price', 'property_type'])
        if len(valid_data) > 5:
            st.subheader("Distribution des prix par type de propri√©t√©")
            
            fig = px.box(valid_data, x='property_type', y='price',
                       labels={'property_type': 'Type de propri√©t√©', 'price': 'Prix (TND)'},
                       title="Distribution des prix par type de propri√©t√©",
                       category_orders={"property_type": sorted(valid_data['property_type'].unique())})
            
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)

# Nouvelle section pour les imputations de donn√©es
def imputation_section(df):
    st.header("Imputation des donn√©es manquantes")
    
    if df is None or df.empty:
        st.error("Aucune donn√©e disponible pour l'imputation.")
        return df
    
    # Cr√©ation de l'interface d'imputation
    st.write("Cette section vous permet de compl√©ter les valeurs manquantes dans votre jeu de donn√©es.")
    
    try:
        # Analyser les donn√©es manquantes
        missing_data_df = analyze_missing_data(df)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("√âtat des valeurs manquantes")
            st.dataframe(missing_data_df)
        
        with col2:
            # Graphique des valeurs manquantes
            missing_cols = missing_data_df[missing_data_df['Valeurs NA'] > 0]
            if not missing_cols.empty:
                fig = px.bar(
                    missing_cols.reset_index(), 
                    x='index', 
                    y='Pourcentage NA (%)',
                    title="Pourcentage de valeurs manquantes par colonne",
                    labels={'index': 'Colonne', 'Pourcentage NA (%)': '% manquant'}
                )
                fig.update_layout(xaxis={'categoryorder': 'total descending'})
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("üëç Aucune valeur manquante dans vos donn√©es!")
        
        # S√©lection des colonnes √† imputer
        st.subheader("Choisir les colonnes √† imputer")
        
        # Organisation par cat√©gories
        price_cols = st.multiselect(
            "Colonnes de prix",
            [col for col in df.columns if col in ['price', 'price_ttc', 'listing_price']],
            [col for col in df.columns if col in ['price', 'price_ttc', 'listing_price'] and df[col].isna().sum() > 0]
        )
        
        condition_finishing_cols = st.multiselect(
            "Qualit√© et finition",
            [col for col in df.columns if col in ['condition', 'finishing']],
            [col for col in df.columns if col in ['condition', 'finishing'] and df[col].isna().sum() > 0]
        )
        
        age_year_cols = st.multiselect(
            "√Çge et ann√©e de construction",
            [col for col in df.columns if col in ['age', 'construction_year']],
            [col for col in df.columns if col in ['age', 'construction_year'] and df[col].isna().sum() > 0]
        )
        
        room_cols = st.multiselect(
            "Pi√®ces, chambres, salles de bain, etc.",
            [col for col in df.columns if col in ['rooms', 'bedrooms', 'bathrooms', 'parkings']],
            [col for col in df.columns if col in ['rooms', 'bedrooms', 'bathrooms', 'parkings'] and df[col].isna().sum() > 0]
        )
        
        binary_cols = st.multiselect(
            "√âquipements (variables binaires)",
            [col for col in df.columns if df[col].nunique() <= 2 and col not in ['transaction', 'city', 'property_type', 'neighborhood']],
            [col for col in df.columns if df[col].nunique() <= 2 and df[col].isna().sum() > 0 and col not in ['transaction', 'city', 'property_type', 'neighborhood']]
        )
        
        # Bouton pour lancer l'imputation
        impute_button = st.button("Imputer les valeurs manquantes", type="primary")
        
        if impute_button:
            if df is None or df.empty:
                st.error("Aucune donn√©e disponible pour l'imputation.")
                return df
                
            # Cr√©er une copie pour l'imputation
            try:
                df_imputed = df.copy()
                progress_placeholder = st.empty()
                
                with st.spinner("Imputation en cours..."):
                    # Imputation progressive avec barre de progression
                    progress_bar = st.progress(0)
                    
                    # 1. Imputation des prix
                    # 
                    
                    # 2. Imputation de la condition
                    if 'condition' in condition_finishing_cols:
                        progress_placeholder.write("Imputation de la condition...")
                        try:
                            df_imputed = impute_condition_simple(df_imputed)
                            progress_bar.progress(40)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de la condition: {e}")
                    
                    # 3. Imputation de la finition
                    if 'finishing' in condition_finishing_cols:
                        progress_placeholder.write("Imputation du niveau de finition...")
                        try:
                            df_imputed = impute_finishing_simple(df_imputed)
                            progress_bar.progress(60)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de la finition: {e}")
                    
                    # 4. Imputation de l'√¢ge et ann√©e de construction
                    if age_year_cols:
                        progress_placeholder.write("Imputation de l'√¢ge et ann√©e de construction...")
                        try:
                            df_imputed = impute_property_year_age(
                                df_imputed, 
                                impute_year='construction_year' in age_year_cols, 
                                impute_age='age' in age_year_cols
                            )
                            df_imputed['construction_year']=2025-df_imputed['age']
                            progress_bar.progress(75)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de l'√¢ge/ann√©e: {e}")
                    
                    # 5. Imputation des caract√©ristiques binaires
                    if binary_cols:
                        progress_placeholder.write("Imputation des √©quipements...")
                        try:
                            df_imputed = impute_binary_amenities(df_imputed, binary_columns=binary_cols)
                            progress_bar.progress(85)
                            time.sleep(0.5)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation des √©quipements: {e}")
                    
                    # 6. Imputation des pi√®ces et caract√©ristiques
                    for room_col in room_cols:
                        progress_placeholder.write(f"Imputation de {room_col}...")
                        try:
                            df_imputed = simple_impute_rooms(df_imputed, rooms_col=room_col)
                            time.sleep(0.3)
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation de {room_col}: {e}")
                    # imputation des prix
                    if price_cols:
                        progress_placeholder.write("Imputation des prix...")
                        try:
                            # df_imputed = impute_missing_prices(df_imputed)
                            df_imputed['price'] = df_imputed.groupby(['neighborhood', 'property_type','transaction'])['price'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price_ttc'] = df_imputed.groupby(['neighborhood', 'property_type','transaction'])['price_ttc'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price'] = df.groupby(['city','transaction'])['price'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed['price_ttc'] = df.groupby(['city','transaction'])['price_ttc'].transform(lambda x: x.fillna(x.mean()))
                            df_imputed = df_imputed[df_imputed['price'].notnull()]
    
                            df_imputed['suffix'] = df_imputed['suffix'].fillna('TTC')
                            
                            df_imputed['listing_price'] = df_imputed['listing_price'].fillna(df_imputed['price'])
                            
                            progress_bar.progress(100)
                            time.sleep(0.5)  
                        except Exception as e:
                            st.error(f"Erreur lors de l'imputation des prix: {e}")
                    progress_bar.progress(100)
                    progress_placeholder.empty()
                
                # Comparer l'avant/apr√®s
                st.subheader("R√©sultats de l'imputation")
                
                col1, col2 = st.columns(2)
                
                # Analyse des valeurs manquantes avant
                with col1:
                    df.drop(columns=['amenities'], inplace=True)
                    st.write("Avant imputation")
                    missing_before = analyze_missing_data(df)
                    st.dataframe(missing_before)
                    
                    # Pourcentage global des donn√©es manquantes avant
                    total_elements = df.shape[0] * df.shape[1]
                    total_missing = df.isna().sum().sum()
                    pct_missing_before = (total_missing / total_elements) * 100
                    
                    st.metric(
                        "Pourcentage global de donn√©es manquantes",
                        f"{pct_missing_before:.2f}%"
                    )
                
                # Analyse des valeurs manquantes apr√®s
                with col2:
                    st.write("Apr√®s imputation")
                    df_imputed.drop(columns=['amenities'], inplace=True)
                    missing_after = analyze_missing_data(df_imputed)
                    st.dataframe(missing_after)
                    
                    # Pourcentage global des donn√©es manquantes apr√®s
                    total_missing_after = df_imputed.isna().sum().sum()
                    pct_missing_after = (total_missing_after / total_elements) * 100
                    
                    st.metric(
                        "Pourcentage global de donn√©es manquantes",
                        f"{pct_missing_after:.2f}%",
                        f"-{pct_missing_before - pct_missing_after:.2f}%"
                    )
                
                # Visualisation de l'impact de l'imputation
                st.subheader("Visualisation de l'impact de l'imputation")
                
                # S√©lectionnez une colonne pour visualiser l'impact de l'imputation
                all_imputed_cols = price_cols + condition_finishing_cols + age_year_cols + room_cols + binary_cols
                
                if True:
                    vis_col = st.selectbox(
                        "S√©lectionner une colonne pour visualiser l'impact de l'imputation",
                        all_imputed_cols
                    )
                    
                    if vis_col in df_imputed.columns:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write(f"Distribution de {vis_col} avant imputation")
                            
                            if pd.api.types.is_numeric_dtype(df[vis_col]):
                                # Histogramme pour les donn√©es num√©riques
                                fig = px.histogram(
                                    df.dropna(subset=[vis_col]), 
                                    x=vis_col,
                                    title=f"Distribution de {vis_col} avant imputation",
                                    nbins=30,
                                    opacity=0.7
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                # Barres pour les donn√©es cat√©gorielles
                                value_counts = df[vis_col].value_counts().reset_index()
                                value_counts.columns = ['valeur', 'nombre']
                                
                                fig = px.bar(
                                    value_counts,
                                    x='valeur',
                                    y='nombre',
                                    title=f"Distribution de {vis_col} avant imputation"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            st.write(f"Distribution de {vis_col} apr√®s imputation")
                            
                            if pd.api.types.is_numeric_dtype(df_imputed[vis_col]):
                                # Histogramme pour les donn√©es num√©riques
                                fig = px.histogram(
                                    df_imputed, 
                                    x=vis_col,
                                    title=f"Distribution de {vis_col} apr√®s imputation",
                                    nbins=30,
                                    opacity=0.7
                                )
                                # Ajouter une ligne pour marquer les valeurs imput√©es
                                orig_values = df[~df[vis_col].isna()][vis_col]
                                fig.add_traces(
                                    px.histogram(
                                        orig_values, 
                                        x=orig_values,
                                        nbins=30,
                                        opacity=0.7
                                    ).data
                                )
                                fig.data[0].marker.color = 'blue'  # Toutes les valeurs
                                fig.data[1].marker.color = 'lightgreen'  # Valeurs originales
                                fig.data[0].name = 'Toutes les valeurs (incluant imput√©es)'
                                fig.data[1].name = 'Valeurs originales uniquement'
                                fig.update_layout(barmode='overlay', legend=dict(orientation='h'))
                                
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                # Barres pour les donn√©es cat√©gorielles
                                value_counts = df_imputed[vis_col].value_counts().reset_index()
                                value_counts.columns = ['valeur', 'nombre']
                                
                                fig = px.bar(
                                    value_counts,
                                    x='valeur',
                                    y='nombre',
                                    title=f"Distribution de {vis_col} apr√®s imputation"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                
                # Option pour continuer avec les donn√©es imput√©es
                if st.button("Utiliser les donn√©es imput√©es pour la suite de l'analyse"):
                    st.session_state['df_imputed'] = df_imputed
                    st.success("‚úÖ Les donn√©es imput√©es sont maintenant utilis√©es pour l'analyse!")
                    st.experimental_rerun()  # R√©ex√©cuter l'application pour utiliser les donn√©es imput√©es
                    
                return df_imputed  # Retourner les donn√©es imput√©es
                
            except Exception as e:
                st.error(f"Erreur lors de l'imputation: {e}")
                st.info("Conseil: V√©rifiez les donn√©es et essayez √† nouveau.")
                return df
    except Exception as e:
        st.error(f"Erreur lors de l'analyse des donn√©es manquantes: {e}")
        return df
        
    return df

# Nouvelle section pour l'apprentissage supervis√©
def supervised_learning_section(df, filtered_df):
    st.header("Mod√®les d'Apprentissage Supervis√©")
    
    if df is None or filtered_df is None or df.empty or filtered_df.empty:
        st.error("Aucune donn√©e disponible pour l'apprentissage supervis√©.")
        return
    
    # Pr√©parer les donn√©es pour la r√©gression
    with st.spinner("Pr√©paration des donn√©es pour l'apprentissage..."):
        try:
            df_prep = prepare_data_for_regression(filtered_df)
            st.success("Donn√©es pr√©par√©es pour l'apprentissage supervis√© !")
        except Exception as e:
            st.error(f"Erreur lors de la pr√©paration des donn√©es : {e}")
            return
    
    # Param√®tres pour les mod√®les
    st.subheader("Param√®tres du mod√®le")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'city' in filtered_df.columns:
            city_options = ["Toutes"] + sorted(filtered_df['city'].dropna().unique().tolist())
            selected_city = st.selectbox("Ville pour le mod√®le", city_options)
            selected_city = None if selected_city == "Toutes" else selected_city
        else:
            selected_city = None
            st.write("Information sur la ville non disponible")
    
    with col2:
        if 'property_type' in filtered_df.columns:
            property_options = ["Tous"] + sorted(filtered_df['property_type'].dropna().unique().tolist())
            selected_property = st.selectbox("Type de propri√©t√© pour le mod√®le", property_options)
            selected_property = None if selected_property == "Tous" else selected_property
        else:
            selected_property = None
            st.write("Information sur le type de propri√©t√© non disponible")
    
    with col3:
        if 'transaction' in filtered_df.columns:
            transaction_options = ["Toutes"] + sorted(filtered_df['transaction'].dropna().unique().tolist())
            selected_transaction = st.selectbox("Type de transaction pour le mod√®le", transaction_options)
            selected_transaction = None if selected_transaction == "Toutes" else selected_transaction
        else:
            selected_transaction = None
            st.write("Information sur le type de transaction non disponible")
    
    # S√©lection du mod√®le
    model_type = st.selectbox(
        "S√©lectionner le mod√®le",
        ["Comparaison de mod√®les", "R√©gression Lin√©aire", "Random Forest", "XGBoost"]
    )
    
    # Bouton pour lancer l'entra√Ænement
    if st.button("Entra√Æner le mod√®le"):
        with st.spinner("Entra√Ænement du mod√®le en cours..."):
            # V√©rifier qu'il y a assez de donn√©es
            if len(df_prep) < 10:
                st.error("Pas assez de donn√©es pour l'entra√Ænement du mod√®le. Veuillez √©largir les crit√®res de s√©lection.")
            else:
                try:
                    # Cr√©er un conteneur pour les r√©sultats
                    results_container = st.container()
                    
                    with results_container:
                        st.subheader(f"R√©sultats pour {model_type}")
                        
                        # Ex√©cuter le mod√®le s√©lectionn√©
                        if model_type == "Comparaison de mod√®les":
                            comparison = comparer_modeles(
                                df_prep, 
                                city=selected_city, 
                                property_type=selected_property, 
                                transaction=selected_transaction
                            )
                            st.dataframe(comparison)
                            
                            try:
                                # Convertir les figures Matplotlib en Plotly pour Streamlit
                                st.pyplot(plt.gcf())  # R√©cup√®re la figure actuelle (courante)
                            except Exception as e:
                                st.warning(f"Impossible d'afficher le graphique: {e}")
                        
                        elif model_type == "R√©gression Lin√©aire":
                            model, importance, metrics = regression_par_segment(
                                df_prep, 
                                city=selected_city, 
                                property_type=selected_property, 
                                transaction=selected_transaction
                            )
                            
                            # Afficher les m√©triques
                            st.write(f"R¬≤ (test): {metrics['test_r2']:.4f}")
                            st.write(f"RMSE (test): {metrics['test_rmse']:.2f}")
                            st.write(f"MAE (test): {metrics['test_mae']:.2f}")
                            
                            # Afficher l'importance des caract√©ristiques
                            st.subheader("Importance des caract√©ristiques")
                            
                            # Cr√©er un graphique Plotly pour l'importance des caract√©ristiques
                            top_features = importance.head(10)
                            fig = px.bar(
                                top_features,
                                x='Coefficient',
                                y='Caract√©ristique',
                                orientation='h',
                                title="Top 10 des caract√©ristiques les plus importantes",
                                color='Coefficient',
                                color_continuous_scale=px.colors.diverging.RdBu,
                                color_continuous_midpoint=0
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                            try:
                                # Convertir les figures Matplotlib en Plotly pour Streamlit
                                st.pyplot(plt.gcf())
                            except Exception as e:
                                st.warning(f"Impossible d'afficher le graphique: {e}")
                        
                        elif model_type == "Random Forest":
                            model, importance, metrics = random_forest_par_segment(
                                df_prep, 
                                city=selected_city, 
                                property_type=selected_property, 
                                transaction=selected_transaction
                            )
                            
                            # Afficher les m√©triques
                            st.write(f"R¬≤ (test): {metrics['test_r2']:.4f}")
                            st.write(f"RMSE (test): {metrics['test_rmse']:.2f}")
                            st.write(f"MAE (test): {metrics['test_mae']:.2f}")
                            
                            # Afficher l'importance des caract√©ristiques
                            st.subheader("Importance des caract√©ristiques")
                            
                            # Cr√©er un graphique Plotly pour l'importance des caract√©ristiques
                            top_features = importance.head(10)
                            fig = px.bar(
                                top_features,
                                x='Importance',
                                y='Caract√©ristique',
                                orientation='h',
                                title="Top 10 des caract√©ristiques les plus importantes",
                                color='Importance',
                                color_continuous_scale='Viridis'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                            try:
                                # Convertir les figures Matplotlib en Plotly pour Streamlit
                                st.pyplot(plt.gcf())
                            except Exception as e:
                                st.warning(f"Impossible d'afficher le graphique: {e}")
                        
                        elif model_type == "XGBoost":
                            model, importance, test_r2 = xgboost_simple(
                                df_prep, 
                                city=selected_city, 
                                property_type=selected_property, 
                                transaction=selected_transaction
                            )
                            
                            # Afficher les m√©triques
                            st.write(f"R¬≤ (test): {test_r2:.4f}")
                            
                            # Afficher l'importance des caract√©ristiques
                            st.subheader("Importance des caract√©ristiques")
                            
                            # Cr√©er un graphique Plotly pour l'importance des caract√©ristiques
                            top_features = importance.head(10)
                            fig = px.bar(
                                top_features,
                                x='Importance',
                                y='Caract√©ristique',
                                orientation='h',
                                title="Top 10 des caract√©ristiques les plus importantes",
                                color='Importance',
                                color_continuous_scale='Viridis'
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                            try:
                                # Convertir les figures Matplotlib en Plotly pour Streamlit
                                st.pyplot(plt.gcf())
                            except Exception as e:
                                st.warning(f"Impossible d'afficher le graphique: {e}")
                            
                except Exception as e:
                    st.error(f"Une erreur s'est produite lors de l'entra√Ænement du mod√®le: {e}")

def unsupervised_learning_section(df, filtered_df):
    st.header("Apprentissage Non Supervis√©")
    
    if df is None or filtered_df is None or df.empty or filtered_df.empty:
        st.error("Aucune donn√©e disponible pour l'apprentissage non supervis√©.")
        return
    
    st.markdown("""
    <div class="info-box">
    L'apprentissage non supervis√© permet de d√©couvrir des structures cach√©es dans les donn√©es sans avoir de variable cible.
    Nous utiliserons le clustering pour identifier des groupes de propri√©t√©s similaires et la PCA pour r√©duire la dimensionnalit√©.
    </div>
    """, unsafe_allow_html=True)
    
    # S√©lection des caract√©ristiques pour le clustering
    st.subheader("S√©lection des caract√©ristiques")
    
    # Obtenir les colonnes num√©riques disponibles
    numeric_cols = filtered_df.select_dtypes(include=['number']).columns.tolist()
    exclude_cols = ['date', 'source', 'neighborhood', 'suffix', 'listing_price', 'price_ttc', 'construction_year']
    available_features = [col for col in numeric_cols if col not in exclude_cols]
    
    # Interface pour s√©lectionner les caract√©ristiques
    col1, col2 = st.columns([2, 1])
    
    with col1:
        selected_features = st.multiselect(
            "S√©lectionner les caract√©ristiques pour le clustering",
            available_features,
            default=available_features[:6] if len(available_features) >= 6 else available_features,
            help="Choisissez les caract√©ristiques qui seront utilis√©es pour identifier les groupes de propri√©t√©s similaires"
        )
    
    with col2:
        # Filtres pour l'apprentissage non supervis√©
        st.write("**Filtres appliqu√©s:**")
        if 'city' in filtered_df.columns:
            city_options = ["Toutes"] + sorted(filtered_df['city'].dropna().unique().tolist())
            selected_city = st.selectbox("Ville", city_options, key="unsup_city")
            selected_city = None if selected_city == "Toutes" else selected_city
        else:
            selected_city = None
        
        if 'property_type' in filtered_df.columns:
            property_options = ["Tous"] + sorted(filtered_df['property_type'].dropna().unique().tolist())
            selected_property = st.selectbox("Type de propri√©t√©", property_options, key="unsup_property")
            selected_property = None if selected_property == "Tous" else selected_property
        else:
            selected_property = None
    
    # Appliquer les filtres
    df_for_clustering = filtered_df.copy()
    if selected_city is not None:
        df_for_clustering = df_for_clustering[df_for_clustering['city'] == selected_city]
    if selected_property is not None:
        df_for_clustering = df_for_clustering[df_for_clustering['property_type'] == selected_property]
    
    # V√©rifier qu'on a assez de donn√©es
    if len(df_for_clustering) < 10:
        st.warning("Pas assez de donn√©es pour l'analyse de clustering (minimum 10 observations). Veuillez √©largir les filtres.")
        return
    
    # Param√®tres des algorithmes
    st.subheader("Param√®tres des algorithmes")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        algorithm = st.selectbox(
            "Algorithme de clustering",
            ["K-Means", "DBSCAN", "Comparaison K-Means vs DBSCAN"]
        )
    
    with col2:
        if algorithm in ["K-Means", "Comparaison K-Means vs DBSCAN"]:
            max_clusters = min(10, len(df_for_clustering) // 5)  # Maximum raisonnable de clusters
            n_clusters_range = st.slider(
                "Nombre de clusters √† tester (K-Means)",
                min_value=2,
                max_value=max_clusters,
                value=(2, min(8, max_clusters)),
                help="Range du nombre de clusters √† tester pour K-Means"
            )
    
    with col3:
        n_components_pca = st.slider(
            "Nombre de composantes PCA",
            min_value=2,
            max_value=min(len(selected_features), 10),
            value=min(3, len(selected_features)),
            help="Nombre de composantes principales √† conserver pour la visualisation"
        )
    
    # Bouton pour lancer l'analyse
    if st.button("Lancer l'analyse de clustering", type="primary"):
        if not selected_features:
            st.error("Veuillez s√©lectionner au moins une caract√©ristique pour le clustering.")
            return
        
        with st.spinner("Analyse en cours..."):
            try:
                # Pr√©parer les donn√©es
                df_scaled, scaler, feature_names = prepare_data_for_clustering(
                    df_for_clustering, 
                    features_for_clustering=selected_features
                )
                
                if len(df_scaled) < 10:
                    st.error("Pas assez de donn√©es valides apr√®s nettoyage. V√©rifiez vos donn√©es.")
                    return
                
                st.success(f"Donn√©es pr√©par√©es: {len(df_scaled)} observations avec {len(feature_names)} caract√©ristiques")
                
                # Afficher les caract√©ristiques utilis√©es
                st.write(f"**Caract√©ristiques utilis√©es:** {', '.join(feature_names)}")
                
                # Appliquer PCA
                pca_model, df_pca, explained_variance = apply_pca_analysis(df_scaled, n_components_pca)
                
                # Appliquer le clustering selon l'algorithme s√©lectionn√©
                if algorithm == "K-Means":
                    # K-Means uniquement
                    st.subheader("R√©sultats K-Means")
                    
                    kmeans_model, best_n_clusters, cluster_labels, metrics, scores, n_clusters_list = apply_kmeans_clustering(
                        df_scaled, 
                        n_clusters_range=n_clusters_range
                    )
                    
                    # Afficher les m√©triques
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Clusters optimaux", best_n_clusters)
                    with col2:
                        st.metric("Score Silhouette", f"{metrics['silhouette_score']:.4f}")
                    with col3:
                        st.metric("Score Calinski-Harabasz", f"{metrics['calinski_harabasz_score']:.0f}")
                    with col4:
                        st.metric("Inertie", f"{metrics['inertia']:.0f}")
                    
                    # Graphique d'optimisation du nombre de clusters
                    fig_elbow = px.line(
                        x=n_clusters_list, 
                        y=scores,
                        title="Score de Silhouette vs Nombre de Clusters",
                        labels={'x': 'Nombre de clusters', 'y': 'Score de Silhouette'}
                    )
                    fig_elbow.add_vline(x=best_n_clusters, line_dash="dash", line_color="red", 
                                       annotation_text=f"Optimal: {best_n_clusters}")
                    st.plotly_chart(fig_elbow, use_container_width=True)
                    
                    # Visualisation des r√©sultats
                    fig_clustering = visualize_clustering_results(
                        df_scaled, cluster_labels, pca_model, df_pca, "K-Means"
                    )
                    st.plotly_chart(fig_clustering, use_container_width=True)
                
                elif algorithm == "DBSCAN":
                    # DBSCAN uniquement
                    st.subheader("R√©sultats DBSCAN")
                    
                    dbscan_model, cluster_labels, metrics = apply_dbscan_clustering(df_scaled)
                    
                    # Afficher les m√©triques
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Clusters trouv√©s", metrics['n_clusters'])
                    with col2:
                        st.metric("Points de bruit", metrics['n_noise_points'])
                    with col3:
                        st.metric("Ratio de bruit", f"{metrics['noise_ratio']*100:.1f}%")
                    with col4:
                        if metrics['silhouette_score'] > 0:
                            st.metric("Score Silhouette", f"{metrics['silhouette_score']:.4f}")
                        else:
                            st.metric("Score Silhouette", "N/A")
                    
                    # Afficher les param√®tres optimaux
                    st.write(f"**Param√®tres optimaux:** eps={metrics['eps']:.3f}, min_samples={metrics['min_samples']}")
                    
                    # Visualisation des r√©sultats
                    fig_clustering = visualize_clustering_results(
                        df_scaled, cluster_labels, pca_model, df_pca, "DBSCAN"
                    )
                    st.plotly_chart(fig_clustering, use_container_width=True)
                
                else:  # Comparaison
                    st.subheader("Comparaison K-Means vs DBSCAN")
                    
                    # K-Means
                    kmeans_model, best_n_clusters, kmeans_labels, kmeans_metrics, _, _ = apply_kmeans_clustering(
                        df_scaled, n_clusters_range=n_clusters_range
                    )
                    
                    # DBSCAN
                    dbscan_model, dbscan_labels, dbscan_metrics = apply_dbscan_clustering(df_scaled)
                    
                    # Tableau de comparaison
                    comparison_data = {
                        'M√©trique': ['Nombre de clusters', 'Score Silhouette', 'Points de bruit'],
                        'K-Means': [
                            best_n_clusters,
                            f"{kmeans_metrics['silhouette_score']:.4f}",
                            "0"
                        ],
                        'DBSCAN': [
                            dbscan_metrics['n_clusters'],
                            f"{dbscan_metrics['silhouette_score']:.4f}" if dbscan_metrics['silhouette_score'] > 0 else "N/A",
                            f"{dbscan_metrics['n_noise_points']}"
                        ]
                    }
                    
                    comparison_df = pd.DataFrame(comparison_data)
                    st.dataframe(comparison_df, use_container_width=True)
                    
                    # Visualisations c√¥te √† c√¥te
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig_kmeans = visualize_clustering_results(
                            df_scaled, kmeans_labels, pca_model, df_pca, "K-Means"
                        )
                        fig_kmeans.update_layout(height=600, title_text="K-Means Clustering")
                        st.plotly_chart(fig_kmeans, use_container_width=True)
                    
                    with col2:
                        fig_dbscan = visualize_clustering_results(
                            df_scaled, dbscan_labels, pca_model, df_pca, "DBSCAN"
                        )
                        fig_dbscan.update_layout(height=600, title_text="DBSCAN Clustering")
                        st.plotly_chart(fig_dbscan, use_container_width=True)
                
                # Analyse des clusters par caract√©ristiques originales
                st.subheader("Analyse des clusters")
                
                # Utiliser les labels du dernier algorithme ex√©cut√©
                final_labels = cluster_labels if algorithm != "Comparaison K-Means vs DBSCAN" else kmeans_labels
                
                # Ajouter les labels de clusters aux donn√©es originales
                df_with_clusters = df_for_clustering.iloc[df_scaled.index].copy()
                df_with_clusters['Cluster'] = final_labels
                
                # Statistiques par cluster
                cluster_stats = df_with_clusters.groupby('Cluster')[selected_features].agg(['mean', 'std']).round(2)
                
                st.write("**Statistiques moyennes par cluster:**")
                st.dataframe(cluster_stats)
                
                # Graphique radar pour comparer les clusters
                if len(set(final_labels)) <= 8:  # Limiter √† 8 clusters pour la lisibilit√©
                    cluster_means = df_with_clusters.groupby('Cluster')[selected_features].mean()
                    
                    # Normaliser les valeurs pour le radar chart (0-1)
                    from sklearn.preprocessing import MinMaxScaler
                    radar_scaler = MinMaxScaler()
                    cluster_means_normalized = pd.DataFrame(
                        radar_scaler.fit_transform(cluster_means),
                        columns=cluster_means.columns,
                        index=cluster_means.index
                    )
                    
                    fig_radar = go.Figure()
                    
                    colors = px.colors.qualitative.Set3
                    for i, (cluster_id, row) in enumerate(cluster_means_normalized.iterrows()):
                        if cluster_id != -1:  # Exclure le bruit pour DBSCAN
                            fig_radar.add_trace(go.Scatterpolar(
                                r=row.values.tolist() + [row.values[0]],  # Fermer le polygon
                                theta=row.index.tolist() + [row.index[0]],
                                fill='toself',
                                name=f'Cluster {cluster_id}',
                                marker_color=colors[i % len(colors)]
                            ))
                    
                    fig_radar.update_layout(
                        polar=dict(
                            radialaxis=dict(
                                visible=True,
                                range=[0, 1]
                            )),
                        showlegend=True,
                        title="Profil des clusters (valeurs normalis√©es)"
                    )
                    
                    st.plotly_chart(fig_radar, use_container_width=True)
                
            except Exception as e:
                st.error(f"Une erreur s'est produite lors de l'analyse: {e}")
                st.info("V√©rifiez que vos donn√©es sont bien format√©es et qu'il y a suffisamment d'observations.")
    
    # Section d'aide et interpr√©tation
    with st.expander("üí° Guide d'interpr√©tation des r√©sultats", expanded=False):
        st.markdown("""
        ### K-Means
        - **Score de Silhouette** : Mesure la qualit√© du clustering (entre -1 et 1, plus proche de 1 = meilleur)
        - **Inertie** : Somme des distances au carr√© des points √† leur centro√Øde (plus faible = mieux)
        - **Score Calinski-Harabasz** : Ratio de dispersion entre/dans les clusters (plus √©lev√© = mieux)
        
        ### DBSCAN
        - **Points de bruit** : Points qui ne peuvent √™tre assign√©s √† aucun cluster
        - **eps** : Distance maximale entre deux points pour qu'ils soient consid√©r√©s comme voisins
        - **min_samples** : Nombre minimum de points requis pour former un cluster
        
        ### PCA (Analyse en Composantes Principales)
        - **Variance expliqu√©e** : Pourcentage d'information conserv√©e par chaque composante
        - Les premi√®res composantes capturent le maximum de variabilit√© des donn√©es
        
        ### Conseils d'analyse
        - Comparez les profils des clusters pour identifier les caract√©ristiques discriminantes
        - Un bon clustering s√©pare des groupes avec des comportements distincts
        - Utilisez le contexte m√©tier pour valider la pertinence des clusters trouv√©s
        """)

# Application principale
# Initialiser les variables de session
if 'df_imputed' not in st.session_state:
    st.session_state['df_imputed'] = None

# T√©l√©chargement du fichier

if uploaded_file is not None:
    try:
        # Essayer de charger avec diff√©rents s√©parateurs
        df = None
        try:
            df = pd.read_csv(uploaded_file, sep=',')
        except:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, sep=';')
            except:
                try:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, sep='\t')
                except Exception as e:
                    st.error(f"Impossible de lire le fichier CSV: {e}")
        
        if df is None or df.empty:
            st.error("Le fichier est vide ou n'a pas pu √™tre lu correctement.")
        else:
            # Pr√©traiter les donn√©es
            df = preprocess_data(df)
            
            # Utiliser les donn√©es imput√©es si disponibles
            if st.session_state['df_imputed'] is not None:
                df = st.session_state['df_imputed']
                st.success("Utilisation des donn√©es imput√©es!")
            else:
                st.success("Fichier charg√© avec succ√®s!")
            
            # Filtres dans la barre lat√©rale
            st.sidebar.title("Filtres")
            
            if 'transaction' in df.columns:
                unique_transactions = sorted(df['transaction'].dropna().unique().tolist())
                display_transactions = ["Tous"] + [t.capitalize() for t in unique_transactions if isinstance(t, str)]
                transaction_map = {t.capitalize(): t for t in unique_transactions if isinstance(t, str)}
                transaction_map["Tous"] = "Tous"
                
                selected_display_transaction = st.sidebar.selectbox("Type de Transaction", display_transactions)
                selected_transaction = transaction_map[selected_display_transaction]
            else:
                selected_transaction = "Tous"
            
            if 'property_type' in df.columns:
                unique_property_types = sorted(df['property_type'].dropna().unique().tolist())
                display_property_types = ["Tous"] + [p.capitalize() for p in unique_property_types if isinstance(p, str)]
                property_type_map = {p.capitalize(): p for p in unique_property_types if isinstance(p, str)}
                property_type_map["Tous"] = "Tous"
                
                selected_display_property = st.sidebar.selectbox("Type de Bien", display_property_types)
                selected_property = property_type_map[selected_display_property]
            else:
                selected_property = "Tous"
            
            if 'city' in df.columns:
                unique_cities = sorted(df['city'].dropna().unique().tolist())
                display_cities = ["Toutes"] + [c.title() for c in unique_cities if isinstance(c, str)]
                city_map = {c.title(): c for c in unique_cities if isinstance(c, str)}
                city_map["Toutes"] = "Toutes"
                
                selected_display_city = st.sidebar.selectbox("Ville", display_cities)
                selected_city = city_map[selected_display_city]
            else:
                selected_city = "Toutes"
            
            # Appliquer les filtres
            filtered_df = df.copy()
            if selected_transaction != "Tous" and 'transaction' in df.columns:
                filtered_df = filtered_df[filtered_df['transaction'] == selected_transaction]
            if selected_property != "Tous" and 'property_type' in df.columns:
                filtered_df = filtered_df[filtered_df['property_type'] == selected_property]
            if selected_city != "Toutes" and 'city' in df.columns:
                filtered_df = filtered_df[filtered_df['city'] == selected_city]
            
            # Cr√©er des onglets pour organiser l'interface
            tab1, tab2, tab3, tab4, tab5,tab6 = st.tabs(["Aper√ßu des donn√©es", "Statistiques de base","Visualisations avanc√©es", "Imputation" , "Apprentissage supervis√©","Apprentissage non supervis√©"])
            
            with tab1:
                st.subheader("Aper√ßu des donn√©es")
                st.dataframe(filtered_df.head())
                
                st.subheader("Informations sur les colonnes")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("Types de donn√©es:")
                    st.write(pd.DataFrame({'Type': filtered_df.dtypes}))
                
                with col2:
                    st.write("Valeurs manquantes:")
                    missing_data = pd.DataFrame({
                        'Manquantes': filtered_df.isna().sum(), 
                        'Pourcentage': (filtered_df.isna().sum() / len(filtered_df) * 100).round(2)
                    })
                    st.write(missing_data)
            
            with tab2:
                # Statistiques de base
                st.subheader("Statistiques descriptives")
                
                # S√©lectionner uniquement les colonnes num√©riques pour describe()
                numeric_df = filtered_df.select_dtypes(include=['number'])
                if not numeric_df.empty:
                    st.dataframe(numeric_df.describe())
                else:
                    st.warning("Aucune colonne num√©rique disponible pour l'analyse statistique.")
                
                # M√©triques cl√©s
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Nombre de propri√©t√©s", len(filtered_df))
                
                with col2:
                    if 'price' in filtered_df.columns:
                        avg_price_sale = filtered_df.loc[filtered_df['transaction'] == 'sale', 'price'].dropna().mean()
                        if pd.notna(avg_price_sale):
                            st.metric("Prix moyen de vente", f"{avg_price_sale:,.0f} TND")
                        else:
                            st.metric("Prix moyen", "N/A")
                        avg_price_rent = filtered_df.loc[filtered_df['transaction'] == 'rent', 'price'].dropna().mean()
                        if pd.notna(avg_price_rent):
                            st.metric("Prix moyen de location", f"{avg_price_rent:,.0f} TND")
                    else:
                        st.metric("Prix moyen", "Colonne manquante")
                
                with col3:
                    if 'size' in filtered_df.columns:
                        avg_size = filtered_df['size'].dropna().mean()
                        if pd.notna(avg_size):
                            st.metric("Surface moyenne", f"{avg_size:.1f} m¬≤")
                        else:
                            st.metric("Surface moyenne", "N/A")
                    else:
                        st.metric("Surface moyenne", "Colonne manquante")
                
                # Visualisations de base
                basic_visualizations(filtered_df)
            with tab3:
                # Visualisations avanc√©es
                advanced_visualizations(filtered_df)
                
            with tab4:
                # Section d'imputation
                updated_df = imputation_section(df)
                if updated_df is not None:
                    df = updated_df  # Mettre √† jour le dataframe avec les donn√©es imput√©es
            
            with tab5:
                # Section d'apprentissage supervis√©
                supervised_learning_section(df, filtered_df)
                
            with tab6:
                unsupervised_learning_section(df, filtered_df)
        
    except Exception as e:
        st.error(f"Une erreur s'est produite lors du traitement du fichier: {e}")
        st.info("Conseil: V√©rifiez le format de votre fichier CSV et assurez-vous que les colonnes sont correctement nomm√©es.")